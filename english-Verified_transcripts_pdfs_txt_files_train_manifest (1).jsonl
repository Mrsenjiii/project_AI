{"audio_filepath": "/content/Audio_trimmed_wav/Perceptron Learning Algorithm.wav", "duration": 0.592, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module two five lecture two perceptron learning algorithm we will now go to the next module which is the perceptron learning algorithm refer slide time seventeen we now see a more principled approach of learning these weights and threshold but before that we will just again revisit our movie example and make it slightly more complicated refer slide time twenty-five now here what the situation is that we are given a list of m movies and a class associated with each movie indicating whether we like the movie or not so now we have given some data of the past m movies that we have seen and whether we like this movie or not and now instead of these three variables we have these n different variables based on which we are making decisions and notice that some of these variables are real they are not boolean anymore the rating could be any real number between zero to one ok and now based on this data what do we want is the perceptron to do actually so i have given you some data these factors i have also given you the label one and zero so if the perceptron if i tell you my perceptron has now learnt properly what would you expected it to do perfect match so whenever i feed it one of these movies it should give me the same label as was there in my data and again there are some movies for which i have a label one which are positive and some movies which i have a label zero so i am once again looking to separate the positives from the negatives so it should adjust the weights in such a way that i should be able to separate so that is the learning problem that we are interested in refer slide time one hundred and thirty-one so now with that i will give you the algorithm this is the perceptron learning algorithm we have certain positive inputs which had the label one we have certain negative inputs which had the label zero and now i don\u2019t know what the weights are and i have no prior knowledge of what the weights are going to be i need to learn them from the data so what i am going to do is i am just going to initialize these weights randomly as i am also going to pick up some random values for this so this should be small n so this should be small n and now here is the algorithm while not convergence do something so before i tell you what to do can you tell me what is meant by convergence when will you say that it has converged when it is not making any more errors on the training data right or its predictions are not changing on the training data so that is the definition of convergence now here is the algorithm i pick up a random from point from my data which could either be positive or negative so it comes from the union of positive negative basically all the data that i have i pick up a random point from there if the point is positive right and this is the condition which happens what does this tell me if the point was positive what did i actually want greater than zero but the condition is less than zero that means i have made an error so i have made an error then i will just add x to w i see a lot of thoughtful nodding and i hope you are understanding what is happening let us see so what is w actually a dimensional n dimension n plus one right because w naught is also inside there so actually there should be w naught also here right and what is x again n dimensional right and that is why this addition is valid so let us understand that w and x both are n dimensional now let us look at the other if condition can you guess what the other if condition is if x belongs to n and summation is greater than equal to zero then so that means you have completely understood how this algorithm works well that is so now consider two vectors w and x so remember what we are trying to prove is or get an intuition not prove actually get an intuition for why this works ok refer slide time three hundred and fifty-five so we will consider two vectors w and x and this is what my vectors look like very similar to the case that we are considering w0 to wn and one to n so this again x naught is just one now this condition that i have been talking about is nothing but the dot product how many of you have gone through the prerequisites for todays lecture ok good so it is just a dot product now we can just read write the perceptron rule as this instead of the dot product i mean instead of using that summation thing we can just say that it is a dot product now we are interested in finding the line w transpose x equal to zero so that is our decision boundary which divides the input into two halves now every point on this line satisfies the equation w transpose x equal to zero what does that mean actually so just a simple example is that if i have the line x1 plus x2 equal to zero then all the points which lie on the line satisfy this equation so you could have one minus one two minus two and so on but two two is cannot be a point on this line at every point lying on this line satisfies this equation so every point lying on this line actually satisfies the equation w transpose x equal to zero refer slide time five hundred and fourteen so can you tell me what is the angle between w and any point on this line how many say how many of you say perpendicular why dot product is zero so if the dot product is zero they are orthogonal so that means if i take this line then my vector w is orthogonal to this it is orthogonal to this point or this point to this point to every point on the line which is just the same as saying that the vector is perpendicular to the line itself right as simple as that so the angle is ninety degrees because the dot product gives you the cos alpha and that is zero right and since it is perpendicular as i said to every point of the line it is just perpendicular to the line itself refer slide time five hundred and fifty-eight so this is what the geometric interpretation looks like this is our decision boundary w transpose x and the vector w is actually orthogonal to this line and that is exactly the intuition that we have built so far now let us consider some points which are supposed to lie in the positive half space of this line that means these are the points for which the output is actually one now can you tell me what is the angle between any of these points and w or you guys are actually trying to tell me the angle we have got some measuring stuff no so i will give you three options i e equal to ninety greater than ninety and less than ninety less than ninety it is obvious from the figure now if i take any point which lies in the negative half space what is the angle going to be between them it is greater than ninety again obvious and it also follows from the fact that cos alpha is w transpose x by something and we know that for the positive points w transpose x is greater than equal to zero that means cos alpha would be greater than equal to zero that means the angle alpha would be less than ninety degrees and for the negative points w transpose x is actually less than zero that means cos alpha would be less than zero that means alpha would be greater than ninety degrees so it actually follows from the formula itself but it is also clear from the figure so keeping this picture in mind let us revisit the algorithm so this is the algorithm refer slide time seven hundred and thirty-two now let us look at the first condition which was this now if x belongs to p and w transpose x is less than zero then means that the angle between x and the current w is actually greater than ninety degrees but what do we want it to be less than ninety degrees and our solution to do this is but we still do not know why this works now anyone knows why this works so let us see why this works so what is the new cos alpha going to be it is going to be proportional to this it is going to be proportional to this i will just substitute what w new is fine that means if cos alpha new is going to be greater than cos alpha what is alpha new going to be it will be less than and that is exactly what we wanted this angle was actually greater than ninety degrees so you want to slowly move it such that it becomes less than ninety degrees it is not going to get solved in one iteration and that is why till convergence so we will keep doing this i will keep picking xs again and again till it reaches convergence that means till we are satisfied with that condition refer slide time eight hundred and forty-seven let us look at the other condition x belongs to n and w transpose x was greater than equal to zero then it means that the angle alpha is actually less than ninety degrees and we want it to be the opposite i will just quickly skim over this w minus this x ok i forgot to mention that this is actually a positive quantity i mean that is why that result holds that means cos alpha new is going to be less than cos alpha and this slight bit of mathematical in correctness i am doing here but that does not affect the final result so i will just gloss over that and you can go home and figure it out but still it does not take away from the final intuition and interpretation so now the new cos alpha is going to be less than the original cos alpha that means the angle is going to be greater and that exactly what we wanted refer slide time nine hundred and forty so we will now see this algorithm in action for a toy data set refer slide time nine hundred and forty-four so this is the toy data set we have and we have initialized w to a random value and that turns out to be this i just picked up some random value for w and ended up with this particular configuration for w now we observe that currently w transpose x is less than zero for all the positive points and it is actually greater than equal to zero for all the negative points if you do not understand w transpose x it is just that the all the positive angle points actually have a greater than ninety degree angle and all the negative points actually have a less than ninety degree angle so this is exactly opposite of the situation that we want and now from here on we want to actually run the perceptron algorithm right and try to fix this w how does it work remember we randomly pick a point so say we pick the point p1 do we need to apply a correction yes why because it is a positive point and the condition is violated so now we add w equal to w plus x and we get this new w so notice that we have a new w we again repeat this we again pick a new point and this time we have picked p2 do we need a correction yes at least from the figure it looks like the angle is greater than ninety so we will again do a correction we will add w is equal to w plus p this x is actually sorry p2 and this is where we end up refer slide time one thousand, one hundred and twelve now again we pick a point randomly n1 do we need a correction so this is what our w is this line here and n1 so we need a correction now what is the correction going to be it will be minus and then the w changes refer slide time one thousand, one hundred and thirty-two now we pick another point n3 do we need a correction no at least on the figure it seems like the angle is greater than ninety and we continue this refer slide time one thousand, one hundred and thirty-nine for n2 we do not need a correction now for p3 again we do not need a correction refer slide time one thousand, one hundred and forty-three the angle looks less than ninety sorry actually it is we need a correction the angle is slightly greater than ninety and this is our correction and now we keep cycling refer slide time one thousand, one hundred and fifty-two now as i keep cycling over the points i realize that i no longer need any correction refer slide time one thousand, one hundred and fifty-four it should be obvious from the figure that for this particular value of w now all my positive points are making an angle less than ninety and all my negative points are actually making an angle greater than ninety that means by definition now my algorithm has converged so i can just stop it so i can just make one pass over the data if nothing changes i will just say it has converged now does anyone see a problem with this it will never converge in some cases so can someone tell me why we are considering only cases where the data is linearly separable that we already assumed so what you are trying to tell me is that you are going over these points cyclically so let me just rephrase and put words in your mouth that what you are trying to tell me actually is that i take a point i adjust w but now for the next point i maybe go back to the same w because that point asked me to move it again and i keep doing this again and again and basically end up nowhere that is why this will never converge that is exactly what you are trying to tell me now that is exactly what i am forcing you to tell me so that is not the case this algorithm will converge"}
{"audio_filepath": "/content/Audio_trimmed_wav/Deep Learning(CS7015): A typical Supervised Machine Learning Setup.wav", "duration": 0.472, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module \u2013 thirty-two lecture \u2013 three a typical supervised machine learning setup we will start module two which brings us to a typical supervised machine learning setup this is a very important module please pay attention refer slide time twenty-one so now we have a sigmoid neuron we have taken care of the fact that the perceptron was a very harsh function so we have a smooth function so things are fine now what next where do we go from here what is my next topic going to be yes a lot of you are giving the right answers we need to learn these weights it does not help just to define the function this function depends on certain weights and now i need to give you an algorithm which will help you to learn these weights now remember when i talked about perceptrons before giving you an algorithm what did i revisit what did i talk about the error surfaces and then i had motivated from there that our goal is to find a set of weights which give us close to give us zero error in that case or in general\u2019s speaking generally they should give us a minimum error they should help us to minimize the error rate so i need to set up that similar story here so we will again revisit the concept of error refer slide time one hundred and thirteen so now in the case of perceptron i had shown you this figure which they were this data is not linearly separable which is obvious and i told you that perceptron cannot handle this data but what do i mean by it cannot handle this data it cannot give zero error but what would happen if i run the perceptron algorithm on this take a guess what does the perceptron algorithm do fine and i could convergences my condition i could make that condition a bit loose what is a valid convergence condition that you would lose here use here till almost all my points are separated properly so instead of aiming for one hundred percent separation i could have a threshold which says as long as ninety percent of the points are separated i am fine with it that looks like a reasonable thing to do so now if i run the perceptron algorithm with that condition what do you think will i get as a decision boundary everyone has a picture in mind ok let us see does this match what you had in mind roughly of course there many things possible but it will basically pass through this now what is happening here what is the problem there are three blue points which are wrongly classified and three red points which are wrongly classified but in most real world applications we will find that this line is not too bad you could live with this error this is probably three out of thirty on both sides which is roughly ten percent error unless you are using it when some mission critical applications or in health care where it is a life and death situation or something in most cases you could live with this right so if you are trying to predict whether people will vote for a particular party if you make this kind of error it would be largely ok unless it is a very close election but largely it would be ok so we could live with this kind of errors in most cases so from now on we are not going to be too optimistic and if you are going to say that there would be some error but my job is to find the weights such that my error is minimizedi want the minimum possible error that i could get is that fine so again whatever weights we want to learn we are going to be driven by some error function and we would want to minimize that error function refer slide time three hundred and fourteen so this brings us to a typical machine learning setup which has the following components so this perhaps is the most important slide in the course and i will say this at least for one hundred other slides in the course but at least for now this is the most important so you are given some data xi yi and you are given n such elements right so let me just elaborate on this and give me i will give you some instances of this let me give you some instances of this right so one thing we say i already told you was this so this is my x and this is my y so one example which i gave was about movies so this was genre actor and critics rating and so on this is one instantiation of this problem i could also give you another instantiation which was i just told you oil right so this is how much oil can i get and here my factors were salinity density and so on there were many other factors so this was my x again x belongs to rn where n is some number integer and another example could be say fraud detection so i have a customer i am a bank i have a customer who has bought some credit card and i want to predict whether he or she would commit a fraud and i would look at factors like what is his occupation maybe salary maybe family size and so on there could be various factors which i could look at so here again this becomes an x ok and you could think of various such examples right where you are given an x and you are given a y ok so this is the data that you have now what is machine learning where does machine learning fit into this so we know that there is some relation which exists between y and x in each of these cases all of us are convinced that there is some relation so whether a person would commit a fraud would depend on these factors it is reasonable to assume that it is not a very wild assumption whether you would find oil at a location would depend on some of these factors and it is related and similarly for the movie case so there exists some true relation between x and y such that if i plug this value of x into the relation it would give me the value of y there exist a true relation this true relation could be governed by various things right it could be governed by physical laws example in the oil mining case it could be even governed by biological laws again the marine life in that location and so on it could be governed by economic law\u2019s it could be covered by psychology right we do not know why a person cheats what is his function that he is using when he cheats and so on right so these could depend on various factors but we all agree that some function exists hence we get these values for this particular input for every input we get a certain value so there is some function which takes us from the input to the output we do not know what this function is we never know in practice it is a very very complex function is all that we know we do not know this exact function if you knew this exact function then there is no problem to solve we just use that function and you can predict how much oil and all of us can become billionaires so that is not the case we do not know what this function is so then what do we do in machine learn we make an assumption ok we make an assumption that there is some function which takes x to y and this function is governed by some parameters and this is our approximation of how the real world works and now under this assumption we want to predict the parameters of this model given the data now let us take a very simple case where we could assume that y is equal to wx plus b i am taking this in the scalar single dimensional case now how would you estimate the values of w and b oh come on if i give you two data points you can estimate the value or should i write it that would jog your memory right this is how we all learn right so m and c you can estimate if i give you two data points so that is the simplest case now we will make similar assumptions but more complex functions and just as we could estimate m and c from the data we would expect to estimate ws also from the data so that is what the machine learning setup is so let us see refer slide time seven hundred and forty-eight so the model when we talk about a machine learning model it is our approximation of the relation between x and y and we are free to make any such approximation so i could say that this is what i think is the relation between y and x and which is governed by some parameters w do you know what is this function have you seen this before no not sigmoid which model is this logistic regression ok but i could also have made a different assumption i could have made this assumption what do i get linear regression ok please note that this error on the slide ok and i could make some other assumption i could assume that y is actually a quadratic function of x i am free to make any assumptions the only thing i need to ensure is there is some parameter involved what is wrong with making this assumption if this is valid is this also valid if not why there are no parameters so no not for any x we will get the we will it will depend still depend on the value of x if i plug in different values of x i will still get a different output there is nothing to learn what do i do with all the data that i have there is absolutely nothing i can use it to learn i have just said that y is equal to one over one plus e raised to minus x i can ignore all the data that you had given me whenever you give me a new x i will just plug it into this formula and tell you the answer and that is bound to be wrong because i have not adjusted this formula now once i put in the ws it gives me this degree of freedom where i can now adjust the formula i can learn the ws in such a way that my predicted y\u2019s are very close to the actual y\u2019s so that is why we need always need a parametric form of course there is nonparametric learning also but i am just saying in this supervised setup we are thinking of models whether you have parameters so you have the data you have the model the model always has some parameters refer slide time nine hundred and fifty in all of the above cases w is a parameter right either the small w which is a vector or the capital w which is a matrix right so notice that this is a matrix this is one cross n n cross n and n cross one now how do we learn these parameters that is the question that we need to answer how do we learn these parameters we are convinced about two things that we never know the true function so we come up with an approximate function and we have to insert some parameters in that function so far good now i have to be able to learn these parameters now for learning these parameters we have something known as an learning algorithm so did you see any learning algorithm so far perceptron learning algorithm right so you already saw the perceptron learning algorithm and it was able to learn the weights for a perceptron refer slide time one thousand and forty-three there are various such algorithms today we are going to learn one such algorithm which is gradient descent now any kind of learning what is it driven by learning is driven by errors objective function and so the analogy which i like to give is suppose you are trying to learn trigonometry you have a chapter that is your training data the chapter has a lot of formulae that is your training data now what is your objective there are two objectives actually i will tell you the easy objective the training time objective is that once you read to the chapter a few times at least whatever formulae are given in the chapter you should be able to produce the correct output for that so if i ask you what is sine square theta plus cos square theta you should be able to answers them and you should be able to give me the correct answer so in other words you are trying to minimize the error on the training data whatever training data you have which is the chapter content you want to make zero errors in anything which is given in the chapter that is your training error of course there is also something as known as a test error because after you have learned the chapter i will give you an independent set of exercises which might contain questions which are not seen in the textbook earlier so you would have seen sin square theta plus cos square theta but now i could ask you some other formula which you should be able to give me answers if you have learned properly right so now right now we are just talking about the training error that means getting all the formula in the chapter correctly and our chapter is actually the training data which is given to you this is what we are reading so this always going to be driven by an objective function and our goal is just as we wanted to minimize the errors that we make on the formula given in the chapter we want to minimize the errors on the training data is this set up absolutely clear to everyone anyone who does not understand this has any doubts so this is something this is the same framework that we will use again in lecture eighteen nineteen twenty and so on to explain some more complex models so you have to absolutely make sure that you understand this it is not very difficult but just make sure you understand this fine so let us concrete at this a bit more refer slide time one thousand, two hundred and forty-four and we will consider our movie example and try to fit that into this framework so what is our training data there they are given movie comma like dislike and when i say movie i am just using a shortcut it is actually all the details of the movie genre actor director critics rating and so on that is our input and our output is the like dislike value what is a model that i chose what is a model that i chose i do not know what is my true relation between when i like a movie or not but i made this approximation that this is how y depends on x and i made sure i introduced some parameters there i could have chosen some other functions also but i chose this now the parameter is w this should be bold w the learning algorithm that we are going to use is gradient descent which we will be seeing soon and what is an objective function here can you tell me a formula so we have been talking about it in terms of english that i should be able to get predictions which are as close to the true prediction can you put it into a formula y i minus y i hat where hat is the prediction this is the prediction so that is y i minus y i hat that should be minimized is that fine whole square of that so why do you square it so that is correct so for all the training points n training points i want to minimize the square difference between y i the true prediction and the prediction sorry the true value and the predicted value is that fine and why do i use squares differentiable is one the other thing the positive errors and the negative errors should not cancel so it would be happen that on some movies i make a positive error of five right that means the actual label should have been five and i gave one on some movies i make a negative error of five and these would cancel each other and i will get the false impression that i am making zero errors but once i square the values the negative values also become positive so this cannot happen right so that is why we always use the squared error function and also this is differentiable which is more important now the learning algorithm should try to minimize this particular quantity ok so this is a typical machine learning setup almost any supervised learning problem that you see you could cast it in this framework change the y hat function appropriately change the parameters appropriately maybe use a different learning algorithm depending on the problem that you are trying to tackle and you should be able to fit it into the same thing is that fine ok at least for this course everything that we do we will largely be able to fit it into this framework refer slide time one thousand, five hundred and twenty-eight"}
{"audio_filepath": "/content/Audio_trimmed_wav/Backpropagation: Computing Gradients w.r.t. the Output Units.wav", "duration": 987.797, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras backpropagation computing gradients w r t the output units module \u2013 forty-five lecture four now we go to the next module where we will first see how to compute the gradient with respect to the output units well that was the first guy in our chain right that is the first person that we need to talk to refer slide time twenty-three so that is the part that we are going to focus on refer slide time twenty-six so this is the output and when i say i want to compute the gradient with respect to output unit what do you actually mean what is the quantity that i am looking for i will help you out actually what i meant by output unit is this entire thing right so i actually meant al\u2019s ok but it is it is a fair answer and even y hat is a fair answer ok in fact am going to start with y hat and then go to al so i will have to start with this guy and then come to this guy refer slide time fifty-four so this is the loss this is y hat which is equal to y one hat y two hat up to yk hat so these are the k values that we have here and we are looking at cross entropy that means we are looking at the classification problem right so we have got a distribution over the k classes that is what y hat looks like and we know that one of these guys is the right class maybe say y two so the loss function is minus log of y hat two because two is the correct class in this toy example that i am considering ok so the loss function i am just repeating the definition right that is how the loss function is refer slide time one hundred and thirty now oh god so again this is what our y hat looks like ok now i want to compute the gradient with respect to any of the output units right so it could be y one y two y three y four up to yk right so this i actually can take values from one to k in this case one to two right ok now can you tell me what is this loss ok this much is fine can you tell me what is this derivative minus one by minus one by y hat l if y is equal to l student refer time two hundred and eight and zero otherwise how many of you get that cool ok so it is a very simple thing that you can think of this as z and this is y only if z is equal to y then the derivative would exist otherwise it is going to be zero right ok so how do i write this fe part using student refer time two hundred and twenty-seven how many of you have seen indicator variables before good so this is what you are telling me right it is going to be minus one by y hat l if i is equal to l ok and if i is not equal to l then these two things are not related it this is a function of something else and you are taking a derivative with respect to a different quantity so it is a constant with respect to that quantity and the answer would be zero ok now i am going to write this as this right so this is the same as saying so this variable actually this is known as the indicator variable it takes on the value one if the condition in the bracket holds otherwise it takes on the value zero so this is exactly i am writing exactly this but in a more compact manner ok is that clear to everyone refer slide time three hundred and fifteen so this is what the quantity this is the quantity that we have computed with respect to one of the output units ok so this is what derivative partial derivative gradient how many of you say derivative no one likes derivative partial derivative that is always the safest choice partially fl right and gradient oh there is one brave soul who say is gradient do not worry well fix that ok so this is the partial derivative y because my y hat is actually a vector and i am taking the derivative with respect to one of those guys ok now if i want the gradient with respect to y hat what would that look like a vector which is a collection of student refer time four hundred and one partial derivatives so let us see this is the quantity that i am interested in am interested in the gradient of the loss function with respect to the vector y hat so remember the vector y hat is y one hat y two hat up to yk hat right so this gradient is going to be a collection of the partial derivatives with respect to y one hat y two hat and so on now what is each of these quantities so it is simple right so this quantity the derivative is either going to be zero or is it going to it is going to be one by y one hat right if l is equal to one right and that is exactly what i have done so now how many elements here are actually going to be nonzero at a time how many of these going to be nonzero one which one student refer time five hundred and four the one corresponding to l right everything else is going to be zero so this is a dash vector y not vector ok so now am going to write one hot vector like this what have we done ok where el is what one hot vector such that it is l th entry is one ok that is what am going that is how am going to define e l is that fine with everyone ok and so you see the story how did how we went about computing this we started with a partial derivative with respect to one of t guys right we found a formula for y i we saw that this formula is generic enough and so now we can compute the gradient which is a collective of all these yis where i ranges from one to k right and then we just put that in a gradient vector so this story is going to repeat throughout the lecture where we try to compute the gradient with respect to one guy and then generalize oh sorry we compute the partial derivative with respect to one guy and then generalize and try to find the gradient fine ok refer slide time six hundred and eighteen refer slide time six hundred and nineteen so what if i what do i have so far i have this quantity what does till which part of the diagram am i currently the dash green part dark green part i am till here i need to go till the light green party that is collectively the output unit ok although i have divided into two halves but when i say output unit i mean that output neuron right complete neuron so what i am actually interested in is these quantities or more specifically ok this is what i am interested in what is this one of those guys right this al is actually al1 up to alk right so this is one of those guys so this is going to be the gradient or this is going to be the derivative a partial derivative sorry ok now what do how do we proceed from here refer slide time seven hundred and twenty-six now i will again have to compute this you already know that good but before that i want you to answer one question right so y hat l what is y hat l it is the output corresponding to the correct class does it depend on an arbitrary al i so in the previous thing we saw that only when i is equal to l there is a connection in this case is there a connection always or only when i is equal to l student refer time eight hundred and two always why softmax so student refer time eight hundred and four denominator has all the ali\u2019s right so this is there it is y hat l in the numerator of course it only has this unit which corresponds to the l th probably did not choose my variables very well so l th component of a capital l right and but in the denominator you have the entire sum which means that every output guy here each of these dark green guys depends on each of the dash green guys light green guys good so that is at least settled that we always the we can always compute this partial derivative we do not need an if else here there is nothing like l is equal to i then what will happen it will always have this partial derivative refer slide time eight hundred and fifty-three so we will now derive the full expression for this so this is what we are interested in is this fine so this is a function of the form so you are taking how do i say this so this is log of a function so first you will take the derivative with respect to log and then push the partial derivative inside right so that would be minus one by y hat l and then the derivative with respect to y hat l now what is y hat l the softmax function right so it is the l\u2019th entry of the softmax function applied to that output vector what is the output vector al right so it is the l\u2019th entry of the softmax or l\u2019th entry of the function applied to the output vector so this was our al what is our output right so now one of these guys here is the l th guy and one of these guys here is the l\u2019th guy right so what you do is you take this you apply the softmax function to it which again gives you a vector and now you are interested in the l\u2019th component of that vector that is what this quantity means it should be clear now refer slide time one thousand and twenty-five now i will just do some simple math stuff here and we should be able to derive this is it fine am just replaced by the actual softmax formula this is a derivative of the form u by v right what is the formula for that yeah it perfectly right yeah so this is what it would be right i mean it is you all know this i am not going to spend time on this so now am just going to substitute the values here yeah it is getting a bit nasty but it is not very difficult right so so this so this is our g of x so am taking the derivative of that then this is this one over h of x you can just figure it out right anyway it everyone just read this for a few seconds and let me know if this is not clear this is g this is h in this formula right have just substituted the gs and hs in this now what is this quantity going to be it is derivative of the form e raise to x right so it is e raise to x always student refer time one thousand, one hundred and thirty-three if i is equal to l right so now we have this dependence because we are looking at a numerator but the numerator only depends on the l th entry right so now you are trying to take the derivative of the l th entry with respect to some arbitrary i th entry so only if l is equal to i you will get the derivative right refer slide time one thousand, one hundred and fifty-two now what about this how many terms in the summation would remain student refer time one thousand, two hundred and two one which one student refer time one thousand, two hundred and four where i dash is equal to i right so the i\u2019th guy would remain the rest of it is straightforward right this square i have just divided into two parts ok ah now let us see can you simplify this because i cannot ok can you simplify this what is this student softmax softmax and which entry of the softmax student refer time one thousand, two hundred and thirty-six l\u2019th entry i\u2019th entry l\u2019th entry with the saw with the indicator variable but what is this this is our input hidden layer output so ok now let us see what is the next step this is should have been y hat i but y hat is equal to f of x right so we can fix this unit so ok fine so we have actually what do we have now we have the derivative of the loss function with respect to the i\u2019th unit of the output layer right and which part of the output layer the pre activation pattern ok now what am i going to do i have a formula which tells me how to compute this what was i actually interested in so now how am i going to go from here to there i just put all the partial derivatives into a student vector vector and that vector is the student refer time one thousand, three hundred and fifty-eight gradient good refer slide time one thousand, four hundred so we have this one formula it is ok if some of you did not get this derivation right it is very very straightforward if you go back and look at it i am pretty sure you will get it is nothing in this is very simple elementary stuff right except for some degree here and there ok so now what would this look like we should add actually l theta here this would look like a collection of all the partial derivatives we have a generic formula what will we do now what is the first entry minus in indicator l equal to one minus y hat one which is the variable that we are indexing over i right not l oh god oh we are indexing or ok have i goofed up oh that is wrong is it oh yeah that is wrong fine then this is fine we are indexing over i and then we can do this now can you simplify this i am looking for ok this is the element wise difference of two student refer time one thousand, five hundred and thirty-eight of the indicator vector and student y hat refer slide time one thousand, five hundred and forty-four y hat oh hey we should change all this y hat is equal to f of x right but i just want it to be consistent as y hat so is this fine this is a simplification fine right so we have come a long way right you have finish this part ok we have got the gradients with respect to the output units ok this much part is a clear to everyone moduler bit of the math which you can go back and look at it this entire derivation is fine but you get the concept right that we start with one unit from there grow the gradient then keep going applying the chain rule so we started with the dark green guys and then went to the light green guys now we have the derivative with respect to the entire light green vector and that is what we had started off with that we wanted the gradient with respect to the output units"}
{"audio_filepath": "/content/Audio_trimmed_wav/Deep Learning(CS7015): Learning Parameters: Gradient Descent.wav", "duration": 1840.422, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module thirty-four lecture three learning parameter gradient descent in this module we will talk about gradient descent refer slide time twenty-two so what we want to do is find a more efficient and principled way of navigating the error surface refer slide time thirty and the goal is to find a better way of doing this refer slide time thirty-five so let us start by setting up things we will define some notations and some parameters and so on and from there on we will try to come to the algorithm ok so my parameters in this case were w comma b what i am going to do is i am going to put them into an array or a vector right and call that vector as theta so theta is the vector of parameters and theta belongs to r r what r2 right there are two parameters here so it is a two dimensional vector refer slide time one hundred and eight now what i want is again what i will do is i do not know what the value of w comma b is so i started with a random guess so that is always going to be my starting point i will always start with a random guess and from there on move on to good values now once i have started with a random guess i want you to tell me some changes that i can make to w and b so that i land up in better situations right that means i land up in situations where the error is less is that fine so that change in w and b i am going to call it as delta w and delta b and that again is a vector which is storing these two values so this is the picture right i want to take theta and i want to add a small change to it so this is my theta this vector is actually theta right this is the theta vector i want to add a small change to it which is again a vector this is delta w comma delta b such that i will get a new value for theta new so theta new would be what actually theta new is equal to w new comma b new is that fine that is what theta new means refer slide time two hundred and seventeen now what has happened is actually when i have added delta theta to theta i have moved in the direction of delta theta i have come from here to here now i am going to be a bit conservative and i am going to say that while i am ok in moving in the direction of delta theta i do not want to make a giant stride what i will do is i will just move by a small quantity in that direction so this delta theta is this large magnitude so all i am saying is that i will not i move in that direction i am fine with that but i do not want to make a giant stride i will just take a small stride in that direction so eta is a scalar which actually scales down delta theta so now if i am going to take only a small step in that direction instead of this large change i will just get a smaller change theta new so red the red vector is actually going to be the movement which i make that is the new value of theta so theta new is equal to the original theta plus a small step in the direction of delta theta so everything is clear you are done we are done with gradient descent what is missing what is delta theta right i am telling you i want to move in a certain direction but what is the right delta theta to use how many of you know the answer to this what is the answer move in the direction opposite to the gradient why where does that answer come from not the ml class folks how many of you know why we need to move in the direction opposite to the gradient why ok we will see ok so that is the question that we need to answer if i give you an answer to this question then what is it i am doing i am giving you a principled way such that you start from a random value of theta move in certain direction and you will ensure that your loss has decreased and then you have to keep doing this right so that is the set up and the answer to this comes from taylor series refer slide time four hundred and eleven so now what i am going to do is i am going to give you the right direction delta theta fine and for ease of notation i am going to call it as u so remember what this delta theta is what is it change in w comma change in b so it is a vector in r2 remember that ok i am just going to call it as u now this is what taylor series tells me what it tells me is that if i am at a certain value of theta and if i want to change that value a bit then what is going to be the new value of the loss function or any function for that point and this is the formula for that ok now what is let us see what are some quantities here what is this quantity scalar vector matrix scalar this vector we just did that right it is a vector what about this what is this quantity actually gradient what is the gradient what is the gradient no you are telling me how to use the gradient i am asking you what is the gradient you are giving me absolutely correct and absolutely useless definitions that is a very good answer ok so now what i am going to do is i am going to digress a bit and i am going to tell you something about derivatives partial derivatives and gradients and then we will come back to this ok so now suppose you have a function l this is l in my handwriting this function of w and say this function is w square ok now what is what is this called a derivative of the function with respect to w this is the derivative and you know this is 2w ok now suppose i have a function b square now what is this quantity is a partial derivative of the function with respect to w why partial because it is considering b as a constant and taking the derivative with respect to only one of the variables right this happens to be and what is this quantity oh sorry so is w comma b right this is the partial derivative with respect to b ok now can you tell me what is a gradient the gradient is nothing but it is just these two partial derivatives taken together and put into a vector right now suppose i had a function which depended on hundred variables what would the gradient be size of the gradient r100 it would lie it would be a hundred dimensional case ok so now can you tell me with this evidence in knowledge but this primer can you tell me what this is this is a gradient vector which is right there in front of you in a red ink this is what it is right fine everyone ok with that so actually the right way to write this and probably we need to correct in the slides would be theta so remember that theta is equal to w comma b so this is the derivative of l theta with respect to theta which is nothing but the collection of the partial derivatives with respect to the components of theta is it fine so everybody understands what is a derivative partial derivative and gradient ok fine so now the gradient is a vector in this case fine ok refer slide time eight hundred and twenty-five so now what is this quantity it is a no it is what is this the dot product between these two vectors ok fine now one last thing and many more things actually so what is this square of the gradient this is not the square of the gradient what is this hessian fine everyone knows the textbook what said can you tell me what does it is a scalar vector matrix matrix what is the size of this matrix two by two what are the elements of this matrix second order partial derivatives right so it is the gradient of the gradient right is that fine so what does that mean you had this gradient this is the gradient now you want to take the gradient of this again with respect to w comma b right that is what this means it is a gradient of the gradient right so what that means is we will take the gradient of the first quantity again with respect to w so that would be dou square by dou w what would this quantity be what would this be is that fine and you can fill in this quantity right so now it is clear what the hessian is it is the derivative of the derivative and it would be a matrix ok is that clear to everyone so i have a habit of doing a lot of these basic stuff i know that the top twenty percent of the class gets really pissed off when i do this but as a philosophy i teach for the bottom thirty percent of the class so i do not mind that and the other thing is i use slides so i do not write a lot of math so i can cover a lot of material despite doing all this basic stuff right so i am going to stick to that what i am trying to say is that write this in the feedback that you do not like this basic stuff but it is just that i am going to ignore that feedback i mean just being honest right so i like doing this because it just takes me ten minutes to do this and for the rest of the class i do not have to look at blank faces afterwards right so it really helps me a lot fine so is that all clear all the quantities here are clear so now so this is the gradient this is the hessian and now eta remember what did we say about eta it is a small quantity and what do we do with small quantities always in maths we ignore them so once we take their powers you are always ignore them whether it is correct or not who cares i mean someone has told it it is good to ignore so we will ignore it right so now all these higher order terms we can ignore right that means i will only consider this fine so let us again look at what the setup is the setup is that i have some value of theta i want to move away from that value such that what do you say about this loss compared to this loss i will call this the new loss and i will call this the old loss what is the relation between them the new loss should be less than so if i or someone gives you a u i am not getting ok someone gives you this u then what does what when would you say it is a good u refer slide time one thousand, two hundred and twenty-eight if this condition holds everyone agrees with that right so i have found a good direction to move in if this condition holds now this condition actually implies that this condition should hold right this is l theta plus eta u right so if i just do minus here i get this right so this quantity which should be less than equal to zero implies that this quantity should be less than equal to zero and remember eta is a positive constant ok why cannot it be negative why because you wanted to take a small step in that direction if we make it negative we will do what we will reverse the direction we do not want that as of now right so eta is that for a positive quantity so that means this quantity should be less than zero is it fine with everyone refer slide time one thousand, three hundred and twenty-nine so so far after all this story what we are left with is this condition should hold for the u that i am trying to choose so that i can be sure that i have chosen the correct u right and the definition of correct u is that the loss at the previous step the loss of the new step should be less than the loss at the previous step is that fine so that is what we have arrived at now what is the range of this quantity that is why i asked you what is this this is a dot product i will leave it at that so now you tell me what is the range of this people from the ml class cannot answer did i cover this in the ml class no ok fine what is the range of this not a very hard question plus or minus student refer time one thousand, four hundred and twenty-five mod of u refer time one thousand, four hundred and twenty-six very good how many of you understood that answer he said plus or minus mod of u into mod of gradient the gradient vector right why is it so easy let beta be the angle between u t and this between sorry it should not be u transpose between u and the gradient then we know that this condition holds cos beta is given by this quantity and we know that cos beta lies between minus one and one ok now if i just say that this quantity is equal to k then i can just get this condition now let us see what are we trying to do we are trying to find a u such that this quantity is negative we are trying to find the use such that this quantity is negative now i just stop at negative we would like to make it as negative as possible right because the more than negative it is the more will be the decrease in my loss function right because this quantity tell me tells me how much my loss decreases so the more the negative it is the more the loss will decrease so let me make it as negative as possible now what is that value when will that happen when alpha is you know the answer you started with the answer student refer time one thousand, five hundred and fifty-four no what is that one phrase which you have marked up move in the direction student refer time one thousand, six hundred and seven ok now think of that student refer time one thousand, six hundred and nine what would happen when this is the most negative it can be what would the angle be student refer time one thousand, six hundred and nineteen one hundred and eighty degrees how many of you get that because when this is the most negative that means the cos beta is actually minus one and when is cos beta minus one when the angle is one hundred and eighty degrees that means u should be such that it is at one hundred and eighty degrees to the gradient hence repeat the phrase student refer time one thousand, six hundred and forty-two move in a direction opposite to the gradient is that fine everyone gets it now why you need to move in the direction opposite to the gradient refer slide time one thousand, six hundred and fifty-three so this is what the gradient descent rule is you are at a particular value of theta you want to move to a new value of theta such that your new loss is less than the current loss what gradient descent tells you is move in a direction opposite to the gradient so are you fine with this now with gradients i have come to scalars but i will just explain what i have written here so this quantity is nothing but theta t plus one right is equal to theta t right and what is this right so the new theta is equal to the current theta minus why because we want to move in the direction opposite so it is basically theta t plus one is equal to theta t plus eta into a negative direction right the direction negative to the gradient hence you get that minus one now what are these quantities let me just take that carefully so this quantity is gradient of the loss function with respect to w sorry the partial derivative of the loss function with respect to w evaluated at w is equal to wt and b equal to bt what does that mean so remember when you are dealing with derivatives as always a formula and then a value add that at a particular value so what is the derivative of x square with respect to what does not matter 2x so derivative of x square with respect to x is 2x what is the value of this derivative at x equal to one two right so you see the difference you have a formula which is 2x now you substitute in a particular value and you get the value at that particular value ok so that is what this means because you are already at w t comma b t now you cannot subtract a formula from here right you have to put subtract a value so you know what the formula is you plug in the values of wt comma bt get that value and subtract it from your current wt is that fine so everyone completely understands what is the gradient descent rule is fine refer slide time one thousand, nine hundred and fourteen so now we have a more principled way of moving in the w b plane what do i mean by that remember this was our w b plane this was our error this is something what our error surface looked like it was this flying carpet i was randomly moving on the w b plane earlier right and trying to guess what the errors or trying to compute the error and then settle for a particular value now i have a more principled way of moving in the w b plane i know what is the next step based on the current step i just need to move in the direction opposite to the gradient so let us try to so this is what it tells me for one step but i need to keep doing this till what is that golden word student refer time one thousand, nine hundred and fifty-eight convergence right i have to keep doing this till convergence ok refer slide time two thousand and two so let us create an algorithm out of this rule i will start a time step zero i will do this for some max iterations instead of saying till convergence i will do it for some iterations at every iteration i will this is how i will update my weights i will take the current weights subtract the gradient from that and get the new weights i mean not subtract the gradient subtract this quantity and get the new weights so now is everything clear is the gradient descent algorithm done can you do it for the toy network which i had is there something still missing student refer time two thousand and thirty-eight eta is fine we will take a small value one or something actually not told you what these are right i means to write it you know these are derivatives but what is this actually ok so let us see that now so that is what we are going to see next refer slide time two thousand, one hundred so now we want to find out we are in the car quest is for this delta sorry the partial derivative with respect to w and partial derivative with respect to b that is the thing which we had plugged in the formula but we do not know what that is right so we need to find that out so now for simplicity let us assume there is only one point of it which is x comma y so earlier we had this x1 y1 and x2 y2 now i am just assuming there is only one point which is x comma y refer slide time two thousand, one hundred and fifty so now what is a loss function earlier i had this summation over i equal to one to two but i have just one x comma y so i will just use that this is what my loss function and what are the quantities that i am interested in finding one is this the partial derivative of this loss function with respect to w refer slide time two thousand, two hundred and eleven so let us do this lets actually derive this so this is what it looks like now you have to help me in deriving this what will i do first student refer time two thousand, two hundred and eighteen tell me the next step student refer time two thousand, two hundred and twenty-three two into f of x minus y and push the gradient inside of course the derivative is that fine anyone who has a problem with this next y is a constant this is the true i remember so that is why this is a constant is not the predicted y now this quantity what is f of x actually student refer time two thousand, two hundred and fifty-one sigmoid function right so i will just write it now this is the quantity that i need the derivative for so i will just write it here what is the next step this is of the form one over x so what will it be student refer time two thousand, three hundred and four minus one over x square and then you put the derivative and say it is that fine now the quantity inside is of the form e raise to x so the derivative is e raise to x and you push it inside is this fine so this on slide should come both these are coming together so is that fine now what is this actually student f of x f of x what is this student refer time two thousand, three hundred and thirty-two this is actually one minus f of x just take my word for it for now you can go home and work it out right so this actually if you do one minus this and do some trickery you will get to this quantity right so what you get is a very simple formula f of x into one minus f of x into x i am going to substitute back here so now i exactly know what the partial derivative of w is refer slide time two thousand, three hundred and fifty-seven so there is only one point then this is what the partial derivative with respect to w is going to be of the loss function right if there were two points what would happen if there were two points my loss function was this is a sum of two elements and i am taking some derivative of a sum i will get a sum of derivatives right refer slide time two thousand, four hundred and twenty-three so how many of you will not cringe if i say this is the answer anyone who has a problem with this you get this how many if you do not get this how many of you get this good fine now can you do a similar thing for b can you tell me the answer without actually deriving it student refer time two thousand, four hundred and forty-one i can perfectly understand what you are saying student refer time two thousand, four hundred and forty-eight x would not be there right because this last x that you see here came because w into x was there but b we are not multiplying x so what we will get is this you can go home and check refer slide time two thousand, five hundred and twelve so now we have everything that we need now we actually have everything that we need ok no more trick questions so now we will write code to do this ok we will actually implement the code and see what happens so these are the two data points that i had five comma two and twenty-five comma nine the first thing which i need is something which can implement the sigmoid function so this is one over one plus e raise to minus w x plus b is that fine now i need something which can compute the error so this is summation of half into f of x minus y the whole square i go over all the data points summation of half into f of x minus y the whole square is that fine now what i will do is i will take this try out a lot of values of w comma b and plot the error surface ok but this is only for illustration in practice i will not do this we just know that this error surface exist i just want to verify that whatever algorithm i come up with does not efficient navigation of this error surface that is what i want to verify that is why i am plotting this next time you need a function which can compute grad of b we just saw this on the previous slide this is f of x minus y into f of x into one minus f of x right simple everyone is fine with this then i need a function which can compute the grad with respect to w same thing except that i have this x at the end so i have all the ingredients in place now what would i do what is the next thing that i will write the main loop right i will write the main loop now so this is what the main loop look like looks like i start with some random initialize for w comma b remember that our initial theta which is composed of w comma b is going to be some random guess so i started with the random guess which is minus two comma two i have chosen eta to be one that means i am not going to be conservative i am going to move in the direction of the gradient if i chosen at one and one i would have been conservative and i am going to run this till one thousand epochs which is my notion of conversions now in each epoch what i am doing is for every data point so remember that this gradient with respect to w was a summation of i equal to one to two and that formula right so for each data point i am computing the grad adding it right so that is the summation part similar thing i am doing for b once i have computed the gradient which is the summation quantity i am just moving in the direction of the gradient is that fine everyone understands the code it is simple python code and it does exactly what i had shown in the pseudo code now let us execute this code and see what happens so i will start with my random point which was minus two comma two and now i am going to actually run this code and keep plotting what happens on the figure so just pay attention fine so now here is how the code is running see what is happening what is happening actually so at every point i am changing my w so that i am moving in the direction of the gradient i keep doing that as i keep doing that my error keeps decreasing why because that is exactly what we got from taylor series that if we do this the error is bound to decrease right and then we keep doing this and after a few iterations we will actually reach almost the value which is the zero error right and this same thing would happen if you start from anywhere else it will keep moving in a principled way and reach the low error configuration now some of you would say that maybe this was the shortest path right it could have just rolled over from there but that is not a principled way of doing that right we the principled way of doing it is to move in the direction of the gradient you might take a longer route but reach your destination taking shortcuts is always risky in life as well as here so so do not please this is an advice for error assignments and so on so this is the more principled way and we will reach the solution so that is what is happening here so we have actually derived everything that we needed and this is all you need to write for gradient descent for this toy example that you had now answer this question now suppose i had hundred such variables instead of w comma b i had hundred such variables what would happen you do not have to visualize it student refer time two thousand, nine hundred and forty-eight in terms of the code student refer time two thousand, nine hundred and fifty-two i will just need to have these functions for all of those i will have to calculate it by hand but still doable it is just a lot of tedious work of course later on we will see a more refined way of doing this where we can do a lot of these computations at one go so we can directly start operating in vectors as opposed to scalars here i am treating w and b separately here i could have actually had a function which tells me grad of theta directly right and later on we will see something like this ok but for now the code is still running here refer slide time three thousand and twenty-four now it suffices so later on we will see gradient descent in more detail in the course and we will also see a lot of variants of gradient descent but for now it suffices that we have an algorithm which can learn the parameters of a sigmoid neuron so just as we had the perceptron learning algorithm we have the gradient descent learning algorithm which can help us learn the parameters of the sigmoid neurons starting from random values and it gives a principled approach for doing that"}
{"audio_filepath": "/content/Audio_trimmed_wav/McCulloch Pitts Neuron, Thresholding Logic.wav", "duration": 778.667, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module twenty-two lecture two mcculloch pitts neuron let us start with module two which is about mcculloch pitts neuron refer slide time seventeen so as we are done this during the history lecture way back in one thousand, nine hundred and forty-three mcculloch and pitts they proposed highly simplified computational model of the brain so now let us see what\u2019s the motivation we know that our brain is capable of very complex processing it\u2019s capable of taking a lot of inputs from various sources and then help us taking various decisions and actions now what if you want a computer to do this we want a module which is very similar to how the brain works or at least how we think the brain works which takes a lot of inputs and then does some processing and helps us take a decision so what they proposed is this model which will take a lot of inputs and these inputs are all binary all these inputs that you see here these inputs are fed to this mcculloch pitts neuron which is an artificial neuron and it is divided into two parts so the first part collects all the input so remember you had these dendrites which were taking all the information from everywhere so this just collects all the information and then the second part is aggregation i have collected a lot of information from all the sources now the second function will decide what this aggregation is and based on that it will take a decision whether to fire or not so the output is again boolean if it\u2019s zero then neuron does not fire if it\u2019s one the neuron fires so let us take a concrete example so suppose i am trying to make a decision whether i should watch a movie or not so x1 could be is the genre of the movie thriller similarly there could be another variable say xn which says is the actor matt damon so these are all various such factors that i could take is the director christopher nolan the music given by someone and so on so all these are probably factors which help me decide whether i want to watch this movie or not and you want this neuron to help us make that decision refer slide time two hundred and twenty-one so now what is happening here is these all inputs they can be either excitatory or inhibitory so let me tell you what inhibitory is first so you are taking input from a lot of sources now see one of these sources or one of these inputs is am i ill today am i down with fever so if that input is on irrespective of who the actor director or whatever is i am not going to watch the movie right because i just cannot leave from my bed so these are known as inhibitory inputs irrespective of what else is on in your input features if this input is on your output is always going to be zero that means the neuron is never going to fire so you could think of it as suppose my mood is not good today i do not feel like getting up or if i injured my leg or anything right if any of these conditions is on irrespective of what the other factors are i am not going to watch the movie so that is an inhibitory input and excitatory input are on the other hand is not something which will cause the neuron to fire on its own but it combine with all the other inputs that you have seen could cause the neuron to fire and how so this is how so these are all the inputs that your neuron is taking all i am going to do is i am going to take a sum of these i am going to take aggregation of all of these so what does this count actually give me the number of inputs which are on the number of inputs which are value one that is all this aggregate this is a sum of all the ones in my input now this is what g does this is a very simple function is taking a sum of my inputs now the function y takes this as the input that means it takes this sum as the input and if the sum is greater than a certain threshold then it fires if the sum is less than the certain threshold then it does not fire so again see what is happening here is it is same as now if you depend on the actor director and genre and so on and you fine at least two of these three conditions are satisfied at least i am happy with the actor and the director even though the genre is not something that i care about i will watch the movie or you might be a very niche go movie watcher who only goes to a movie if the actor matches your requirement the director matches your requirement and the genre and the music and everything matches your requirement so you are threshold in that case it should be high so this is how it is going to help you make decisions now again a very simplified model and this is theta is called the thresholding parameter that is the value which decides whether the neuron is going to fire or not and this over all thing is known as the thresholding logic so this is what a mcculloch pitts neuron looks like refer slide time four hundred and fifty-two now let us implement some boolean functions using this mp neuron so from now on i will just called it mp neuron and we will try to implement some boolean functions using it so now why are we interested in boolean functions it is because we have overly simplified the way we take decisions we are saying that the way we take decisions is we take a lot of boolean inputs is actor matt damon and genre thriller and so on and based on that we produce a boolean output so an input is all booleans so we have x1 to xn which are all booleans and your output is also boolean so that is a boolean function that you are trying to learn from x to y is that clear you have x just happens to contain n different variables here ok and lot of decision problems you could cast in this framework you can just imagine right whether to come for lecture today or not again is you could cast in it depending on various boolean inputs refer slide time five hundred and forty-three this is a very concise representation of the mcculloch pitts neuron what it says is it takes a few boolean inputs and it has certain threshold if the sum of these inputs crosses this threshold then the neuron will fire otherwise it will not fire that is the simple representation of the m p neuron now suppose i am trying to learn the and function when would the and function fire all the inputs are on so what should be the value of the threshold in this case three everyone agrees what about the or function one let us see a few more this function so let me tell you what this function is so you see this circle here so that means that this input is an inhibitory input if that is on then the neuron is not going to fire that is how i am representing it so now tell me what should the threshold for this be it is not so hard see if x2 is on it is not going to fire so you have four rows zero zero zero one one zero one one so two of those are ruled out and it is not going to fire now out of the remaining two when do you wanted to fire so what should be the threshold one now what about this function zero or three three is not even a valid option zero everyone agrees to that and what about this zero so you get this so now if you have a certain number of input variables and the function that you are trying to model the decision that you are trying to make is a boolean function then you could represent using these mp neurons whether all boolean functions can be represented in this way or not that is still not clear i am just showed you some good examples we will come to the bad examples later on here is the question refer slide time seven hundred and thirty-seven so can any boolean function be represented using a mcculloch pitts neuron so before answering this question we will see a bit of a geometric interpretation of what mp neuron is actually trying to do refer slide time seven hundred and forty-nine so let us take or function where you have two inputs x1 and x2 and this neuron is going to fire if x1 plus x2 is greater than equal to one that is clear that is how the definition is now if you look at this x1 plus x2 greater than equal to one now let us ignore the greater than part first so we will just talk about x1 plus x2 equal to one what is this equation of a line everyone gets that ok now in this case since we are dealing with boolean inputs and we have two access x1 and x2 how many input points can we have four right zero zero zero one one zero one one refer slide time eight hundred and thirty-six so you could have these four points so just note that this is an x1 and x2 axis but only four inputs are valid here this is not a real numbered access this is only boolean inputs possible here now what is the line x1 plus x2 equal to one tell you which line is that so one which passes through one zero here and zero one here this is that line now what do we want that for all those inputs for which the output is actually one they should lie on the line or on the positive side on the line and all those inputs for which the output is zero they should lie on the other side of the line is that happening so what is actually mp in unit actually learning linear decision boundary it just what it is doing in effect is actually it is dividing the input points into two halves such that all the points lying on that line right are sorry all the points for which the input should be zero lie below this line and all the points for which the output should be one sorry in both cases it should have been output so let me just repeat it all the points for which the output is zero lie below this line and all the points for which the output is one either lie on this line or above the line is that fine and so let us convince ourselves about this even it is not already clear from the equation for how many of you it is already cleared from the equation that this is exactly what it does for a large number of periods but still we will just do a few examples and move ahead refer slide time one thousand and fifteen now for the and function what is the decision boundary it is x1 plus x2 no that is the decision boundary equal to two so again i have these four points only these four points are possible now where is my decision line passing through that one one and intercepting this somewhere around two zero and this around zero two so that is the line which i am interested in now again do you see that our condition is satisfied that all the inputs for which we want the output to be one are on or above the line and all the inputs for which we want the output to be zero or below the line now what about this function what is the threshold zero so what would the line be x1 plus x2 equal to zero which passes through the origin right and again all the points are either on or above the line so this part we are going to call as a positive half space and this we are going to call as the negative half space refer slide time one thousand, one hundred and twenty-four now what if we have more than two inputs in a two dimensional case when we just had x1 and x2 we are trying to find a separating line in the three dimension case what will we do plane in the higher dimensions hyper plane so this is now your three dimensional case again there are three axis here but not all points are possible how many points are possible eight points and which is the function that we are trying to implement or so for these eight out of these eight points for how many is the output one seven and for one it is zero so what is the kind of plane that we are looking at we are looking for a plane such that seven points lie on or above it and one point lies below it and which is that point zero so now what is the equation of that hyper plane x one plus x two plus x three is equal to one you see this so you see that all the seven points are visible but the points zero zero is not visible because it is on the other side of the plane so this is doable in three dimensions also and again in higher dimensions also right we could find in hyper plane refer slide time one thousand, two hundred and thirty-eight so the story so far is that single mcculloch pitts neuron can be used to represent boolean functions which are linearly separable so a linearly separable function is such that there exists a line such that for that function whichever points produce an output of one lie on one side of the line and whichever points produce an output zero lie on the other side of the line"}
{"audio_filepath": "/content/Audio_trimmed_wav/Motivation from Biological Neurons.wav", "duration": 411.584, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture \u2013 two mcculloch pitts neuron threshold logic perceptrons perceptron learning algorithm and convergence multilayer perceptrons mlps representation power of mlps so welcome to lecture two of cs seven thousand and fifteen which is the course on deep learning so we will talk about mcculloch pitts neuron thresholding logic perceptrons and a learning algorithm for perceptrons and talk about the convergence of this algorithm and then we will talk about multilayer network of perceptrons and finally the representation power of perceptrons so let us start module one which is on biological neurons so remember during the history we had started all the way back in the 1880s when we spoke about biological neurons so we will just start there spend a few minutes on it and then go on to the computational models which is mcculloch pitts neuron refer slide time forty-nine so now this is a course on deep learning so we are going to talk about deep neural networks now the most fundamental unit of a deep neural network is something known as an artificial neuron and the question is why is it called a neuron where does the inspiration come from so we already know that the inspiration comes from biology and more specifically it comes from the brain because we saw that way back in the 1890s this term neuron was coined for neural processing units or the cells in our brain so now before we move on to the computational neurons or the artificial neurons we will just see the biological neurons in a bit more detail and then we will move on from there refer slide time one hundred and twenty-nine so this is what a typical biological neuron looks like so here actually there are two neurons this portion is called the dendrite so it is used to receive inputs from all the other neurons so that is the place where the input comes in then remember we said that in 1950s we discovered that these neurons are actually discrete cells and there is something which connects them so that connection is called a synapse and it decides the strength of the connection between these two neurons so there is an input there is some strength to the connection then once this neuron receives inputs from various other neurons it starts processing it so that is the central processing unit which is called the soma and once it is done this processing it will it is ready to send its output to other set of neurons so that output is carried on by the axon so we have inputs we have some weights attached to the input we have some processing and then an output so that is what a typical biological neuron looks like refer slide time two hundred and thirty-one and let us see a very cartoonish illustration of how this works right how the neuron works so our sense organs interact with the outside world and then they pass on this information to the neuron and then the neuron decides whether i need to take some action in this case the action could be whether i it should laugh or not right whether the input is really funny enough to evoke laughter so if that happens this is known as something that the neuron has fired refer slide time two hundred and fifty-seven now of course in reality it is not just a single neuron which does all this there is a massively parallel interconnected network of neurons so you see a massive network here now the neurons in the lower level site so these neurons they actually interact with the sensory organs they do some processing based on the inputs so they decide whether i should fire or not and if they fire they transmit this information to the next set of neurons and this process continues till the information is relayed all the way back and then finally you decide whether you need to take any action or not again in which this case it should be laughter so that is how it works and when i say massively parallel interconnected network i really mean it because there are ten raise to eleven which is roughly one hundred billion neurons in the brain refer slide time three hundred and forty-four now this massively parallel network also ensures that there is some division of work now what do you mean by that is not that every neuron is responsible for taking care of whether i should laugh or not or not every neuron is responsible for processing visual data some neurons may possess visual data some neurons may possess speeds data and so on so there is this division of work every neuron has a certain role to play so for example in this cartoonish example that we took refer slide time four hundred and seven so there might be this one neuron which fires if the visuals are funny right whatever you are seeing is funny there will be one neuron which finds sheldons speech to be funny the way he speaks so that might be funny and there might be another neuron which actually finds the dialogue content to be funny and now all of this pass on the information to the next level and this guy would fire if at least two of these three inputs are funny so that means i have some threshold based on which i decide whether to react or not if it is really funny then only i laugh it otherwise i will not laugh refer slide time four hundred and forty-two so the neurons in the brain as was obvious in the previous slide are arranged in a hierarchy and i will take a more realistic example where we look at the visual cortex so is this is the portion of the brain which is responsible for processing visual information right so as you see here you have our retina from where the information starts flowing and it goes through various levels so you see you follow the arrows and you will see there are several levels there is one level here then another here another here and so on right so it is again as i was trying to illustrate in that cartoon the information is relayed through multiple layers and then it goes all the way back to the spinal cord which decides that in this case i need to move the muscle right so that is what is being decided here right so the information flows through a hierarchy of layers and in this particular case i am going to focus on these three circled layers which are v1 v2 and ait right so these actually form a hierarchy and let us see what this hierarchy does right so at layer one you detect edges and corners so i am looking at you all i just see some dots and some shapes so that is what layer one recognizes i just recognize some edges and some dots and so on refer slide time five hundred and forty now layer two tries to group all of these together and come up with some meaningful feature groups right so it realizes oh these two edges actually form the nose these two dots actually form the eyes and these two edges actually form the mouth right so that is slightly higher level of processing that it is doing and then layer three further collects all this and leads to higher level objects right so now it is realizing all these things put together is actually a human face right so you add edges and circles or dots then you had some feature groups and then the feature groups combine into objects right so that is how this hierarchy processes refer slide time six hundred and thirty so here is a disclaimer i understand very little about how the human brain works right and what you saw is a very oversimplified explanation of how the brain works right what i told you is there is an input a layer of networks which does a network which has many layers which does some processing and then you have an output right that is the very simplistic view that i gave you this is an oversimplified version but this version suffices for everything that we need for this course right this is not a biology or a neural processing course right so it is enough for this course so that is where we will end module one"}
{"audio_filepath": "/content/Audio_trimmed_wav/Output functions and Loss functions.wav", "duration": 1569.941, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module forty-three lecture four output functions and loss functions we go on to the next module where we will be talking about output functions and loss functions refer slide time nineteen the question that we are going to focus on is how to choose the loss function but i will show you that it is tightly coupled with the choice of the output function also remember that we had said that we have a special o function as the output function i have not told you what that o is and now that is what we are going to define refer slide time thirty-three now the choice will be loss function actually depends on the problem at hand and that is exactly the question which had come up right that in some cases it is to have sigmoid as the output function because your values are between zero to one but whatever there are cases where your output is not between zero to one right so it definitely depends on the choice of the on the problem that you are trying to solve so we will illustrate this with the help of two examples and these two examples will cover a broad range of problems that you will encounter or if you are working in machine learning right so the first problem is again you are given the input as movie you are using a neural network with l minus one hidden layers and an output layer y hat right so this is sorry this is a true one so you have an output layer and the output layer is going to predict the imdb rating the critics rating and the rotten tomatoes rating is that fine ok so what kind of problem is this people have done machine learning this is a regression problem and notice that the output values that you want to predict are not bounded it by zero and one they are still bounded by one to ten but in general you could imagine that there could be problems so there are no bounds at all right it could be a very large number is that clear now here yi belongs to r three so remember in all these cases we were assuming that we just want to predict one value but nothing stops you from predicting multiple values at the same time so your output is now three dimensional you are taking an n dimensional input and trying to predict three values from it ok fine the loss function should capture how much yi had deviates from yi ok so this is a valid or maybe we corrected on this way ok so this is the formula which was supposed to be in there right so you take you have predicted three values and you know the true three values you just take the difference between these right is that clear the first element of the predicted value minus first value of the actual value and so on for all the three values that you want to predict refer slide time two hundred and forty-two now you have a loss function but what should be the output function in this case can it be the logistic function yes no it will be bounded between zero to one and you know that your output cannot be bounded between zero to one ok so in such cases then what is a good output function to use one option is to scale it so i will keep that aside why do that it is unnatural and you are actually clamping it and then trying to scale it right so can you do something more natural in that just use a sum which is linear function right so what we could do is you could have o as a linear function so what that means is again remember that this is a of l ok and i know all the computations that have happened so far a linear transformation nonlinear linear non linear and then again linear so i have computed a of l from that i want to compute the final output right so i could just have it as a linear function of the input which is a of l in this case does it make sense how many of you feel it makes sense ok why because now it is no longer bounded right you could this linear transformation your weights could be adjusted in any way to get a value whatever you wanted whether you wanted between one to ten or one to one hundred or one to one thousand these weights could be adjusted to do that right so at least you are not bounding it and it is free to learn what is the range from the data it should be able to run but how should you adjust these ws so that you get the desired range now tell me why would it not happen that you learn ws you start predicting values like one thousand ten thousand and so on in this particular case where your input is bounded by one to ten sorry your output is bounded between one to ten why would it happen i this is my argument and you prove me wrong right i would say that if you have chosen a linear transformation which is not bounded i then network could learn weights which start producing a rating of ten thousand twenty thousand and so on because it is not bounded but you know that that is wrong because the ratings can only be between one to ten so why would that not happen because you are minimizing this loss function right so if you start predicting values like ten thousand when your actual rating was nine then you have a ten thousand minus ninety whole squared loss that is a very high loss so it will start moving you away from that configuration right so the training is always guided by the objective function so if your training happens well it will try to prevent this now suppose let us take a simple thing rate that you are given a our same ball example for probability so you are given an urn which has balls of three colors say black white and yellow refer slide time five hundred and thirty-eight and you have to put the balls in that so you know that the true probability distribution is actually thirty-five twenty-five and four for red black and white ok this is the true probability distribution you have put say thousands of balls in urn now what you do is you just allow me to peep into the urn or you allow me to take some samples from there you tell me take these one hundred samples and you ask me tell me what this probability is right so this is the true probability that you know is true right because you know it because you have estimated now you just give me a small sample from there and ask me to estimate it and based on that i actually estimate this ok so there was a true probably distribution and an estimated probably distribution now i want to find out how wrong i went right afterwards you tell me the answer you tell me that this is what the true was and this is what you predicted now i want a way of computing how wrong i was right so how do i do that you already know this and these are two vectors what can i do you could just do the this is valid anything wrong with this in principle no you could just treat these as any two vectors you have a true value you have a predicted value you just take the squared error difference between them right but you know this is a probability distribution right you should be able to do something better than this you know this is a special quantity this is not just any number that you are predicting you are trying to predict a distribution so you should be able to do something better than that right so that is what we want to see how to do something better than this that is what our quest is now again why we are at this right i also want to make a because this is something people do not immediately understand so i just want to make a case for something else so i will just do that ok now suppose there is this ipl ok and there are four teams in the semifinal let us call them a b c and d ok now i was not in town after the semifinal so i just know the results up to semifinal and then the finals also happen and one of these teams wins let us call it the b team right the b team wins can you express this in terms of probability can you express this in terms of distribution what do you mean my zero and one b has won so it is a certain event because it has one now so what is going to be the distribution zero one zero zero right so this event happens with one hundred percent probability ok now the same case can you ok so now let us do the same thing that is as i said i was not in town right and you asked me tell me which team would win that is i know these four teams have qualified in the semifinals and i know who the players are and so on and with my limited knowledge of cricket i will predict something right so say i predict this ok can you again tell me how wrong i was you know what the true label is and you know what i predicted you can tell me how wrong i was ok so the case which i am trying to make is that even if the event is certain you can still write it as a probability distribution where all the mass is allocated to the correct output can you relate this to a classification problem when you see training data you have already observed it suppose there were four classes possible apple orange mango and banana if you have seen it is apple and if you ask you what is the distribution what will you tell me zero one zero zero you will express it as this one hot vector where all the probability mass is concentrated on the guy which is correct right so even certain events which happen with certainty you can write them as a distribution rate where all the masses are located on the true label so that is how all classification problems when you are dealing with multiple class classification problems it is often the case that you will write it as this that your true label is given to you in this format there were four possible events four possible classes or k cost possible classes out of which only one is correct and then you make a prediction and you want to now find out how different was your prediction from the true label you are trying to get the set of how this relates to a classification problem and this is that is why this is of interest to us ok so this so we will see this soon now the next thing that we need is how many of you know what is entropy forget about cross just entropy ok that is why i have left two slides intentionally blank ok so so now let us see where i go with entropy ok how many of you know what is expectation please fine so again the same thing now i knew that this was the distribution which i think i am into gambling am not i am into gambling and i try to bet on these teams and i bet some amount on each of these can you tell me what is the expected reward that i will get so what am i saying wait suppose this is the case that if team a wins i get 10k rupees or my net profit is 10k rupees if team b wins my net profit is 20k rupees and c and d so on right you get the setup for every even there is an associated value with it this is the value of event a winning b winning c winning d winning so the net profit in each of these case so what is my expected net profit no give me a formula sigma overall events right how many events do i have here four right so rather i should say i equal to abcd right probability of i multiplied by the value associated with that event so this is how you compute expectation ok everyone gets this so now suppose say am doing this right there are suppose four symbols i do not know what i am teaching ok so and i am trying to communicate this from a source to a destination ok and now suppose these are the four symbols that i give and if these one of these symbols is say with probability one and if i transmit it what is the information that this guy gets so this is assumed that a is that sun is going to rise today if i tell you this when you are sleeping in the night what will you tell me so basically are not gaining any information well it is a certain event you know this is going to happen right now one of these events suppose i am going to say that this there is going to be a cyclone tomorrow morning what is the probability of a cyclone happening in chennai almost one but still it is a very rare event so if i tell you something which is very rare that message has a very high information content right so if event which has a very high probability has a very low information content and an event which has a very low probability has a very high information content right so you can measure the information content of an event so so the point is that what you can have is that the information content of an event you can write it as how many of you get this how many of you have seen this before all of you have seen this right so this is the value associated with an event ok now can you tell me what is the expected information content for every event now i have given you the value associated with that even so what is the expected information content summation p of i into information content of i and this like and this is of course log right so it would be so what is this called this is called the entropy now what is cross entropy how many distributions are you dealing with here one which is the p distribution which tells you how likely these messages were and based on that you are trying to calculate the entropy of this situation right so now what is cross entropy you have a true distribution say you have a predicted distribution ok this is what you predicted so that means according to your predictions the information content of every event is going to be log of qi because that is what you predicted right but what are the actual properties which with these which these events are going to occur pi\u2019s right so then the expectation has to be computed over pi\u2019s right so then what you will have is summation pi log qi so this is what you estimated the information content to be but the actual events are going to happen with this probability right so this is your value associated with the event and this is the actual probability of the event right so this quantity is known as the cross entropy is it clear and this is a way of measuring when would this be in when would this be minimized when both are same that means if your prediction is very close to your true distribution this quantity will be low minimized actually so that is what we wanted actually you wanted to predict some distributions in all of these cases and you wanted a measure which tells you that this prediction was good and what is the definition of good it is as close to the correct value so cross entropy gives you a measure of telling how close a predicted distribution is to a true distribution so now instead of using the squared error which was actually pi minus qi right so pi was my true distribution and qi was my predicted distribution i can use cross entropy which is given by this model and it does the same thing it gives me a principled way of measuring how close my predicted distribution is to my true distribution do you get this refer slide time one thousand, six hundred and forty-six so now so this was for whatever we have done so far right till this point this was for regression right now i wanted to enter into classification for which i have built this set up of how to take the difference between two distributions so now let us consider this problem where we have this situation and which is a classification situation that you are given four possible classes out of which one is the correct class and this is the true data given to you this is the true distribution all the probability mass is focused on one of these classes now we want to given an image classify this into one of k classes if you could again use a squared error loss but since we are dealing with probability distributions here we want to use something special so before we get to what the special is going to be what do i first need to tell you in the earlier case my output was not bounded was it also dependent was there any condition on if the imdb rating is something the critics rating should be something else or the rotten tomatoes rating should be something else no now in this case is there a tightly coupled behavior between the outputs why because they should sum to one we are trying to predict a probability distribution so the sum should one right so i need an output function which ensures this you get this setup refer slide time one thousand, eight hundred and eight now we should ensure that y hat is also a probability distribution whatever we are predicting is also a distribution so now can i use a sigmoid function yes it will give me values between zero to one and probabilities are between zero to one but the sum would not be y so sigmoid is ruled out refer slide time one thousand, eight hundred and thirty-two so what we use is something known as the softmax function how many if you have seen this before please everyone raise your hands otherwise you will get zero on the assignment fine so what does this what does this function actually do let us look at this function right so here you had a l which was say a l one a l two a l three right suppose we had three classes ok so from here i actually want to go to hl or rather i going to want to go to y hat right which is going to consider y hat one y hat two y hat three right it is going to give me probability of each of the three classes let us assume there are only three classes right so now what this function does is how is it going to predict y one hat suppose these values were ten minus twenty and thirty so what is going to be y one hat is going to be e raised to ten divided by e raised to ten plus e raised to minus twenty plus e raised to thirty so now you see how the output is comp computed from each of these values right so why did we do this e raised to stuff why could not i have just taken ten plus minus twenty plus thirty divided by the sum because we have negative values so once we take the exponent even the negative values become positive right so that is why we need the softmax function i hope all of you wrote this in your assignment they did ok so you get this we have a different output function now and this output function does it make sense it gives us a probability distribution now the summation would be one and each of these values would be between zero to one that is exactly what we wanted refer slide time two thousand and twenty-four refer slide time two thousand and twenty-five and now that we have ensured that y and y hat both our distributions what is the objective function that we are going to use cross entropy how many of you convinced it is cross entropy we have two distributions now we saw that a principled way of computing the difference between two distributions is the cross entropy so we will use the cross entropy now can you tell me something about this sum there is something special about this sum what are these three true values and these are the predicted values what is so special about this sum how many terms are there in this summation k as many as the number of classes in this case four how many of those terms will go to zero all but one right except for the correct class everything else will go to zero so this just boils down to the following loss function that if l is the true class right for that class yc is going to be one it is going to be zero for everything else that is exactly what this vector tells you only that term will remain so were actually trying to minimize this quantity refer slide time two thousand, one hundred and thirty-five let us see so for classification problems this is your objective function you either minimize the negative log of y hat l or you can say you are maximizing this thing ok now what is this quantity y hat l no it is a predicted probability of the correct event right so this is a probably no wait this is an important question so you have y hat l here and this is a function of i mean this optimization problem is with respect to theta is this a well formed objective function does y hat l actually depend on theta yes it does so theta because why i tell is a function of all these things everything here and then a log on top of that right so it is actually a function of all your parameters so this is a properly set objective function we are trying to minimize or maximize with respect to theta ok and you told me that y hat l is actually the probability of the predicted probability of the correct class ok hence this quantity is also known as the ml class pattern recognition class log dash of the data student all refer time two thousand, two hundred and fifty-three all good and fill in the blanks so it is a priority of the x belonging to the l th class and then hence y hat l because it is the probability it is the likelihood of it is called as the log likelihood of the data log likelihood so what have we done so far we started with a feed forward neural network we defined the hidden layers and the input layers and the weights and the biases we kept a provision for the output layer to be something special right then we went to two classic problems one is regression and the other is classification in regression we wanted to predict values of all sorts of ranges so we decided to use a linear layer there so that there is no bound on the values that you can predict and your objective function should take care of where the bound lies it should not allow values which are way off from the true values right and that is why we use the squared error function there the other problem that we looked at was classification where we saw that the label actually can be treated as a distribution where all the mass is focused on the true label and zero everywhere and our job is then again to predict our distribution so we are given the true distribution and we predict another distribution so the output again we want something special in this case which is a distribution so to ensure that use a spatial function which is called the who said sigmoid softmax function fine and then we got a prediction which is a probability distribution and then how did we find what was the objective function what is the difference between the true and the predicted the cross entropy right so we use cross entropy as the objective function and then with some simplification we realize that it boils down to maximize the log of the probability of the true class or other log of the predicted probability of the true class refer slide time fifty-three so now let us look at the summary so if your outputs are real values what is your output activation going to be linear what is the loss function going to be squared error if your output is a distribution what is the output function going to be softmax what is this loss function squared error cross entropy right now this grid light actually takes care of a wide range of problems that you will see right think of any examples that have been giving you so far movie prediction or sentiment prediction or image classification or anything all of that you can fit into this frame of it and so if you know these two loss functions how to deal with them then you can deal with a large class of problems that you are going to deal and for the rest of this lecture which will happen tomorrow we are going to focus on this at this particular output function and this particular loss function how do we compute i have a loss function what i am going to compute now the gradient with respect to all the parameters so this is what we are going to focus on right so we have seen the loss function in detail we have seen that the loss function is tightly coupled with the output function now we are all set but given this loss function how do we start computing gradients of this loss function"}
{"audio_filepath": "/content/Audio_trimmed_wav/(Need for) Sanity.wav", "duration": 245.12, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture one chapter nine need for sanity so lot of fields have adopted deep learning now and lot of state of the art ai systems are based on deep neural networks but now what is needed is after all thi s madness were deep learning has taken over a lot of research areas can we now bring in some sanity to the proceeding so this is really a need for sanity refer slide time thirty-two and why i say that is that because there is this paradox of deep learning so there is this interesting question that why does deep learning works so well despite having a high capacity so the deep neural networks have a very high capacity which means that susceptible to over fitting so most of you would have done some course on machine learning so there you know that over fitting is bad because you are just memorizing the training data and then you might not be able to do so well and at tested and over fitting happens when your model has a high capacity so even though deep neural networks have high capacity why are they doing so well we will focus on this high capacity but when we talk about the universal approximation theorem and give some arguments for why deep neural networks have such a high capacity the other thing is they have this numerical instability right so we spoke about these vanishing and exploding gradients and again we will talk about this later on in the course so despite this training difficulties why is it that deep neural networks performs so well and of course they have this sharp minima which is again it could lead to over fitting so if you look at there is an optimization problem it is not a neat convex optimization problem so it is a non convex optimization problem so why does it still do so well so it is also not very robust so here is an example on the right hand side the figure that you show so the first figure is actually of a panda and the machine is able to detect this panda with some fifty-seven percent confidence right we have trained a machine for a lot of animal images we have shown it a lot of animal images at test time we show at this image the first image that you see on the right hand side and is able to classify this is a panda with fifty-seven percent confidence but now what i do is i add some very random noise so that second image that you see with some very random pixels if i add it to this image i will get a new image so every pixel in this image is added to this new noise image and i get the image which is see on the third the third image that you see right to you and me or to any average human this still looks like a panda there is hardly any difference between this image and the original image but now if you pass this to the machine all of a sudden instead of recognizing this is a panda it starts to recognize it as a gibbon and that too with ninety-nine percent confidence so why is it that they are not very robust and despite this not being very robust why are deep neural networks so successful so people are interested in these questions and people have started asking these questions there are no clear answers yet but slowly and steadily there is an increasing emphasis on explainability and theoretical justifications so it is not enough to say that your deep neural network works and gives you ninety-nine percent accuracy it is also good to have an explanation for why that happens is it that some components of the networks are really able to discriminate between certain patterns and so on so what is going on inside the network which is actually making it work so well right and hopefully this will bring in some sanity to the proceedings so instead of just saying that i apply deep learning to problem x and got ninety percent success we will also make some kind of more sane arguments just to why this works and what is the further promise of this and thinks like that so that is roughly a quick historical recap of where deep learning started and where it is today starting all the way back from advances in biology in one thousand, eight hundred and seventy-one to recent advances till two thousand and seventeen and so on deep learning right and here are few url refer slide time three hundred and fifty-five so you could take a look at this for a lot of interesting applications of recurrent neural networks refer slide time four hundred bunch of startups which have come up in this space is working on very varied and interesting problems and here are all the references that i have used for this particular presentation refer slide time four hundred and six so that is where we end lecture one and i will see you again soon for lecture two"}
{"audio_filepath": "/content/Audio_trimmed_wav/Deep Learning(CS7015): Representation Power of a Network of Perceptrons.wav", "duration": 769.515, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module \u2013 twenty-eight lecture \u2013 two representation power of a network of perceptrons we will go to the next module where we talk about a network of perceptrons and then we talk about the representation power of a network of perceptrons so this module should have been titled as network of perceptrons so now in particular what we are going to see is how any boolean function whether linearly separable or not can be represented using a network of perceptrons refer slide time twenty-five now what do i mean by represented during a network of perceptrons what it means is that i will give you a network of perceptrons you take any boolean function feed any value of x1 to xn and the network will give you the same y as it is expected from the truth table ok that is what representation means just to put it out clearly refer slide time fifty-seven and now i am going to again do a setup i am not giving you the solution i am just making some set up and then we will discuss the solution so for this discussion we will assume that true equal to plus one and false equal to minus one so instead of zero and one we will assume minus one and plus one and these are your inputs x1 and x2 we are taking the two input case and i will have four perceptrons first i will have four perceptrons and i will also have very specific weights connected to form the inputs to these perceptrons so red means minus one and blue means plus one right so the first two inputs are connected with a weight of minus one the next two inputs with minus one plus one plus one minus one and the last would be plus one now once i have this i will set the bias of all these perceptrons to minus two so that will that means they will fire only if they are weighted sum of the inputs is greater than two now after this i will have one more perceptron so i had two inputs i converted that to four values these four values are now going to feed into one more perceptron and these weights i will not fix them these are the weights that i am going to learn ok these and the final output of this perceptron which is the green perceptron is the output of the network right so now coming back to what i said that it can represent any function what i mean is that you take any function feed in any combination of x1 x2 this network will give you y and i am telling you that it will match the truth table of that function refer slide time two hundred and forty-three now let us define some terminology this will also stay with us for the rest of the course so this network contains three layers the layer containing the inputs it is called the input layer very creative the middle layer containing the four perceptrons is called the hidden layer and the output layer which gives you the output is called the output layer output perceptron which gives you the output is called the output layer right so you have a input layer a hidden layer and an output layer and the outputs of the four perceptrons i am going to call them as h1 h2 h3 and h4 and the red and blue edges are called the weights for the layer one which we have not learned we have actually set them by hand and the weights for w1 w2 w3 w4 are called the weights for the second layer other the layer two weights and these are the weights that we want to learn refer slide time three hundred and thirty-four now i make this claim that this network it can take any boolean function it can implement any boolean function so this same network can implement any boolean function that means if i take this network and if i try to learn the values of w1 w2 w3 w4 for any boolean function whether it was originally linearly separable or not i will be able to implement it so isn\u2019t this an astonishing claim any boolean function do you think this is an astonishing claim well not really if you really understand what is happening here right so let us see what exactly is happening here so when will perceptron one fire when the input is false false zero zero will it fire for any other input when will perceptron two fire any other input same for the next perceptron same for the next perceptron so you start getting an intuition of what is happening here you do ok let us see so now for this particular network now that i have given you some intuition of what is happening basically every node or every neuron in the hidden layer is catering to one of the inputs and it will fire only for that input it will not fire for anyone else refer slide time four hundred and fifty-nine so now let us try to implement the xor function and see what are the so now let us try to implement the xor function and see what are the set of inequalities that result from this earlier when we try to look at the set of inequalities we ended up with a contradiction let us see if that happens now so this is x1 x2 this is your xor function so that is just like any truth table then i am noting down the intermediate values and then my final input to the green perceptron is going to be summation of these and it will fire if this summation is greater than equal to zero or else it will not fire now for the first case when the input is zero comma zero what is h1 going to be one and everything else is going to be zero that is exactly what we saw in the previous slide so what is the summation going to be just w1 right so it is w1 h1 plus w2 h2 so on but h2 to h4 are zero so only thing that remains is w1 for the second case w2 for the third case w3 for the 4th case w4 so is it clear now what is happening let us go a bit more into detail right so now for the xor condition what are the conditions that we need w1 should be less than w0 because this should not fire w2 should be greater than equal to zero w3 should be greater than equal to sorry w naught not w is not zero and w4 should not fire so w4 should be less than w0 are there any contradictions here by design no right so we have made sure that for the final layer only one of these guys feeds to it so it does not matter what the remaining outputs are they do not interfere with each other unlike earlier where we had conditions like w1 should be something w2 should be something and then w1 plus w2 should be something there are no such contradictions here because we have made sure that every neuron in the middle layer actually caters to one specific input and now the weights in the final layer can be adjusted so that we get the desired output for that input so i can set whatever value of w1 i need to set so that i can fire the neuron in fact i could just fix w0 as zero and then i can adjust the weights of w1 w2 w3 w4 and i can implement the xor function so are you convinced that this can be used to implement any boolean function how many if you are not convinced so the negative question never works how many if you are convinced sure now what if we had three inputs refer slide time seven hundred and forty before that it should be clear that the same network can be used for any of the remaining fifteen functions and for each of these functions we will end up with a different value of w1 w2 w3 w4 but you will be able to satisfy the truth table right and you can go home and try it which i am sure you will do refer slide time seven hundred and fifty-six ah so what if we have a function of three inputs two hundred and fifty-six what is two hundred and fifty-six no eight fine sure refer slide time eight hundred and eleven so this is what it will look like and anything specific about the weights of the initial layer can you tell me what the weights would be just tell me red red red red blue blue whatever colours you like this thing first perceptron what would the weight colours be red red red then enough so this is how it will look right right and now this same thing will work with the same logic for any boolean function of three inputs you will get these eight inequalities and they will not interfere with each other and you can set the values of w1 to w8 so that you can satisfy it ok fine refer slide time eight hundred and forty-seven so what if we have n inputs two power n perceptrons in the middle layer right ok refer slide time eight hundred and fifty-five so now here is the theorem any boolean function of n inputs can be represented exactly by a network of perceptrons containing one hidden layer with two raised to n perceptrons and one output layer containing one perceptron we just saw an informal proof of this we just constructed i just gave you the answer it this is how you will get it now note that a network of two raised to n plus one perceptron is it sufficient or necessary or both sufficient yes that is what it says is it necessary no we already saw the and function which we can just represent using a single perceptron right so it is not necessary but it is sufficient so this is a very powerful theorem if you think of it right so now this whole objection right remember this history and when we have the c i winter when people showed that perceptron cannot handle the xor function that is for a single perceptron if you have a network of perceptrons you can actually have any boolean function but what is the catch as the value of n increases the number of neurons increases exponentially right but still in theory you could have a solution refer slide time one thousand and one now again why do we care about boolean functions i keep coming back to this why do we care about boolean functions because you took this and so the question that i the question that i want to answer is how does this relate back to our original problem right we know any boolean function can be implemented how do we go back to our original problem which is whether we like a movie or not right and you could see that there is a whole family of problems there right whether we like a movie or not whether we like a product or not whether i want to go home today or not yes no any kind of a yes no problem it is a whole family of problems there refer slide time one thousand and thirty-four so let us see so we are given this data from our past experience right so we are told that this is what the movie looks like these are the actor\u2019s director\u2019s joiners everything we also know whether we like these or not so we have a set of positive points and we have a set of negative points right and now we want to have a computational model which can satisfy this data that means once the model is trained once whatever algorithm i algorithm i use has converged it should be able to give me the correct output for a given input that is what we are interested in and that is a real classification problem that we are interested in now for each movie we are given these factors as well as the decision and i said pi\u2019s and ni\u2019s are positive and negative points the data may or may not be linearly separable it is not necessary that the data is linearly separable those were the goody cases it but in general that may not happen but do we worry about it now no what the previous theorem told us is that irrespective of whether your data is linearly separable or not i can give you a network which will be able to solve this problem modulo that it might be very expensive in the number of neurons in the middle layer but if you keep that aside i have a solution for this and that is why we care about boolean functions because many problems we could actually cast to it in a simplistic way if we ignore the real inputs and if you even think of the real inputs suppose it could take all values between zero to one you can always make it binary you could say that is the value between zero and one is the value between one and two and you could make it as small the scale as small as possible right so that is why we care about this refer slide time one thousand, two hundred and nine so the story so far has been that the network of networks of the form that we just saw it which contain one input layer output layer and one or more hidden layers these are known as multilayer perceptrons but a more appropriate terminology would be multi layered network of perceptrons because the perceptron is not multilayered you have a network of perceptrons and that network has many layers right but generally there is abuse of notation we always call it mlp which is multilayered perceptrons and the theorem that we just saw gives us the representation power of an mlp and basically tells us that it can represent any boolean function that we want to deal with so that is where we will end this class and in the next class we will talk about sigmoid neurons"}
{"audio_filepath": "/content/Audio_trimmed_wav/Faster, higher, stronger.wav", "duration": 127.467, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture \u2013 one chapter five faster higher stronger so this is what the progression was right that in two thousand and six people started or the study by hinton and others led to the survival and then people started realizing the deep neural networks and actually we use for lot of practical applications and actually beat a lot of existing systems but there are still some problems and we still need to make the system more robust faster and even scale higher accuracies and so on refer slide time forty-one so in parallelly while there was lot of success happening from two thousand and twelve to two thousand and sixteen or even two thousand and ten to two thousand and sixteen in parallel there will also a lot of research to find better optimization algorithms which could lead to better convergence better accuracies and again some of the older ideas which were proposed way back in one thousand, nine hundred and eighty-three now this is again something that we will do in the course so most of the things that i am talking about we are going to cover in the course so we are going to talk about the imagenet challenge we are going to talk about all those networks the winning networks that i had listed there alex net zf net google net and so on we are going to talk about nesterov gradient descent which is listed on the slide and many other better optimization methods which were proposed starting from two thousand and eleven so there was this parallel resource happening while people were getting a lot of success using traditional neural networks they are also interested in making them better and robust and lead for lead to faster convergence and better accuracies and so on so this led to a lot of interest in coming up with better optimization algorithms and there was a series of these proposed starting from two thousand and eleven so adagrad is again something that we will do in the course rms prop adam eve and many more so many new algorithms i have been proposed and in parallel a lot of other regularization techniques or weight initialization strategies have also been proposed for example batch normalization or xavier initialization and so on so these are all things which were aimed at making neural networks perform even better or faster and even reach better solutions or better accuracies and so on this all that we are going to see in the course at some point or the other"}
{"audio_filepath": "/content/Audio_trimmed_wav/Beating humans at their own games (literally).wav", "duration": 82.944, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture one beating humans at their own game literally now since i mentioned rl so we will go on to the next chapter which was now becoming much more ambitious with what you can do with deep learning and people started beating humans at their own game quite literally refer slide time twenty-six so there was this starting with atari games in two thousand and fifteen where resources from deep mind show that you could train a deep neural network to play atari games and do much better than what humans do so that is something that they were able to show on atari games and then people started looking at other game refer slide time forty-six so then there was this go and this popular tournament and which alphago which is deep reinforcement learning based agent was actually able to beat the reigning champion at that time one of the best players of go at that time refer slide time one hundred and six then even at poker were something known as deepstack which is again a deep reinforcement learning based agent which is able to beat eleven professional poker players at this game refer slide time one hundred and seventeen then other games like defense of the ancients since on which is a much more complex strategy based game where again deep reinforcement learning based agents have shown a lot of success in beating top professional players on this game"}
{"audio_filepath": "/content/Audio_trimmed_wav/Feedforward Neural Networks (a.k.a multilayered network of neurons).wav", "duration": 1085.141, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture four feed forward neural networks backpropagation so welcome to lecture four of cs7015 the course on deep learning today we will talk about feed forward neural networks and back propagation so quick recap of the story so far it so we started with mp neurons we saw there were some problems with the mp neurons they could handle only boolean inputs and boolean outputs and threshold needed to be hard coded so from there we moved on to perceptrons which allowed for real inputs real outputs and sorry real inputs and binary outputs and we also learned an algorithm for learning these weights and parameters right so we need there was no need to hand code these parameters anymore but then we found that for a single perceptron there is a limitation it cannot it can only deal with functions which are linearly separable so then we went on to a multi layer network of perceptrons and we proved by illustration that it can handle any arbitrary boolean function whether linearly separable or not the catch is that you will need a large number of neurons in the hidden layer right then we also observed that perceptrons have this harsh thresholding logic so which makes the decisions very unnatural it is forty-nine it is negative fifty-one is positive so you wanted something more smooth so the smoothest approximation to this step function which is the perceptron function was a sigmoid function sigmoid is a family of functions and we saw one such function which was logistic function and then we saw that it is very smooth now it is continuous and differentiable now for the sigmoid neuron on a single sigmoid neuron we saw a learning algorithm which was gradient descent and we proved principally that it will always go in the direction where the loss decreases right so that is what is the basis for gradient descent and then we graduated from a single neuron to a network of neurons and made a case that such a network of neurons with enough neurons in the hidden layer can approximate any arbitrary function right ok so i have told you that it can approximate any arbitrary function what does that mean and what is the thing in the network that does all this all the tower functions and the tower functions depend on weights and biases so there in that illustrative proof again we were adjusting the weights and biases by hand right we knew that we wanted these very tiny tower functions and we were doing it now from there where should we go student refer time two hundred and thirty-nine we need an algorithm to learn these weights and biases right so that is what back propagation is so today i am going to formalize these feed forward neural networks we just did it by illustration the other day i will introduce you to the terminology and see what the input outputs are and so on and then we will look at an algorithm for learning the weights in this feed forward neural network refer slide time three hundred and three let us begin so this a lot of this material is inspired by the video lectures by hugo larochelle on back propagation he has a course on neural networks it is available on youtube you can check it ok so let us first begin by introducing feed forward neural network right refer slide time three hundred and eighteen so what is a feed forward neural network the input to the network is an ndimensional vector so ok that means my input belongs to rn that fine the network contains l minus one hidden layers where do you already know what hidden layers are right we have been defining that terminology since multi layered perceptron so you have these hidden layers and there are l minus one of these and then it has one output layer containing k neurons ok those are the feed forward neural network looks like what is missing here student refer time three hundred and fifty-seven the weights right so each neuron in the hidden layer ok before that each neuron in the hidden layer and the output layer can be split into two parts right so i will call the first part as the pre activation and the second part as the activation have you seen this plate before right what does the pre activation do student aggregation aggregation and what does the activation do student nonlinearity nonlinearity right so we have this pre activation and activation at every layer and a i and h i are vectors is that correct because this entire thing or rather this part is h one and this part is a one both of these are vectors right and for this discussion am going to assume that everything till here belongs to r n so the input was r n and all the hidden layers also have n neutrons is that fine so please pay a lot of attention to this couple of slides because this is going to stay with us for the rest of the lecture and perhaps two more lectures and even for the course alright so this is very important that you understand this the way we are defining a feed forward neuron network refer slide time five hundred and eight the input layer can be called as 0th layer what i mean by that is that i could refer to this as h zero ok there is no a zero h zero here because there is no pre activation activation you are just given the input so i just call it as h zero ok and the last layer can be called as h of l right whatever you get from this green part you will call it as h of l ok what is the dimension of h of l r raised to k it belongs to r k because i have said here that you have k neurons each corresponding to k classes ok now we have weights between the input layer and the first hidden layer now can you tell me this belongs to r n this also belongs to r n so what is the dimension of w one n cross n right because it contains weights for connecting each of these inputs to each of these hidden layers there are n here n there right so it is n cross n and what are the dimensions of the bias n one corresponding to each of the hidden inputs fine and this is only for up to this layer because till here i have assumed everything is n refer slide time six hundred and twenty-three now what about the output layer n cross k and the biases k k dimensional ok so this is what the network looks like but now i have to give you some function so i have just i have shown you a diagram but what does it mean mathematically because remember that we are always interested in writing something of the form y is equal to function of x right and that is not well defined yet refer slide time six hundred and forty-nine so let us start defining that ignore the red portion for now ok i will go over it so each of these activations right or rather the pre activations is given by b i plus w i into h i minus one so what it means is that these activations take inputs from the previous layer multiply by them by weights and also add the bias is that clear so let us see it right for example if i look at a one which is this vector so that is three dimensional and assuming it is three dimensional for simplicity so it is a one one a one one a one two a one three right and that is equal to how do you get rid off this b one one b one two b one three plus this matrix multiplication is this clear to everyone i know it is trivial but am still going over it right so let us not ok and then how do you do this matrix multiplication row was multiplied by the column so this is what you get right and in the end i can write it as this right and this looks very similar to what we have been seeing throughout it from a mp neuron to perceptron to sigmoid neuron and now this case right so it is just an aggregation of all your inputs or weighted aggregation of all your inputs that is the case which i want it to know and that is obvious now so you understand what these are right so this is r n in our case we have assumed n equal to three what is this i will keep asking till this is completely fine with everyone r n and this is student refer time eight hundred and thirty n cross n and this is student refer time eight hundred and thirty-four n cross one n cross n i mean r n sorry is it fine so everyone understands the operation happening here it is a weighted aggregation of your inputs so every guy here is a weighted aggregation of all the inputs ok refer slide time eight hundred and forty-seven now after that i do h i of x is some function of a i of x ok what does this mean so this is again a vector right i have assumed that it is three dimensional so these are the three elements of h i so these are the three guys now these are some function of these light blue guys ok now how does that function operate on the vector it operates element wise not all functions on vectors are element wise but this particular function we are going to do element wise that means that h one one is equal to g of a one one h one two is equal to g of a two and h one three is equal to g of a one three right where if i take g of a one three one of the functions that i could choose is the sigmoid function so it would just be one over one plus e raised to minus here so what is happening is i am taking this value and passing it to the sigmoid function to get oh sorry am taking this value and passing it to the sigmoid function to get h one one taking this value passing it to the sigmoid function to get h one two right so the key thing to understand here that this is a element wise operation right it is not operating on the vector that does not make sense it is operating on every element of the vector right ok and g is called the activation function refer slide time one thousand and two it could be logistic tanh linear anything right so we will see some of these functions later on ok now the activation at layer i sorry they are supposed to be activation at the output layer the activation at the output layer is given by the final function which is f of x is equal to o of a of so let us see so this is a three in our case l was equal to three because we had l minus one hidden layers and the lth layer was the output layer right so this is a l so this is what i have computed here that light green part of the figure that you see right now based on that i want to produce an output so that is someone had asked me a question that why do we always choose sigmoid because sigmoid will clamp the output to zero to one what if i want to predict the amount of oil which will not be between zero to one right that is why for the output we will use a special function that will call the output function and later on i will show you that it depends on the task at hand so it is going to change with the task that we are going to do right so we are just going to say that the final output which is h of l is equal to some function of the pre activation at that layer is this terminology clear to everyone how is each function operating is that clear to everyone refer slide time one thousand, one hundred and twenty-two and we will see some examples of the output activation function right now just for simplicity am going to remove the x\u2019s from the brackets right so instead of calling everything ai of x hi minus of x and so on i will just call them ai hi and so and so that just simplifies things but we know that everything is a function of x because x is the input and that passes through some functions and we get the final output right so this is the notations that we are going to use is the dimension of everything that you see every variable that you see here completely clear to everyone dimension of ai bi w hi x everything is clear ok and the output layer has a slightly different dimension than the other layers because there we have k classes as opposed to n neurons everywhere else ok fine now i need to put this in the paradigm that we saw for supervised machine learning what were the five components there data student model model student parameters parameters student learning learning algorithm student refer time one thousand, two hundred and twenty-nine objective function right ok everyone remembers that ok so i said that we will do deep neural networks and we are trying to write this y hat as a function of x but then what i gave you is just a diagram from which this is not clear whether y hat is actually a function of x how many of you think y hat is actually a function of x very few ok refer slide time one thousand, two hundred and fifty-two so let us see what exactly is our model assumption here right so the question let me repeat the question just to be clear so i said that they are given some data we do not know the true relation between y and x we make an assumption that y is related to x using some function f right and it is has some parameters and then we like to try to learn the parameters of that function so what is the function here so what is your model what have you assumed as the model can you write y as a function of x if yes what is that function how many of you have the answer i think you have your answer ok i think i cannot wait more so i will give you the answer then it will become very obvious ok so this is how y is a function of x right so let us see what is happening i took the original x which was this i transformed it added b one that was the dash at layer one student refer time one thousand, three hundred and fifty-six no this thing student refer time one thousand, four hundred preactivation at layer one i passed it through the activation function right ok now again let us be clear about the dimensions what is the dimension of this student n n what is the dimension of this n cross n so what is the dimension of this product student refer time one thousand, four hundred and twenty-one n what about this so what is the product the final dimension of this r n now you are passing it through a function g that function is operating element wise so what is the output dimension student r n r n so this is again r n ok now this student refer time one thousand, four hundred and forty-two so now you see the whole story right so now this n cross n guy multiplies with this n guy again you get a vector again pass it through a nonlinearity was it so hard it is obvious now right you just take an x just note down all the transformations that you have done that is what a function does right it passes it through the through first a linear transformation this is a linear transformation then a nonlinear transformation then again linear nonlinear and so on so just see how far we have come from where we started off right we started off with simple things like w transpose x right that was the perceptron model where we were taking decisions based on w transpose x and we were saying y is equal to one if this quantity is greater than something y is equal to zero if this quantity is greater than something right that is why we started off with we made it slightly more complicated by doing this this was sigmoid neuron now from there where have we gone to this right so we have increased the complexity of the network with great complicity complexity comes great student refer time one thousand, five hundred and forty-six no power right we have already seen the representation power of deep neural networks right so it comes from this complexity that you have you have a lot of linear and nonlinear transformations right that adds to the complexity of the network it has more parameters at each linear transformation you have some parameters and you are also using a lot of nonlinearity so that is the reason why deep neural networks are so powerful right do you get that ok so just to impress again right so any machine learning algorithm that you have you should be able to write it in this form right that y is a function of x with some parameters and then your job boils down to learning these parameters right it just happens that here y is a very complex function of the inputs is that clear ok so i am not deviated from the original story i am still being able to write y as a function of x with some parameters ok what are the parameters student refer time one thousand, six hundred and forty-two all the w\u2019s all the b\u2019s right so w one to w l and b one to b l refer slide time one thousand, six hundred and forty-four and the algorithm that we are going to see today for learning these parameters is called gradient descent but we will use it with back propagation where back propagation will help us to compute gradients it is ok it does not it does not make sense at this point that is what the lecture is supposed to be about right so and what is an objective function student refer time one thousand, seven hundred and seven loss function so i could just go with this loss function right ok there is an error here i thought we corrected this there is a summation so actually these are vectors right so this does not make sense so you should have summation j equal to one to k yij minus yij does that make sense so this is the vector y hat ok for the i th example it will be called as y hat high i which will have k elements right so y hat i one y hat i two up to y hat i k right so that is what my predictions are and i will have the corresponding true vector also i am trying to take the difference between them which is going to be an element wise difference everyone understands the error in the slide how many of you do not get it how many of you get it if you do not get it please raise your hands it is a minor thing i can correct it and how does deep neural networks fit into these this paradigm"}
{"audio_filepath": "/content/Audio_trimmed_wav/The Deep Revival.wav", "duration": 436.992, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture one chapter three the deep revival when this deep revival happened so in two thousand and six a very important study was or a very important contribution was made by hinton and salakhutdinov refer slide time fifteen sorry if i have not pronounced it properly and they found that a method for training very deep neural network effectively now again the details of these are not important we will be doing that in the course at some point but what is the important take away here is that while from one thousand, nine hundred and eighty-nine to two thousand and six we knew that there is an algorithm for training deep neural networks and they can potentially be used for solving a wide range of problems because that is what the universal approximation theorem said but the problem was that in practice we were not being able to use it for much it was not easy to train these networks but now with this technique there was revived interest and hope that now actually can train very deep neural networks for lot of practical problems this sparked off the interest again and then people started looking at all such of thing right that even this particular study which was done in two thousand and six will actually be very simple to something done way back in nine thousand, one hundred and ninety-three and which again showed that you can train a very deep neural network but again due to several factors may be at that time due to the computational requirements or the data requirements or whatever i am not too sure about that it did not become so popular then but by two thousand and six probably the stage was much better for these kind of networks or techniques to succeed so then it became popular in two thousand and six refer slide time one hundred and forty-one then this two thousand and six to two thousand and nine people started gaining more and more insights into the effectiveness of this discovery made by hinton and others which is unsupervised pre training right that is what i spoke about on the previous slide unsupervised pre training and they started getting more and more insights into how you can make deep neural networks really work so they came up with various techniques some of which we are going to study in this course so this was about how do you initialise the network better what is the better optimization algorithm to use what is the better regularization algorithm to use and so on so there were many things which were started coming out at this period two thousand and six to two thousand and nine and by two thousand and nine everyone started taking note of this and again deep neural networks of artificial neural networks started becoming popular that is when people realised that all this all the negative things that were tied to it that you are not able to train it well and so on have slowly people have started finding solutions to get by those and maybe we should start again focusing on the potential of deep neural networks and see if they can be used for large scale practical application so this two thousand and six to two thousand and nine was again a slow boom period were people were again trying to do a lot of work to popularize deep neural networks and get rid of some of the problems which existed in training them refer slide time two hundred and fifty-eight now from two thousand and nine onwards there was this series of success is which kind of caught everyone which made everyone to stand up and take notice right that this is really working for a lot of practical applications starting with handwriting recognition so around two thousand and nine these guys won handwriting recognition competition in arabic and they did way better than the competitor systems using a deep neural network and then this was a success refer slide time three hundred and twenty-three so this was an handwriting recognition and then there was speech so this shown that various existing systems the error rate of these system could be seriously be significantly reduced by using deep neural networks or plugging in a deep neural network component to existing systems right so this was handwriting and then speech refer slide time three hundred and forty-five then again some kind of pattern recognition which was on handwritten digit recognition for mnist this is a very popular data set which had been around since ninety-eight and a new record was set on this data so this is the highest accuracy that was achieved on this data set around that time in two thousand and ten sorry and this is also the time when gpus entered the same so before that all of the stuff was being done on cpus but then people realised that very deep neural networks require a lot of computation and lot of this computation can happen very quickly on gpus as opposed to cpus so people started using gpus for training and that drastically reduced the training and inference time so that was again something which sparked a lot of interest right because even though these were successful they were taking a lot of time to train but now the gpus could even take care of that and this success continued refer slide time four hundred and thirty-eight so people started gaining or getting success in other fields like visual pattern recognition so this was a competition on recognising traffic sign boards and here again a deep neural network did way better than its other competitors refer slide time four hundred and fifty-three and then the most popular or one thing which made neural networks really popular was this image net challenge which was around since two thousand and eight or two thousand and nine and before two thousand and twelve when this alexnet was one of the participating systems in this competition most of the systems were non neural network based systems and this competition was basically about classifying a given image into one of thousand classes so this could be an image of a bird or a dog or a human or car truck and so on say you have to identify the right class of the main object in the image so in two thousand and twelve this alexnet which was a deep neural network or a convolutional neural network based system was able to actually outperform all the other systems by a margin of sixty-seven percent so the error for this system was sixteen percent and this is a deep neural network because it had eight layers the next year this was improved further and something known as zf network propose which was again eight layers but it did better than alexnet the next year even a deeper network with nineteen layers was proposed which did significantly better than alexnet then google entered the scene and they proposed something which is twenty-two layers and again reduced the error then microsoft joined in and they proposed something which had one hundred and fifty-two layers and the error that you see here is actually better than what humans do so even if a human was asked to label this image because of certain law certain noise in the image and so on even a human is bound to make more errors than thirty-six per cent that means even if you show hundred images to humans he or she is bound to may go wrong or more than three or four of these images right there is this system was able to get an error of thirty-six per cent over the large test set so this two thousand and twelve to two thousand and sixteen period were there was this continuous success on the image net challenge as well as successes in other fields like natural language processing handwriting recognition speech and so on so this is the period where now everyone started talking about deep learning and lot of company started investing in it a lot of traditional systems which were not deep neural network based was now started people started converting them to deep neural network based system so translation system speed systems image classification object detection and so on there were lot of success in all these fields using deep neural networks and this particular thing that we are talking about which is image net and the success in this was driven by something known as convolutional neural networks"}
{"audio_filepath": "/content/Audio_trimmed_wav/Backpropagation (Intuition).wav", "duration": 791.957, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module forty-four lecture four backpropagation intuition this lecture is on backpropagation and feed forward neural networks so we introduced a feed forward neural networks we saw the input layer hidden layer and the output layers and we saw that the output layer actually the output function depends on the task at hand and we considered two main tasks one was classification the other was a regression for regression it made sense to use a linear layer at the output because we did not want the outputs to be bounded they could be any range and for the classification problem we realized that we want a special kind of output because we are looking for a probability distribution over the output and for that we use the softmax function and in both cases we used a different kind of a loss for the regression problem the squared error loss made sense because we predict some values and we want to see how far we are from those values but for the other case the classification we realize that it is a distribution so maybe we could use something which allows us to capture the difference between the true distribution and the predicted distribution refer slide time one hundred and twenty and therefore we had this figure emerging which was depending on the output whether it is real values or probabilities you will have different types of output activation functions and different types of losses and of these combinations today we are going to focus on softmax and cross entropy and our aim is to actually find these gradients remember there are many of those we have seen this large matrix which had many such partial derivatives and we want to find that entire matrix i hopefully do it in a way that it is not a repetitive we could compute a large number of partial derivatives at one go so before we look at the mathematical details we just get an intuition for backpropagation refer slide time two hundred and eleven and then we will get into the gory details of how to actually compute these gradients and partial derivatives so this is the portion that we are in we are intended to ask these two questions and this is where we are refer slide time two hundred and twenty-one so now this is what our network looks like this is clearly much more complex than that single neuron that we had and which had only two weights w and b that was very easy to compute the gradients there now imagine that i want to compute the gradient of the loss function and let us assume it is a classification problem then what is the loss function minus log of y hat so this is the loss function and we want to compute the derivative of this with respect to one of these weights in the network and am deliberately taking something which is much farther away from the loss but why do you say why do i say it is much farther away it is right at the input layer right and the loss is somewhere at the output layer so we want to compute this gradient refer slide time three hundred and ten now to learn sorry you want to learn this way to learn this weight we know that we can use gradient descent we are all convinced that this gradient descent algorithm which i have shown here as long as we put all these variables or all these parameters that we have into theta we can just run the gradient descent algorithm and compute them the only thing that we will need is this partial derivative with respect to all the weights in the network and in particular with respect to this weight that i am interested at refer slide time three hundred and forty now so we will now see how to calculate this we will first this is only to get the intuition so we will first think of a very simple network which is a very deep but the thin network it has many layers but it is a very thin network here you see what i mean by a thin network ok now this is what i am interested in can you tell me how to compute this this looks like a chain so it is justified the user chain rule of derivatives so what would the chain rule look like you want to compute the derivative of this with respect to this and you have done this in high school right so you have functions of the form of sine of cos of tan of e raised to sine of x and this is exactly how this chain is right you have some function of x followed by another function of x another function of x function of x function of x and so on you just keep making a composite function of the input we actually wrote down that function if you remember it was just one function applied after the other function or a very composite function so you just need to apply the same idea here so we take we go step by step so i am almost accounting for every shade of color here so dl theta by d y hat then dy hat by d a l eleven there is only one neuron here then this with respect to the sorry h twenty-one then h twenty-one with respect to a twenty-one a twenty-one with respect to h eleven h eleven with respect to a eleven and then a eleven with respect to w eleven so i just traversed down the chain in the reverse order this is how the chain rule works right anyone has a problem with this it is straight forward right and now what i have done is for convenience i have just compressed the chain you see the red part and the green part i have just compressed this weight so that and this is again something that you have done in high school if you have this you could just write the chain as the first and the last it so this is what you can do and i also compress this other chain ok and am going to use these kinds of compressions later on so what am trying to impress on you is that if i want to go from here to here right that is what my intention is if somehow i have already travels from here to here then i can just reuse that computation that is the idea which i am trying to impress on it i do not need to follow the entire chain every time i can do these partial computations up to a point have you seen this something similar idea somewhere else dynamic program is something like that so you have just computed up to a certain point and then it is reuse the value for further down the chain so that is what we are going to do and same for all the weights right for each weight the chain size would be different depending on where it lies in the network right for the weights which are very close to the output layer the chain would be very small makes sense ok so this is the intuition and we will see the intuition a bit more refer slide time six hundred and forty so let us now understand this in the terms of the wide complex network that we are using refer slide time six hundred and forty-seven so what actually is happening is that we are at a certain stage that means we have some values of ws and b\u2019s ok at the initial stage we just have these w knots and b knots but let us assume that we have done some training and we are at a certain level we are at wt at time step t and bt at time step t right for all the weights inverse now we feed it a training example we do this entire compute computation what do we get at the end we get y hat which is a function of this x that we have fed it but we also know this true y we know the true value we know y hat so we can compute the loss function so we compute the loss and to our surprise we see that the loss is not zero we are getting a non zero loss that means the network has not yet learnt properly right the weights and biases are still not in the right configuration that we want them to be in right so now what do we do we go on this path of investigation we want to find at who in this network is messing up things there is someone who is causing this problem because of which i am not getting the desired output and we are on our quest is to now find out who this guy is who is responsible for this so what would you do where would you start the output layer refer slide time eight hundred and eleven because the output layer is the guy who give you the output right so go and talk to him and we say that hey what is wrong with you why are you not producing the desired output right now what is the output layer going to tell you in very civil language i will say i cannot do anything boss i mean i was just given some weights and inputs from the previous layer and those weights and inputs were messed up so there is nothing which i can do go and talk to them so who will it directors do it will say that i am just as good as wl hl minus one and bl because these are the guys that i completely depend on if these guys were ok then i would have been fine so we then go and talk to these guys that what is wrong with you refer slide time eight hundred and fifty-eight so now they say ok fine wn and bl take the responsibility they are the nice guys they say we are the weights we are supposed to make a we are the ones who are responsible for the adjustments in the network so we have failed to do our job properly and i think we should get adjusted right but then hl will resist it will say it is not my fault why will it resist because it against again depends on the previous activation layer so till then point as to what the ws and b\u2019s in the previous layer right and you see how the investigation is now proceeding where will we reach well keep going down the network we are talking to everyone in the network we are talking to every dark green guy every light green guy every dark blue guy every light blue guy we are also talking to all these weights and biases and in the end what do we figure out the responsibility lies with all the weights and all the biases they are the ones who are responsible for this now but now we find out that this is also one of those weights which is responsible and this is also one of these weights that is responsible but it was have been very difficult for us to talk to them directly so then what are we going to do instead of talking to them directly which is this we will talk to them through the chain rule so we will talk to the output layer that is exactly how what we did maybe went to the first guy that we knew that guy pointed out to the previous hidden layer that guy pointed us to the previous hidden layer and then finally we get to the weights right so this talking to is fine but where do derivatives figure out in this why are why is the language derivatives why are we not talking in english or hindi or something else what does the derivative tell us so talking about gradient descent like what we saw in gradient descent but in general what does the derivative tell us if i change this a bit how much does my loss change right so that is how much this guy is responsible for the loss because if this is very sensitive even adjusting a bit of this i could drastically reduce the loss right so that is what the derivative tells us that tells us how sensitive is the loss function to the weight or any quantity with this with respect to which am taking the derivative right that is why the language is of derivatives right is that clear is the intuition fine to everyone refer slide time one thousand, one hundred and twenty-nine so now will convert this intuition into actual math and try to figure out how to compute every guy along the way right and we will use this idea that we have made some partial computations and then well use it for the rest of the chain so we have made this much at some point we will reach where we have made this much and then you could use it for the rest of the chain in fact we will start right from here well start with this guy and then keep expanding the chain so the rest of the story is going to be about computing three quantities can you tell me which are these three quantities gradients with respect to the output units gradients with respect to the hidden units and then gradients with respect to the parameters so these are the three things that we need to do if we do this we have everything in the chain and we are done and the other thing that we need to do is we cannot sit down and compute this for every element right we want to have it in a generic fashion where instead of talking about w one one one w one one two and so on we should at least be able to talk about w one w two and so on so that means we have only three matrices and three biases right at least at that level so we have to do a collective computation instead of just computing for every guy so instead of looking at scalars which is what we are doing when we are doing gradient descent for w naught and v naught we were just computing the update rule for w and b we want to now do it for vectors and matrices so that is that is the transition that is going to happen and our focus is going to be on what cross entropy and softmax why is that important because that is the loss function so that is the quantity that am going to take the derivative if i change the loss function all the gradients are going to change are all the gradients going to change only the first guy will change in the change all this should remains still same right modulus some conditions but largely it should remain the same right unless you change something in between"}
{"audio_filepath": "/content/Audio_trimmed_wav/Biological Neuron.wav", "duration": 377.664, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture \u2013 one partialbrief history of deep learning hello everyone welcome to lecture one of cs7 fifteen which is the course on deep learning in today\u2019s lecture is going to be a bit non technical we are not going to cover any technical concepts or we only going to talk about a brief or partial history of deep learning so we hear the terms artificial neural networks artificial neurons quite often these days and i just wanted you take you through the journey of where does all these originate from and this history contains several spans across several fields not just computer science we will start with biology then talk about something in physics then eventually come to computer science and so on so with that let us start refer slide time fifty-six so just some acknowledgments and disclaimers i have taken lot of this material from the first people which i have mentioned on the bullet and there might still be some errors because its dates as back as one thousand, eight hundred and seventy-one so maybe i have got some of the facts wrong so feel free to contact me if you think some of these portions need to be corrected and it would be good if you could provide me appropriate references for these corrections so let us start with the first chapter which is on biological neurons as i said its spans several fields will start with biology refer slide time one hundred and twenty-four and we will first talk about the brain and neurons within the brainso way back in one thousand, eight hundred and seventy-one one thousand, eight hundred and seventy-three around that time joseph von gerlach actually proposed that the nervous system our nervous system is a single continuous network as opposed to a network of many discrete cells so his idea was that this is one gigantic cell sitting in our nervous system and it is not a network of discrete cells and this theory was known as the reticular theory refer slide time one hundred and fifty-five and around the same time there was the some breakthrough or some progress in staining techniques where camillo golgi discovered that a chemical reaction that would allow you to examine the neurons or the nervous tissue so he was looking at this nervous tissue using some staining technique and by looking at what you see in this figure on the right hand side the yellow figure even he concluded that this is just once single cell and not a network of discrete cells so he was again a proponent of reticular theory so this is about camillo golgi refer slide time two hundred and thirty-five and then interestingly santiago cajal he used the same technique which golgi proposed and he studied the same tissue and he came up with the conclusion that this is not a single cell this is actually a collection of various discrete cells which together forms a network so it is a network of things as opposed to a single cell there so that is what his theory was and this was eventually came to be known as the neuron doctrine refer slide time three hundred and ten although this was not a consolidated in the form of a doctrine by cajal that was done by this gentleman so he coined the term neuron so now today when you think about art here about artificial neural networks or artificial neurons the term neuron actually originated way back in one thousand, eight hundred and ninety-one and this gentleman was responsible for coining that and he was also responsible for consolidating the neuron doctrine so already as you saw on the previous slide cajal had proposed it but then over the years many people bought this idea and this guy was responsible for consolidating that into a neuron doctrine interestingly he is not only responsible for coining the term neuron he is also responsible for coining the term chromosome so two very important terms were coined by this one person so now here is a question so around one thousand, nine hundred and six when it was time to give the nobel prize in medicine what do you think which of these two proponents say there are two theories one is reticular theory which is a single cell and then there is this neuron doctrine which is a collection of cells or collection of neurons that a nervous system is a collection of neurons so what do you think which of these two guys who are proponents of these two different theories who would have got the actual nobel prize for medicine refer slide time four hundred and twenty-seven so interestingly it was given to both of them so till one thousand, nine hundred and six in fact way later till one thousand, nine hundred and fifty also this debate was not completely set settled and then the committee said both of these are interesting pieces of work we yet do not know what really actual what the situation is actually but these conflicting ideas have a place together and so the nobel prize was actually given to both of them and this led to a history of a some kind of controversies between these two scientists and so on refer slide time four hundred and fifty-eight and this debate surprisingly was settled way later in one thousand, nine hundred and fifty and not by progress in biology as such but by progress in a different field so this was with the advent of electron microscopy so now it was able to see this at a much better scale and by looking at this under a microscope it was found that actually there is a gap between these neurons and hence it is not a one single cell it is actually a collection or a network of cells with a clear gap between them or some connections between them which are now known as synapses so this was when the debate was settled so now why am i talking about biology why am i telling you about biological neuron and so on so this is what we need to understand so there has always been interested in understanding how the human brain works from a biological perspective at least and around this time the debate was more or less settled that we have this our brain is a collection of many neurons and they interact with each other to help us do a lot of complex processing that we do on a daily basis right from getting up in the morning and deciding what do we want to do today taking decisions performing computations and various complex things that our brain is capable of doing now the interest is in seeing if we understand how the brain works can we make an artificial model for that so can we come up with something which can simulate how our brain works and what is that model and how do we make a computer do that or how do we make a machine do that so that is why i started from biological neurons to take the inspiration from biology"}
{"audio_filepath": "/content/Audio_trimmed_wav/Deep Learning(CS7015): Representation Power of Multilayer Network of Sigmoid Neurons.wav", "duration": 2094.169, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module thirty-five lecture three representation power of a multilayer network of sigmoid neurons before we move on to the next modulate some small corrections from yesterday\u2019s class refer slide time thirteen so one was this partial derivative it should have been dou w square so we already taken one derivative with respect to w and now you are taking another derivative it is the gradient of the gradient and similarly should this should have been dou b square and this should have been dou w dou b refer slide time forty-three the other small thing which i wanted to say was so when i was executing this algorithm right so i forgot to mention that just notice what is happening is the black dot that you see the black dots that you see right and which are very close to each other actually because you are just making small movements those are the changes in the w comma b values and the red dots are the corresponding loss to that w comma b values right just to clarify so that is why you see a movement on the w b plane which is this movement and as you keep changing that your loss function changes and it becomes better and better right that means it goes closer to zero refer slide time one hundred and twenty-five so in this module we are going to talk about the representation power of a multilayer network of sigmoid neurons right so i am going to compare these two things which are written in the title so first tell me what was the representation power of a multilayer network of perceptrons ok i roughly hear what you are saying and basically what you are telling me is that a multilayer of network of perceptrons with a single hidden layer can be used to represent any boolean function precisely right no errors that\u2019s what we saw with that illustrative proof where we actually constructed once its network now what is the representation power of a multilayer network of sigmoid neurons so multilayer network of neurons with a single hidden layer can be used to approximate ok so just see the difference in the language so this was a represent that means exactly this is approximate that means i will tolerate some error any continuous function instead of boolean function to any desired precision so this was not this was precisely with no errors this is up to any arbitrary desired precision so what does this mean actually what is the meaning of this so there is a guarantee that for any function ok which takes our original x from r n to r m what is the m that we have been considering in all our examples one right we just care about one output but it can be r m also we can always find a neural network with one hidden layer containing enough neurons so that is the operating trace here enough neurons whose output g of x so that means you would have a network it would take as input n x it would produce some y hat and that is what i am calling as g of x right that g of x would be very close to the true function f of x so remember that we said that there is this true function f of x which gives us the true y\u2019s and we are trying to predict this y hat so the true why i am calling by f of x and the y hat i am calling by g of x and you can come up with a neural network which can give you values which can predict values which are very close to your true values does that make sense do you see the value of this theorem what is it trying to tell me tell me can you can you give me an interpretation of this why is this so useful do you know what this theorem is called universal approximations here and we did that in the history right refer slide time three hundred and fifty-seven so this was one thousand, nine hundred and eighty-nine ok what is the significance of this why do we care about such arbitrary functions and what does this theorem telling us actually it is of course telling us something about the representation power of a multilayer network of sigmoid neurons but why is this important so we will see that refer slide time four hundred and twenty-six so this the remainder of the lecture i have borrowed ideas from this url you should actually read this it is a very interesting book it is available online for free very illustrative so please take a look at it ok refer slide time four hundred and forty-one so now actually what we are interested in is we are interested in knowing whether a network of neurons can be used to represent any arbitrary function like the one shown in the figure ok so let me put some labels on this so they understand what i am trying to say suppose this is salinity again i go back to my oil mining example and i say that my decisions are based only on a single variable which is salinity and this is actually how the amount of oil varies right as the salinity increase it is a very arbitrary function it is definitely not a linear function it is not even a quadratic function it is not an exponential function it is just some arbitrary function but a mathematical function this is possible it is quite likely that salinities has this influence or in oil production or maybe it does not but i am just taking that as an example now what do we want the network to learn if i take some data and train the network at the end of training what do i want so if i feed at this point after training what should happen it should give me this value right that is what training means and that means i should be able to approximate this curve if i do that that means i have learned from the training data so let us see refer slide time six hundred now we make an observation that such an arbitrary function can actually be approximated by a lot of something that we call as tower functions these are all single i mean pulse functions which you have many of these and you could have an approximation right and you can see that this approximation is bad at many places but still it is an approximation it largely gives you the same shape as the original curve what would happen if i increase the number of such tower functions refer slide time six hundred and thirty-one student refer time six hundred and twenty-nine the approximation would improve right if i keep increasing it the approximation would go more and more better right so now just try to keep things in mind whether i write in the theorem right you can make it arbitrarily close to the actual value that means you can keep doing something so that your approximation becomes better and better and you already see something of that sort this is still in the sense of a figure we need to relate this back to a neural network but you see that as i am increasing these tower functions i become approx arbitrarily close to the actual function refer slide time seven hundred and five now this is what is actually happening right i have multiple such tower functions i am adding them up all of them are shifted in time so this tower function is actually this one this tower function is actually this one and so on right and i have not drawn the remaining ones i am taking all of these tower functions adding them up and getting my original function right and the more such tower functions have the better is the approximation refer slide time seven hundred and thirty-five now you make a few observations right all these tower functions are actually the same what is the only difference they just shifted and their magnitude changes right but they are all tower function right so let us think of this that if i know how to make a rectangle then i can make any rectangle right i just need to change the size of the rectangle and maybe shift it or oriented differently or something right so they are all similar i just need to learn how to draw a tower right that is what my quest is now if i take the original input salinity pass it through multiple such blocks each block is capable of making a tower function and each of these would give me one of these towers that i am looking for and i am looking for so many of these right if i have as many such tower makers then i could get these towers i could just add them up and then get the original function back and the more these i have the better is my approximation right so i am taking as input the salinity and trying to predict the oil does this make sense still we have not figured out a neural network way of doing this we are still building intuitions of how to do this now our job now is to figure out what goes in this black box that is the tower maker and how does it connect to neural networks if you figure that out then our story is complete then we know that a neural network can actually do this and that precisely proves the statement which i had made that it can it can represent arbitrary functions so we will figure this out over the next few slides refer slide time nine hundred and twelve now if you take the logistic function and set w to w to a very high value what will we get just try to think about it the answer is already written but i want you to imagine it w covers what student refer time nine hundred and thirty-one the slope right as i make w very high what will happen is i will get the so let us try changing the value of w ok i just increase the value of w and see what happens to the sigmoid curve refer slide time nine hundred and forty-seven some error here actually there is some problem the w value should have increased and that is how the sigmoid slope increases not the b value the b value comes later on so actually sorry about this the w value as i keep increasing so do not think that b is increasing think that the w is increasing it will become sharper and sharper and it will come very close to the step function right it will not become exactly the step function that will only become in the limit but if i keep increasing i will get very close to the step function everyone agrees with this now what happens if i increase the value of b it will shift everyone is confident about that can you tell me why student refer time one thousand and thirty-four what will shift actually the point at which the transition happens right so what is this point actually student refer time one thousand and forty-three this is the point at which i get that half value right and let us look at our function this is a function when will i get that half value when w x plus b is student zero zero right so that means x equal to minus b by w that is why it is proportional to b so as i keep increasing the value of b this will keep shifting ok is that fine everyone ok with this refer slide time one thousand, one hundred and sixteen now what if i take two such modified sigmoid functions which are shifted differently and both are very close to the step function right so here is where one threshold is here is where the other threshold is and now i subtract this one function from the other what will i get you know the term you will get a tower right is that fine everyone gets this right so these places up to this point both are zero so zero minus zero will be zero at this for this small range this is one and this is zero so that one minus zero and then afterwards both are one so one minus one would be zero so you get that tower function so now i have my tower maker refer slide time one thousand, two hundred and five now can we come up with a neural network to represent this operation i want a sigmoid neuron i was working with a sigmoid neuron with some arbitrary weights right so that i recover that step function can you imagine now given x i want this tower function and that is exactly what one of the blocks was right so what i am asking you is oh god so i am asking you to give me a neural network for this can you think of it can you try imagining it two neurons in the hidden layer how many of you agree with that ok can you can you take some more time to imagine what it would be and i have already ok right refer slide time one thousand, three hundred and seven so this w one b one if i set it appropriately i will get this step function if this w two b two i set it appropriately i will get this step function now i needed to subtract one from the other right so i will do plus one minus one this is just a simple addition and i will get this is that fine everyone agrees with this this is just a adder right this is just an aggregator everyone gets this so now i have given you the tower maker if you put enough of these tower makers and learn the w\u2019s appropriately what will you get that function that we were needed so you can approximate it arbitrarily to any precision that you want as long as you keep increasing the number of these units right so these units actually give you one tower more of these units that if you have actually this much this is the input ring the more such tower makers that you have the more is the bars that you will get and then you can approximate everyone gets the intuition behind this fine ok this all is always good in one dimension refer slide time one thousand, four hundred and twenty-one now what will happen in two dimensions what if we have more than one input what is the tower there do you do you guys all do all know what is the tower there if you say no i will give you a zero on the assignment remember the last question of the assignment did you all make a tower did you all make a 2d tower did you all copy that no so what if we have more than one inputs suppose you had again trying to take a decision about whether we will find oil at a particular location of the ocean right and suppose now we base it on two two right so say this is salinity this should be x one should be x two should be y and this is pressure now just observe about the red and blue points so the red points are where you will not for those configurations of salinity comma pressure you will not find oil and the blue points are for which you will find oil what is the one thing that you can tell me about the red points and the blue points not linearly separable right but we still want to be able to learn this is that fine a single perceptron cannot do it i will also make a case for a single sigmoid neuron cannot do it and then i will show you that in fact first i will show you that with a network of neurons we can do it and then i will show that with a signal single sigmoid neuron you cannot not actually do that so now this is again a valid problem you could have we could imagine that you will get this kind of data where you have two factors and your function is some arbitrary function of these two factors it is not a need linear boundary between the blue and red points everyone sees that the blue and red points are not linearly separable you cannot draw a plane such that all your red points lie on one side and the blue points lie on the other side everyone sees that ok but the solution which i have plotted here that is a good solution it makes sure that all the red points are in this region and the blue points are outside so it will predict a high value for these red points and a zero value everywhere for the blue points is that obvious how many of you understand that figure ok good refer slide time one thousand, six hundred and forty-six so now i want to show that even in 2dimensions i could come up with arbitrary i could come up with a neural network which could actually approximate this and again what will i look for a tower maker right i just want something which can make towers and approximate it refer slide time one thousand, six hundred and forty-eight so this is what a 2dimensional sigmoid looks like slightly incorrect because i have what i have done is i have actually said w two to zero so if you actually i would want you to do this go back and plot this for w one equal to three and w two equal to three just go back and plot this and see what you get you will not get such a smooth such a nice looking s but you will still get something which looks like looks like a snakes hood right so in still get that s shaped function it just that it would be bent at some points and it be thinner at some points and broader at the other points so just go back and see and then you will realize what is happening right refer slide time one thousand, seven hundred and twenty-nine so here again what we want to figure out is from the single sigmoid i was able to take you to a tower function right from a 2dimensional sigmoid what does a tower mean here and how do i take you to the tower so that is what i want to do so i have said w two equal to zero and i will it will become obvious why i have done that so just understand what the figure is doing right so this if you just look at this is like the cross cut right so you are looking at the front view of this figure and that is just the sigmoid function without the w two right and now since i have said w two equal to zero no matter what i set x two to the same function will get repeated throughout that axis do you get that so that is why this entire function is just getting repeated throughout this axis and then you just get a similar s shape function everyone gets that how many of you do not get that how many of you get that so this if you look at the front view this is the sigmoid of one variable but since i have said w two to zero no matter what i change x two to the function is going to remain the same so it will just get copied throughout the x two axis is that fine with you now what will happen if i increase w two sorry w one same thing right it will just keep shifting till it becomes almost like a 2d step function ok now what will happen if i increase b shift i can do the same thing here also same logic applies here also ok refer slide time one thousand, nine hundred and twelve now what is the next step that i am going to do take two of these which are shifted by some point and then subtract what will i get everyone had this figure in mind so just see right so this portion both are zero so zero minus zero would be zero this portion this is one but this is zero so that would be one minus zero and again in this portion both of them are one so one minus one would be zero so you will get this kind of function would you like to live in such a tower i am very serious yes or no no why it is open from two sides right you cannot live in this tower so you want something which is a closed tower right so how will you do that give me an intuition we will do the reverse thing what will be set to zero w one ok refer slide time one thousand, nine hundred and fifty-eight and this is how it would look the orientation would change and again so notice that this is your sigmoid function and since i have set x one to zero no matter what i change along the x one axis the same function gets copied and you get a nice looking a sigmoid function now again i will do the same thing i will increase the w i will get a close to a step function i will increase the b i will move along this axis refer slide time two thousand and twenty-four next step take two of these subtract get what another tower function this is also not a tower that you like to stay in so what do i do now add them sure add this tower to the other tower refer slide time two thousand and forty-four so now what will happen if i add these two will you get a tower function what will you get you will get a tower function with a parking floor right is that what you will get everyone understands why this is so these portions both are zero so you get zero same logic applies for all the four corners right is that fine now for this portion or rather this area right so this guy is zero this guy is one so you will get a one the same logic applies for all these four corners in the centre both are actually one so one plus one would give you two so this is two this is level two this is level one this is level zero is that fine so what am i done so far i have taken my x one x two passed it through some transformations right this what are these transformations we will see but transform it through these multiple hoops right where i adjusted a w\u2019s and b\u2019s and i have got some z right and this is how that z behaves for different values of x one comma x two i will get these different values and these values range from zero to one to two is this pictured clear i have taken my original x one comma x two passed it to some of these transformations and irrespective of what my x one to x two is this tells me the entire range of values that i will get for some combination of x one comma x two i will get zero for some combinations i will get one for some combinations i will get two and some combinations also between one and two right so these places where it transitions is that clear is that picture clear to everyone so now i can treat this as the output z ok now from here how do i go to a tower threshold it how will you threshold it what do you want you only want this much part to exist right this without the parking floor how will you do it any output which is greater than equal to two you want to keep it any output which is less than two you want to make it zero if i do this will i get a tower right sorry greater than equal to one any value which is greater than equal to one you want to keep it anything which is less than one you want to make it zero so this entire thing will get demolished how do you do this this is an if else ok if else if something is greater than equal to zero do something else do something else what is that perceptron right but we do not want to use perceptron we want to use sigmoid neurons have you learned an approximation from a sigmoid neuron to a perceptron very high w right you get the intuition let us see what we do on the next slide refer slide time two thousand, four hundred and seven so i take this any z which comes from here i will pass it through a sigmoid neuron which are very high slope such that the threshold is at one anything which is greater than one will pass out as one anything which is less than one will go to zero so everyone sees how we took this structure and converted it to a tower we have this tower now now what do i do with this refer slide time two thousand, four hundred and thirty-four i lead multiple such towers and i can approximate this i could put a tower here here here and so on i could have these multiple towers and here of course all my towers would be of zero height right in this region right so now i can cover the entire 2d space with a lot of tower functions and approximate this exactly that is a very weird statement approximate this exactly i mean approximate this to arbitrary precision everyone gets this do you see why we constructed these tower functions and now we can put them inside this cone and approximate it refer slide time two thousand, five hundred and nine now all this is fine i was making some towers there so can you now give me a complete neural network which does this i want you to imagine that remember you are taking what i am asking you to do is this x one x two give me this such that i get this two dimensional tower i do not know how to draw it something like this maybe whatever so i want this 2dimensional tower what is this network of perceptrons going to look like just go back to all the operations that we did and try to imagine in your mind no we will not use perceptron because we can always use a sigmoid neuron instead of a perceptron with the high w i do not expect you to answer this i just want you to imagine right we just try with a there is something known as a pen there is something on a paper ok so here is the solution refer slide time two thousand, six hundred and eight so what is happening here you have this salinity and oh actually this is slightly wrong i do not know why you guys saying it is correct actually at both places i need both the inputs it is just that in one case i do not care about that input because i have said w two to zero so i learn these weights w1 w2 b w1 w2 b of course here the network should learn that w two is equal to zero right and then you get this one tower do not needs this to be modified this figure is incorrect so we need x one x two both as inputs we need to label it with w one w two equal to zero and b and so on it so we will discuss this later anyways but you get the idea right that you take these two inputs make one tower take the inputs again make another tower add them up to get this function pass it through this step neuron function step sigmoid function so that you get the tower so this is one block you will have many such blocks each of which will learn different w\u2019s and b\u2019s so that they get shifted and then you will place them all together you have an aggregator on top of this which will combine them just a minute how many of you get this ok good yes so that is a good question i am going to come to that right so i have very conveniently given you a solution where i have what is the bad thing that i have done i have hand coded these things right i have hand coded w ones w twos and b\u2019s is that fine in practice no i mean that is where we started off and we do not want to hand code these right so now you know a learning algorithm for a single sigmoid neuron now what you have is a network of neurons right for this network of neurons i need to give you a learning algorithm driven by the objective function that whatever output it gives would be very close to that arbitrary function that you are trying to model if i give you a learning algorithm then you would be convinced that if this has to be minimized and the weight configuration which need it needs to arrive at as w two is equal to zero then the algorithm should be able to do that right because we saw we have some faith in these algorithms in the case of a signal sigmoid neuron that with the right objective function it will give me a principled way of reaching that objective function in this big network my objective function is to arbitrarily to approximate this of this true function right so now if i give you that as the objective that whatever outputs the network generates so the network might generate something like this so that has to be very close to the true output that is the objective function that i am going to use in that learning algorithm and if that learning algorithm works which will prove then you should be able to arrive at the necessary weights to make this approximation right is that clear and in fact there might you might not even have to do these multiple towers in practice all i am trying to prove is that there is one solution which exists if there is one solution which exists i can say that locate the network can learn that is the only claim i make i am not saying this is the only solution right same as in the case of the boolean functions where i said that one solution exists where you have to raise to n neurons of the hidden layer that was a sufficient solution that was not a necessary solution for the and function we were actually able to do it with a single sigma neuron right so just keep that in mind i am just giving you a sufficient solution and the network could actually learn something better than this all right this is again a very bulky solution why it scales with the number of neurones\u2019 proportional to number of input variables that you have so that is for a sufficient solution but you would want something better than that all i am trying to say is that it can approximate i am just telling you the representation power and just as we had the catch there that the hidden layer is very large the same catch applies here also is this story clear to everyone so i have given you a solution i have not told you how to learn the weights i have given you a network now later on we will discuss a learning algorithm for this network and we will have some confidence that given a particular objective function that learning algorithm can strive to go to minimum error or minimize the quantity of that objective function that is going to come in two lectures from now is that fine refer slide time three thousand and thirty-two and that was for the tower function now i could have actually directly done this right so i wanted to approximate these functions so i could have placed a lot of these kinds of things here and approximated it right so that instead of that very high slope sigmoid function i could just use a normal sigmoid function also ok and again there is a error here but i hope you get the picture it is just that you feed both the inputs to them refer slide time three thousand and fifty-six so for one dimensional input we needed two neurons to construct a tower for two dimensional input how many neurons did we need i am just counting these because these are simple aggregators right and this is one constant at the end so how many did we need actually o of two n i mean o of i mean so for n how many would we need let us try to work that out ok so i will ask you that in the quiz how many do we need for n dimensions refer slide time three thousand, one hundred and thirty now why do we care about approximating any arbitrary function we will again try to close the loop now we saw that we can arbitrarily we can approximate any arbitrary function but now again i want to come back to the point why do we want to do this and can we tie this back to the classification problem that we were dealing with refer slide time three thousand, one hundred and forty-seven and this is the data which i had given you which was there were some points some values of x and y sorry this should be x one and x two it is where this is pressure and salinity or salinity tendency and this is the output which is oil now there was this is what the function actually looks like now what would have happened if i had used a single sigmoid neuron to try to approximate this function try to represent this function and sigmoid neuron in two dimensions right so the two dimensional sigma what would have happened can you give me one solution for this remember earlier i had said that perceptron cannot handle data which is not linearly separable but then i anyways used it for data which was not linearly separable and we got some line such that we got some errors the red points and the blue points are not clearly separated so i am asking you for a similar thing here i force you to use a sigmoid neuron what would you give me refer slide time three thousand, two hundred and forty-seven is this fine this is one of the possibilities of course it could have been oriented differently and several things what is happening here is that for these blue points it is acting correctly but for these red points it is not acting correctly i am assuming red is positive and blue is negative i think that should have been the other way round but let us assume red is positive and blue is negative again now for these red points this part is working fine but it is misclassifying all these blue points so all these bad locations is actually saying that you can find oil and for all these good locations here it is saying that you cannot find oil that is what a sigmoid neuron would do and you could have multiple solutions are possible here right but all of them would have this problem that will make errors on some red points and some blue points right but the true solution that we wanted is something like this again there are multiple solutions possible right you could have anything there are you could have even finer one side you could just have this much there many things possible this is one such solution what the illustrative proof told you is that you can actually use a network of perceptrons and approximate this arbitrary function which exists between the input variables and the output variable so if this is the function which exists between the input variables and the output variables now you could take these multiple two dimensional tower functions and approximate it with the catch that you might need many of these in the hidden layer but you can still do that ok so that is why this in theorem important because now any problem that you take right any problem that you will have in machine learning would always want you to take an x learn a function of x which takes you to y this function will be have some the function will have some parameters right and now what this theorem is saying is that you could adjust these parameters such that you can arbitrarily come close to the true function right so that is the significance of this any machine learning problem that you can think of in the sense of classification or regression you would find that this is useful and i am giving you a very powerful tool to do that of course with the catch that i am not giving you any bound on the number of neurons that you will need i am just saying use as many as you want"}
{"audio_filepath": "/content/Audio_trimmed_wav/Deep Learning(CS7015): Learning Parameters: (Infeasible) guess work.wav", "duration": 672.981, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module \u2013 thirty-three learning parameters infeasible guess work lecture \u2013 three in this module we will try to learn these parameters and initially we will try to learn them by guesswork and i will show that that is actually infeasible that is why we need a more principled approach refer slide time twenty-six so we will keep the supervised machine learning setup in mind and now we will focus on this model and discuss an algorithm for learning the parameters which are w and b given some data using a giving appropriate function objective function so that is what we are going to focus on refer slide time forty-seven now sigma here stands for the sigmoid function the logistic function in this case when this sigma is actually the logistic function and now i am going to simplify this further so that it helps us to do a better analysis i am just going to consider the case where i am just in one input and the bias ok and also following the normal terminology in the literature this w naught from now on i am going to call it b because that is the normal convention b stands for bias so i have two parameters w and b which i need to estimate ok and this is my model for the movie example and the other change which i am going to make is instead of deciding whether i like or dislike which is one zero the setup that i am going to work with is that i am giving the critics rating and i want to predict the imdb rating so i am given a real value and i also want to predict a real value for no particular reason this just makes life easier for me for explaining a few things but the same thing or the same algorithm would also hold if you add a binary output right and you will see that later on in the course so here is a setup clear we just have two parameters w and b and we are going to assume that y belongs to real numbers it is a imdb rating and x also belongs to real number it is a critics rating refer slide time two hundred and five now let us see what we are given as training is a set of points we are given some n training pairs and now we understand what this means that means for a lot of movie i am giving the critics rating and i am also given the true imdb rating for them of course in the two variable case this does not make much sense but just bear with me and now the training objective is such that whatever my function predicts which is a function of w x and b that should be very close to the true output that i know this is the function that i want to optimize now let me ask you this refer slide time two hundred and thirty-seven i am trying to tell you that i am going to give you an algorithm for training this network suppose i have trained this with two data points five comma two and twenty-five comma nine right at the end of training i will give you some values of w and b let us call them w star and b star these are the final values of w which i have given w and b what do you expect from these values what do you expect at the end of training if i say now the network has learned what do you expect you are still going to the test case i am just talking about the training still we expect such that what happens if i plug in at the end of training if i plug in the value five here what should happen nine so this is what you expect at the end of training if you plug in the value five it should be very close to two the output and if you plug in the value twenty-five it should be very close to nine this is exactly what you expect and this is what training means ok fine in other words we hope to find a sigmoid function such that these two points lie on that function can you imagine a geometric picture for this what would happen actually how many if we can imagine it ok how many of you get it now this is what will happen right so you will get a sigmoid function such that these two points lie on that fair ok and that exactly means that when i plug in this value i will get this value and when i plug in this value i will get this value right so that is what it means refer slide time four hundred and nine so let us see this in more detail refer slide time four hundred and ten and now what we will do is our quest is for this w star and b star i will try to find this manually i will do some random guesswork and try to find this because i do not have any clear principle algorithm for finding it as of now so i will just use some guesswork so i will give my initial guesswork as w equal to five b equal to zero for no reason i just picked up some values right and this is what the function that i got what does this mean this function an error so the sigmoid formula should be here we should have this sigmoid formula here so is this a good are you happy with the solution if i give you are you happy with this solution is this good bad ugly has to be something bad we will not call it ugly ok so why is it bad it is not passing through those points i will ask you a question how bad is it can you assign a number to it we are always good at qualitative stuff but quantitatively can you tell me a number how bad is this can you tell me a way of finding how bad this is i already told you in detail how to find that how bad it is the loss function right refer slide time five hundred and twenty-seven we have the loss function let us see that again and see if we can find out how bad this is refer slide time five hundred and thirty-two so this is what my loss function is ok and i have two data points i will just expand it out fine now i will plug in the values i know this is nine and i will compute the value of f twenty-five i will plug in this and i will plug in this ok and this is what i get so this is how bad it is what did we actually expect it to be in the good case zero so this is not zero this is seventy-three so now we have a quantitative handle on how bad this is ok so let us keep this in mind and let us try to continue guessing so we want the loss function to be asked close to zero as possible we are not there yet refer slide time six hundred and fourteen so then i make a different guess i say let me try minus ten zero what happened now is it now good bad ugly now let us call it ugly right so it is worse and how do i know it is worse because i plugged it in to the loss function and i got a value which is greater than the value at which i was so i clearly know this is bad so now this is how my mind is working right oh i as far as w was positive things looked at least i was close to zero in the first decimal now when i made it negative that does not look good so let me just keep it positive and keep increasing it right so i saw ninety-four and i also tweaked the b of it i have done complete random guesswork right now what happened good bad ugly better ok now what will you do what would your next case would be make w even more positive perhaps that would help and be even more negative and so on i can continue in this manner and actually get close very close to the solution so i can do this guesswork and find these values but it is still an educated guess right i am not guessing in the dark this is what is helping me drive towards those guesses and i am just looking at these values and making an educated guess right and that is the educated guess which i took that probably making w even more positive would help but this is still brute force in a sense right this is not something that you would want to do when you have one hundred one thousand parameters and so on right and one million data points and so on refer slide time seven hundred and forty-two so let us look at something which is better than our guesswork algorithm ah so we are not there yet actually on the next slide i am still going to talk about the guesswork algorithm refer slide time seven hundred and fifty-three and eventually we will get to something which is better than the guesswork that ok so since we have only two points and two parameters what i can do is i can take all possible values of w and b right that is what i was trying i was picking up some values of w and b why just pick some values of w and b i will pick all possible values of w comma b right and i will fix the range i cannot fix pick it from minus infinity to infinity but i will pick a range i will say from minus six to six let me try all values of w comma b compute the loss and plot it right let me tell something about this error function because this is going to stay with us for quite some time so what you see here is something like a flying carpet this is colour coded red is bad red are the places where the error is high blue is good blue are the places where the error is low darker the shade of blue lower the error darker the shade of red higher the error so in particular if i look at this point what has happened is i have taken the corresponding value of w comma b right which is say minus four comma minus one right something like that i have plugged that value into my loss function and i got this as the loss function this has the loss value and that is what i have plotted for all values between minus six to plus six and minus six to plus six for w and b so everyone understands how i have constructed this error surface now this of course becomes and now what i can do is once i see this error surface i know how good this is the point where i need to be this is the darkest ah shade and this is where the error is the lowest so i can just pick a w comma b value which lies there this is fine for this toy example where you just have two parameters but this becomes untractable once you have more data points and many more parameters and that is what happens in most real world applications right so this is not a feasible way of going about things right and here again note that i have only taken the range from minus six to six i do not even know what will happen if i have to look at all values of w comma b right maybe there was something outside here right which was even more lower error or something right so i do not really know that so i cannot really use this so i need something better than this plotting the error everywhere and finding it order that is pure brute force or surrogate to this was the guesswork algorithm but which is again something we cannot do for if you have large number of parameters so everyone gets this that this is a way of finding the solution but this is not feasible right that is the only point i am trying to make refer slide time one thousand and twenty-four and we look at the geometric interpretation of what was actually happening in the case of the guesswork algorithm with respect to the error surface refer slide time one thousand and thirty-three so i had chosen some values of w comma b the first value that i chose actually gave me an error of if you remember it was some seventy-three or something like that right so that is the point then i decided to take a very random guess and my error actually increased so you see that i am actually climbing up on this error surface i have gone from a slightly darker shade of blue to a lighter shade of blue right and then i corrected myself and then kept moving in a direction where i was going towards the darker and darker shades of blue so what i was actually doing is i was trying to traverse the error surface and land up in the good regions which were the dark blue regions now what i want to do is i want an algorithm which will allow me to do this in a principled manner which is neither brute force nor guesswork so that is what we learn in that module"}
{"audio_filepath": "/content/Audio_trimmed_wav/Perceptrons.wav", "duration": 619.072, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module twenty-three lecture two perceptron now let us go to the next module which is perceptron refer slide time eighteen so far the story has been about boolean input but are all problems that we deal with we are only dealing with do we always only deal with boolean inputs so yeah so what we spoke about is boolean functions now consider this example this worked fine for a movie example where we had these as actor so much and his director and so on but now consider the example where you are trying to decide you are in oil mining company and you are trying to decide whether you should mine or drill at a particular station or not now this could depend on various factors like what is the pressure on the surface on the ocean surface at that point what is the salinity of the water at that point what is the aquatic marina aquatic life at that point and so on so these are not really boolean function the salinity is a real number density would be a real number pressure would be a real number and so on right and this is a very valid decision problem companies would be interested in doing this so in such cases our inputs are going to be real but so far mcculloch pitts neuron only deals with boolean inputs so we still need to take care of that limitation now how did we decide the threshold in all these cases i just asked you you computed it and you told me right but that is not going to work out i mean it does not scale to larger problems where you have many more dimensions and the inputs are not boolean and so on so we need a way of learning this threshold now again returning to the movie example maybe for me the actor is the only thing that matters and all the other inputs are not so important then what do i need actually i need some way of weighing these inputs i should be able to say that this input is more important than the others now i am treating all of them equal i am just taking a simple sum if that sum causes a threshold i am fine otherwise i am not fine but maybe i want to raise the weight for some of these inputs or lower the weight for some of these inputs so whether it is raining outside or not maybe does not matter i have a car i could go or i could wear a jacket or an umbrella or something so that input is probably not so important and what about functions which are not linearly separable we have just been dealing with the goody stuff which is all linearly separable but we will see that even in the restricted boolean case there could be some functions which are not linearly separable and if that is the case how do we deal with it so these are some questions that we need to answer refer slide time two hundred and thirty-five so first we will start with perceptron which tries to fix some of these things and then we will move forward from there so as we had discussed in the history lecture that this was proposed in one thousand, nine hundred and fifty-eight by frank rosenblatt and this is what the perceptron looks like do you see any difference with the mcculloch pitts neuron weights you have a weight associated with each of the input otherwise everything seems so this is a more general computational model than the mcculloch pitts neuron the other interesting thing is that of course we have introduced these weights and you also have a mechanism for learning these weights so remember in the earlier case our only parameter was theta which we are kind of hand setting right but now with the perceptron we will have a learning algorithm which will not just help us learn theta but also these weights for the inputs how do i know that actor is what matters or director is what matters given a lot of past viewing experience past given a lot of data about the movies which i have watched in the past how do i know which are the weights to assign this so we will see an algorithm which will help us do that and the inputs are no longer limited to be boolean values they can be real values also so that is the classical perceptron but what i am talking about here and the rest of the lecture is the refined version which was proposed by minsky and papert which is known as the perceptron model so when i say perceptron i am referring to this model so this diagram also corresponds to that refer slide time four hundred and six so now let us see what the perceptron does this is how it operates it will give an output of one if the weighted sum of the inputs is greater than a threshold so remember that in the mp neuron we did not have these weights but now we have these weighted sum of the inputs and the output is going to be zero if this weighted sum is less than threshold not very different from the mp neuron now i am just going to do some trickery and try to get it to a better notation or a better form so is this i have just taken the theta on this side now is this notice this here the indices were one to n now i have made it zero to n and the theta is suddenly disappeared so what has happened student w zero is minus theta right and x0 is one does anyone not get this right if i just start it from one to n then it would be summation i equal to one to n wi xi plus w0 x0 but i am just saying w0 is equal to minus theta and x0 is equal to one which exactly gives me back this right so very simple x0 equal to one and w0 is equal to minus theta so in effect what i am assuming is that instead of having this threshold as a separate quantity i just think that that is one of my inputs which is always on and the weight of that input is minus theta so now the job of all these other inputs and their weights is to make sure that their sum is greater than this input which we have does not make sense so this is how this is the more accepted convention for writing the perceptron equation so it fires when this summation is greater than equal to zero otherwise it does not fire refer slide time six hundred and seven now let me ask a few questions so why are we trying to implement boolean functions i have already answered this but i will keep repeating this question so that it really gets drill in why do we need weights again we briefly touched upon that and why is w naught which is negative of theta often called the bias refer slide time six hundred and twenty-five so again let us return back to the task of predicting whether you would like to watch a movie or not and suppose we base our decisions on three simple inputs actor genre and director now based on our past viewing experience we may give a high weight to nolan as compared to the other inputs so what does that mean it means that as long as the director is christopher nolan i am going to watch this movie irrespective of who the actor is or what the genre of the movie so that is exactly what we want and that is the reason why we want these weights refer slide time six hundred and fifty-eight now w0 is often called the bias as it represents the prior so now let me ask a very simple question suppose you are a movie buff what would theta be zero i mean you will watch any movie irrespective of who the actor director and genre now suppose you are a very niche movie watcher who only watches those movies which are which the genre is thriller the director was christopher nolan and the actor was damon then what would your threshold be three high in this case i always ask this question do you know of any such movie always takes a while interstellar so the weights and the bias will depend on the data which in this case is the viewer history so that is the whole setup that is why you want these weights and that is why you want these biases and that is why we want to learn them refer slide time seven hundred and forty-eight now before we see whether or how we can learn these weights and biases one question that we need to ask is what kind of functions can be implemented using the perceptron and are these function any different from the mcculloch pitts neuron so before i go to the next slide any guesses i am hearing some interesting answers which are at least partly correct refer slide time eight hundred and eleven so this is what a mcculloch pitts neuron looks like and this is what a perceptron looks like the only difference is this red part which is weights which has added so it is again clear that what the perceptron also does is it divides the input space into two halves where all the points for which the output has to be one would lie on one side of this plane and all the points where which the output should be zero would lie on the other side of this plane so it is not doing anything different from what the perceptron was doing so then what is the difference you have these weights and you have a mechanism for learning these weights as well as a threshold we are not going to hand code them so we will first revisit some boolean functions and then see the perceptron learning algorithm refer slide time eight hundred and fifty-five so now let us see what does the first condition this condition if i actually expand it out then this is what it turns out to be and what is that condition telling me actually w naught should be less than zero clear so now based on these what do you have here actually what is this a system of linear inequalities right and you know you could solve this you have algorithms for solving this not always but you could find some solution and one possible solution which i have given you here is w0 is equal to minus one w1 equal to eleven and w2 equal to eleven so just let us just draw that line so what is the line it is eleven x1 plus eleven x2 is equal to one that is the line and this is the line and you see it satisfies the conditions that i have is this the only solution possible no right i could have this also as a valid line if i could draw properly right all of these are valid solutions so which result in different w1 w naught and w 0s so all of these are possible solutions in fact i have been telling you that you had to set the threshold by hand for the mcculloch pitts neuron but that is not true because you could have written similar equations there and then decided what the value of theta should be so you could try this out for the mcculloch pitts neuron also you will get a similar set of conditions or i mean similar set of inequalities and you can just say what is the value of theta that you could set to solve that"}
{"audio_filepath": "/content/Audio_trimmed_wav/Backpropagation: Computing Gradients w.r.t. Hidden Units.wav", "duration": 1221.227, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module \u2013 forty-six lecture four back propagation computing gradients w r t hidden units now we will go to the gradient with respect to the hidden units refer slide time sixteen so this portion so you already see there is a repetition here and i do not need to treat each hidden unit separately i can just have a formula for the hidden unit and then i could compute it for all the hidden units so that is what our aim is so let us do some simple stuff first and then you will come back to it refer slide time thirty-three so suppose you have a variable x you compute two functions from that one is x square the other is x cube i will call this as y one and i will call this as y two and i take y one and y two and compute a z which is say a log of y one by y two now what i am interested in is this what is the answer for this how do you get this this is a fair question to ask y one y two are functions of x z is a function of y one y two hence z is a function of x so i can compute this derivative and i can ask for this derivative how would you compute it if i cannot really do this right so if this path did not exist then it is trivial it is just the chain rule along one path but now you have two paths so what will happen add them right so can you tell me a formula for that so let me know if this makes sense to you ok does this make sense now let me complicate this a bit just let me just do it as y three now student refer time two hundred and fifteen what will happen student refer time two hundred and sixteen that is all right so you see that if there are multiple paths you can just add up the chain rule across all these paths right that is what chain will across multiple paths does refer slide time two hundred and twenty-eight so with this we will go back to this figure so now i am interested in i am interested in going to the hidden layers again i will do this to bit calculation where i first asked for this guy and then i will ask for the light blue guy right and am going to look at one unit at a time now what is the what am i interested in the derivative of the loss function with respect to say d h two two right the second unit of the second hidden layer refer slide time two hundred and fifty-eight now what i am going to say here is exactly what i had written on the previous slide this was our final function right which was z so z was sorry again i have not chosen my variables well ok but if so we had exactly the same situation right which is which you see here ok so we will just have to sum up the derivatives partial derivatives across all the paths which lead from this guy to this guy and there could be as many paths as there can be but i do not care i will just sum across all those paths in fact actually here there are not just two paths because we have always assumed there are k classes so there are actually k of these paths right so this form this is exactly the formula which i wrote on the next slide right this one but just written in terms of the network that we are dealing with so you can just go back and look at this but as long as you understand this figure you from my point of view we can go ahead so everyone understands this figure that we just need to compute the derivatives across all the paths and add them up refer slide time four hundred and three so now let us start we again the same recipe we will compute it with respect to one guy and then go towards the gradient so what is this now let me explain right so dl theta there are k of these guys between right so there are k paths so this summation has to happen over k paths just as you told me when there were two paths the summation was two three paths to three that is k paths of the summation over k guys the derivative with respect to each of these guys and the k\u2019th the m\u2019th unit rate that is the index that i am iterating over and then the derivative of this guy with respect to whatever you are interested that is just that there are only two nodes in the path in the chain but there are k such chains how many of you exactly get this ok how many of you have a problem want me to repeat this you have problem oh many of you ok good please do this so i am interested in this quantity that means i am interested in the partial derivative of this loss function with respect to this guy refer slide time five hundred and six and this guy is nothing but h ij that much is clear is the j\u2019th unit of the i\u2019th hidden layer in fact this is actually h two two so my i is equal to two and j is equal to two now i just made a case on the previous slide that if you have such a function which first computes some intermediate values and then your final function is computed based on all these intermediate values right and now you are trying to find the gradient the partial derivative of this with respect to the original input that you had so then what you will do is you will sum across all the paths that lead from this guy to the output how many such paths are there you already see two such paths here right but i am saying there are k such paths because there are some other nodes here which i have not drawn we have already said that in the output layer we have k nodes right so there are k paths so that takes care of the first bit that the summation is going to be over the k paths now what is each of these paths composed of this intermediate value and this quantity that we are interested in first we will take the derivative of the out of the loss with respect to this intermediate value what is that that is the unit in the that is the unit in the previous layer or the next layer rather so i am interested in i so i am looking at the unit in the next layer hence i plus one right because that is what comes in my path the next layer is what comes in my path we have always the special case that this guy feeds into k guys but all the other hidden units before that feed into n guys right so that is let us just keep that complication aside for the minute and we just look at this case ok is that fine so we have agreed there are k paths and each path is composed of these two nodes from the last loss function to this intermediate value and then from this intermediate value to the quantity of interest and why is this i plus one because the next node in the path when i am at the i\u2019th layer so i will be feeding to the i plus 1\u2019th layer right and in fact i will be feeding to all the nodes in the i plus one th layer that is why i am taking or all the k paths right and then that node which is this node with respect to the quantity that i am interested in is this clear now right this is very similar to the toy example which i did i just have k paths now instead of two paths there so let us move ahead now what is ok which of these quantities do we already know is there any quantity that we know this one why because in this special case i plus one is actually equal to l right because we are feeding into the last layer and they have already seen how to compute the partial derivatives with respect to the last layer so this quantity is known we do not know this for the generic case yet but we will get that but for this special case when we are feeding into the last layer we know this does everyone get this ok now do we know this quantity so what you have told me is that we know this quantity because that is what we have computed in the previous module do we know this quantity we have to compute it can you compute it ok let us just do it right so let us assume that this hij that am dealing with is actually h two two ok fine now what is a i plus one m actually which are the elements there a three one and a three two i am assuming that i only have two units in the output layer ok so my m is equal to two now is this fine this is how the next layer is related to the current hidden layer plus biases ok now what am i interested in one of these guys ok let me take one of these guys so can you tell me what is a three one first row multiplied by the first column there is only one right plus b two one student refer time one thousand and eleven sorry student refer time one thousand and twelve b three one now let me just clarify something what is this in terms of variables i j k m what is this this is i this is j this is k this is m this is i plus one right ok this is one of the ms that i am dealing with now i want the derivative of this with respect to hij in fact i want it with respect to h two two where this is i and this is j is this clear what is this derivative w three one two everything everyone fine with this now help me find this what is this ijkm and i plus one what is this this is coming from the m how many of you see this because that is the unit that you are connecting to and this is j so what is the formula how many as many as the number of neurons in the next layer a bias will be connected to all the neurons in that layer right everyone gets that right there are only two units so there will be only two guys ok so what is the formula for this w i plus one mj everyone comfortable with that ok fine you can just go back and look at this and it should be cleared right so whenever you are dealing with vectors and matrices right if you are really good at it you can imagine the entries and figure out what is happening if you are not good at it do not be lazy just work it out right you just need to write down this product and at the end remember everything is always element wise and you are never dealing with a vector or matrix now just dealing with the individual components of them so you should always be able to compute these derivatives or partial derivatives with respect to the individual components and that is exactly what i did here right if you just work it out if you just write it out then you will always get it if you cannot but eventually try to get to a point where you can just visualize it but if you cannot at least try to work it out refer slide time one thousand, two hundred and twenty-five so this is what it will look like ok now consider these two vectors one is this vector what does this vector look like this is a collection of all the partial derivatives so this is just a collection of all the partial derivatives nothing new we have already seen this now what is this vector actually in fact i have started with the matrix and i am saying look at this vector what does this mean this i plus one is just the layer in which the matrix is right so that index we do not really care about for a matrix what we care about is the i comma j index ok now what does this dot comma j mean all the i\u2019s belonging to j that means the dash column j\u2019th column everyone gets this this is all the i\u2019s or all the entries belonging to the j\u2019th column so it is effectively just the j\u2019th column so it is one comma j two comma j up to k comma j right so these are two valid vectors now tell me what is this quantity going to be this is the dash between two vectors dot product dot product between two vectors is a student refer time one thousand, three hundred and forty-three is a summation over element wise thing ok i have said enough now try to connect this is a very simple maths the column that you will ever get in your life try to connect this to something which is already there in the slide how many of you think the answer is this this into this plus this into this plus this into this and just write it as a formula you will get this everyone sees that ok so now i have a compact way of writing one of these entries refer slide time one thousand, four hundred and ten one of these guys i have a compact way of writing this it happens to be the dot product between two vectors one of them is the gradient but do i know this already do i know this quantity already in this special case yes because i plus one is equal to l and that i have already computed this of course i know right because these are the weights that i am dealing with where do i go from here this dot yeah it means anything from that column so that means the entire column student refer time one thousand, four hundred and forty-eight ah no these are weights right so this is a weight matrix it has columns and rows i am talking about the j\u2019th column so i fixed the value of j i am talking about the j\u2019th column but i am not telling your given i\u2019th entry there am just telling you all the entries there that just means the j\u2019th column you can take this offline ok this is very simple i will take it offline ah now where do i go from here student refer time one thousand, five hundred and sixteen i plus one student refer time one thousand, five hundred and twenty ok no in this specific case are we done student refer time one thousand, five hundred and twenty-seven where are we right now with respect to one unit where do we want to go the entire thing so what is the quantity that i am interested in gradient with respect to always say with respect to h i right student refer time one thousand, five hundred and forty-four where i is two in this case this special case ok what is that going to be collection of all these guys that you have already computed ok now simplify this what is this first column of the matrix multiplied by the same vector the second column of the matrix multiplied by this vector the nth column of the matrix multiplied by this vector this reminds you of something very very difficult this is a very very complicated matrix multiplication right first row of the matrix multiplied by a column the second row of the matrix multiplied by column how many if you get this right so this is can you tell me what this is wi plus one transpose student refer time one thousand, six hundred and fifty-two perfect right so now you see that this entire quantity we can compute in one go by using a matrix vector multiplication right so that is what i meant when i was saying that we should not be doing these unusual computations but we able to compute that at one row right so now we can just do this matrix vector multiplication and get this entire quantity ok now what is still missing in this module so what is the special case that i have assumed i told you that i already know these quantities but only if i plus one is equal to l i need to tell you this in the generic case ok so we are almost there except that i do not know this when i is not equal to l or i is less than equal to l minus one ok that is the case that i am looking for refer slide time one thousand, seven hundred and thirty-eight so that is again very simple again what will i do i will compute it with respect to ok what is this this is the guy that i am interested in the generic i not the l\u2019th one right the generic i this is what the vector looks like the gradient vector looks like i want each of these guys ok now i will take one of those and i will write it as this ok what am i doing am saying that i already have the entries up to here ok at a very general level even here i could have said the same thing remember that i had said that the output layer you can always write as hl right so even at the output layer i could say this chain rule always holds how many of you agree with that i want to go from the loss function to one of the lighter blue guys so am saying that i can go through the intermediary dark blue guys that is all i am saying i have just compressed this entire path into up to the dark blue guy remember i had said earlier that i will be compressing this chains now how many of these quantities do you know the first one is what we computed on the previous refer time one thousand, eight hundred and fifty-two the second one looks very difficult sorry so h ij is nothing but sigmoid of a ij or any nonlinearity of the a ij so i can just write this derivative as i will just write it as sigma prime ok refer slide time one thousand, nine hundred and ten or g prime is this fine now i have it with respect to one unit what will i do go to the gradient fit it all these values now simplify this what is this a vector right what is this another vector there is a one to one correspondence between them so you have two vectors and you are doing a one to one multiplication what is this student refer time one thousand, nine hundred and forty-three how many of you say dot product dot product is always a what is the output here student vector can it be a dot product can it be a dot product no please empathic no ok so what is it going to be an element wise multiplication and this is how you denote that ok so what is this called you had a multiproduct right so this is every element of one vector multiplied by the corresponding element of the other vector ok so now again the entire vector we can compute at one row right i am not i am when i am teaching this i am telling you how to compute one element and then go to the gradient but when you are going to implement this we are just going to compute the gradient at one go"}
{"audio_filepath": "/content/Audio_trimmed_wav/Error and Error Surfaces.wav", "duration": 220.544, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module twenty-four lecture two errors and error surfaces before we go to the next section which is on learning i just want to introduce the concept of errors and error surfaces and tell you what it relates to these multiple solutions that we were talking about refer slide time twenty-six so for simplicity what we will do is we will just set the threshold to minus or minus w to one which is setting the threshold to minus one and now i will try different values of w1 and w2 ok so i was saying that there are multiple values of w1 and w2 possible and these are all real numbers we are not constrained by having them as boolean values so now this is one solution which i tried i tried setting w1 to minus one and w2 to minus one what is wrong with this line does it lead to any errors how many just one error so this makes an error of one out of the four inputs now let me just try some other values of w1 and w2 this line again one error what about this line not four three because zero zero is anyways on this side of a line so now given this now tell me that i my quest is to find these w so i would want to find w1 w2 and so on given this discussion on errors can you tell me a condition that i am looking for i want to find w1 w2 or up to wn such that errors are minimized and in the best case errors are zero so that is what i want so this just i want to make a case that these search for w\u2019s is driven by certain objective and this objective is to minimize the error so now since we are doing this let us plot the error surface corresponding to different values of w naught w1 and w2 refer slide time two hundred and three once again for simpler analysis we will just keep w naught to be fixed at minus one and now what i have so just do not read this bullet as of now even this one so i have this w2 here so that is my one axis and i have w1 here which is my another axis now what i am going to do is i am going to try different values of w1 and w2 so this axis can go from minus infinity to plus infinity of course for showing the sake of showing here i have just had it from minus four to four so now what i am going to do is i am searching for some values of w\u2019s w1 and w2 so that my errors is zero and let us do a brute force and i will just try every value between minus four to four ok in fact one of the solutions which i proposed actually was this eleven eleven right that is the line which we saw on the previous slide and which led to zero errors and that is the dark blue surface here so how did i compute this error actually i just substituted minus sorry eleven eleven here and then i put in all the four values combinations for x1 x two and i realized that i am able to satisfy all of them so i do not get any error now instead of that if i had put something different so let me just go back to the previous slide which was see minus one minus one which is i think yeah somewhere around here right minus one minus one i guess so for that i am in this light blue region where the error was one i make errors for one of the inputs so it is a very brute force way of finding this and this is not going to work because we have lots of inputs to check but this is just to give you an intuition that we are looking at errors and we are trying to find a value of w1 w2 which minimize this error so that is the idea behind errors and error surfaces"}
{"audio_filepath": "/content/Audio_trimmed_wav/Deep Learning(CS7015): Linearly Separable Boolean Functions.wav", "duration": 337.707, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module twenty-seven lecture two linearly separable boolean functions so in this module we look at linearly separable boolean functions again and we will try to make some more statements about them refer slide time twenty so what do we have do so the guiding question that we have is what do we do about functions which are not linearly separable and let us see one such very simple function can you guess what function i am going to talk about all of you are paying attention in the first lecture refer slide time thirty-six so here is the xor function now these are the set of inequalities that result from xor function i hope right now let us see the first condition implies that w naught should be less than zero second condition implies this third condition implies this fourth condition implies this just looking at this can you tell me can you find a configuration for w naught w1 w2 such that these inequalities can be satisfied together no right because two and three want it to be greater than minus one minus w naught and when you take an addition of that it has to be less than minus one so that is not going to happen so you see a contradiction so this is a simple boolean function which the perceptron cannot handle because it is not linearly separable it is not linearly separable there does not exist a line if there does not exist a line you cannot find the line in fact you can look at it visually so these are the red points for which the output should be zero or one and the blue points are the points for which the output should be zero if we need to change this i think we were using blue as positive and red as negative and you cannot just draw a line there is no way you can draw a line such that the blue points lie on one side and the red points lie on the other side so it is a simple two input function so it is not that i have taken a very contrived example refer slide time one hundred and fifty-seven most real world data is not linearly separable and it always contains some outliers right so here maybe you have some data where you are trying to say that people which live in this part of the world belong to a certain or maybe people who live or work here have a certain qualification people who work in this company may have a certain different qualification and there might be some outliers right it is not that is always going be very clean so now what do i mean and it is not necessary that the points will only be outliers in fact there could be a clear case where there are no outliers but still you cannot find a line such that you separate the positive from the negative can you think of such an example good right this is clear data there is no outliers here as well i mean it is just saying that everyone who lies within this boundary has a certain characteristic and outside that boundary people have a different characteristic right and there is no outlier here but you cannot separate this data with a line so all functions that you deal with will not go or are not going to be linearly separable so we have to work around those right and while a single perceptron cannot deal with this we will show that a network of perceptron\u2019s can indeed deal with such data so that is where we are headed refer slide time three hundred and sixteen so before going there we will discuss some more boolean functions in more detail and i will try to see what kind of nonlinearly separable boolean functions are there refer slide time three hundred and twenty-six so first of all how many boolean functions can you design from two inputs how many can you design sixteen looks like a good number from three inputs two hundred and fifty-six how many if you understand this let us see so let us begin with some easy ones that you already know right so these are two inputs x1 x2 what is this function always off the other extreme is always on and i have already given you the answer f sixteen so then you have the and function and or function then some other functions right so why did you reach sixteen actually because with two inputs we will have these four values to take care of and each of these are again binary so you actually have two raise to two raise to n right so for three inputs two raise to two raise to three would be two hundred and fifty-six now that is the easy part of these how many are linearly separable i will have to do any actually stare it in and seriously try to find the answer when you cannot really do that so turns out all of them except xor and in not of xor ok so for the two input cases there are two functions which are not linearly separable for n inputs how many functions would be not linearly separable it is an arbitrary n is not the answer you are not going to disappoint me not n ok but what is the answer so for n inputs we will have two raise two n functions of these we do not know how many are going to be not linearly separable that is not a solved problem although i encourage you to go and find the answer i am looking for a good will hunting kind of a moment but all it suffices to know is that there exists some which are not linearly separable and that everyone agrees that there exists some right and as n grows probably that number will increase and so on but it is not known exactly you cannot write it as a function so what we have done so far is looked at boolean functions how many boolean functions can exist and of that we just have concluded that there would be some which are not linearly separable"}
{"audio_filepath": "/content/Audio_trimmed_wav/Proof of Convergence of Perceptron Learning Algorithm.wav", "duration": 897.109, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module \u2013 twenty-six lecture \u2013 two proof of convergence in this module we will talk about the proof of convergence for the perceptron or the learning algorithm that we saw in the previous module refer slide time twenty-one so we have some faith and intuition that it actually works we just need to formally prove it that it actually converges so that is what we are going to do in this module refer slide time thirty-one so before that a very few very simple definitions so if you have two sets of points p and n in an n dimensional space and we call say that these points are absolutely linearly separable if there exists some n plus one real numbers which has w0 to wn such that every point which belongs to p right p is the case where the output is one then these set of weights satisfy this condition and every point which lies in the negative set the set of weights satisfy this condition so nothing very different from what has we have been saying so far it is just formally defining it now our proposition is that if the set p and n are finite and there is a fixed number of points in that which was the case in the toy example that we were doing and which will be the case in most examples that we do and linearly separable the perceptron learning algorithm updates the weight vector ok before i go there ok let me not give you the definition and let me ask you the definition so now i have given this definition the first definition and given this part of the proposition can you tell me what do i need to prove if i need to prove that the algorithm converges that is one way of looking at it but what was happening in that wrong argument which was i was making that it continuously kept toggling that means i am not making a finite number of updates right i have to keep changing again and again and this process continues in a loop so that is how i am going to define convergence that the perceptron learning algorithm updates a weight vector of finite number of times it only needs to update it finite number of times and it will reach a configuration such that now it is able to separate the p from the n ok that is what the proof of convergence means so in other words if you are going to pick up these vectors randomly from the set p and n cyclically as we were doing in the toy example then a weight vector wt is found after a finite number of steps which will separate these two steps these two sets so that is what we are trying to prove so that is the definition of converge does it make sense refer slide time three hundred and two so proof is on the next slide and it is going to take me around five to ten minutes to prove it so just stay focused all right so here is a few set up right so i am going to before i go to the actual proof i am going to make a set up so that it becomes easier for us to prove it so the first thing that i am going to say is that if there is a point which belongs in negative set then the negative of that point belongs in the positive set and that is very clear because if the point belongs in the negative set then w transpose x is less than zero but then w transpose minus x would be greater than equal to zero right so i take the negative of the point i can just put it in the positive set so instead of considering these two different things p and n i am just going to consider one p prime which is an union of p and all the n points negative ok will the set up clear if this is a setup then what is the condition that i need to ensure for every point in p dash student refer time three hundred and fifty-seven w transpose p should be greater than equal to zero right so i do not care about the negative case i have just made everything positive now and it is i am not done anything wrong here it is just a simple trick ok and now this is how the algorithm will look in this setup these are the inputs with label one inputs with label zero n minus contains a negation of all the points in n and p prime is a union of these now again i start by initializing w randomly while convergence i will do something i will pick a random p from p prime now what is the if condition less than zero do i need the other if condition no right because everything is now positive ok and the other small thing that i am going to do is i am going to normalize p ok so that again does not mean because we are talking in terms of angles and i am not changing the direction of the vector i am just shrinking it right so i am just or maybe scaling it also i am just making it unit norm so that does not change anything so it is still everything still holds and in particular you can see here so if this condition was true this condition will also be true ok so so far just i am done some simple tricks to make things easier for me later on so now p has been normalized now remember that this data is linearly separable that is what we started the proposition if p and n are linearly separable then the perceptron learning algorithm will converge so now if p and n are linearly separable irrespective of whether we have the perceptron learning algorithm or not what do we know there exists a w star which is the solution vector right there exists at least one w star which is the solution vector right such that it will separate the p points from the n points so this vector which we do not know but we just know that it exists so you can refer to it so we will call this w star fine now we start the proof refer slide time five hundred and fifty-six so w star is some optimal solution which we know exists but we do not know what it is right now suppose you had a time step t so remember that this algorithm is going on while convergence so you have time step one two three you are picking up points so we are at a time step t at which you pick up a random point pi and you find that the condition is actually violated so this should actually be less than zero if i know the condition is violated so now what will you have to do w is equal to w1 so i will just call it the new w wt plus one is equal to the old w plus pi ok now what i am going to do is i am going to consider the angle beta between w star and wt plus one i do not know what w star is but we can still assume it exists and make some calculations based on that so what is the angle between w star and wt plus one its beta and what is the cost of that angle this and remember that we do not have w star here because we had assumed that it is the normalized vector so we do not need that but this is actually equal to one ok so now if i just take the numerator w star in dot product wt plus one now i am going to expand wt as wt plus pi fair that is exactly what i did on the previous step now now what is pi actually it is so what you had is you had these p1 p2 p3 my hand writing is really horrible and up to pn right so i have just picked one of these pi\u2019s ok now what i am going to define is now suppose this is my these are my pi\u2019s so these are all the vectors that i have now suppose i have this w star suppose this was the w star that i am interested now for each of these i could compute w star p1 w star p2 and so on up to w star pn and i could sort them now what i am doing is that for whichever of these points w star pi is the minimum i am going to call that value as delta suppose w star p one is the smallest quantity out of w star p1 w star p2 w star pn and i am calling that quantity delta so i have this quantity here and my delta is the minimum of all the possible values that it can take it can make w star p1 p2 up to pn so delta is the minimum quantity so here i have an equality refer slide time eight hundred and forty-five now are you ok with this this is the minimum quantity right so any pi that i put in here it is always going to be greater than or worst case equal to delta now again this w2 itself i could write it as wt minus one plus pj because that also would have come up from some update in the previous step ok again this is there which i could call it as delta and still retain the greater than equal to here ok fine so let us see where are we heading with this now notice that we do not make a correction at every time step when i was running that toy algorithm i was not making a correction at every time step we were only making a correction at those time steps for which the condition was violated so now if i am at t\u2019th time step maybe i have made only k which is less than or equal to t corrections at max i would have made t corrections but it could have been less than that also so now every time we make a correction we are adding a value delta to this so at the time step t what would happen i had started off from w naught i have reached time safety and i have made a case that i have not made t updates i have made k less than equal to t updates so how many deltas would get added k delta so i could say that with respect to w naught where i had started from this is what this quantity is ok is that fine anyone has a problem with this refer slide time one thousand and nineteen so far what are we shown we started with this this condition was true again not less than equal to and hence we made the correction and this was the point that we picked up at the t th step and thence we made that correction and we also showed that the numerator is actually greater than equal to this quantity we showed it by induction fine now let us look at the denominator and particularly let us look at the denominator squared ok is a step right this is actually wt plus one dot product wt plus one but wt plus one can be written as wt plus p i this bracket needs to disappear right is that ok fine now what is what is this quantity that is less than equal to zero so now can you guess what is the next thing that i am going to write that is correct yeah it is a negative quantity so that is going to be less than equal to this so that is fine and what about pi square or this term because this is less than right that is why correct is this fine ok now what is pi square one now can you guess what i am going to do by induction so what is wt square again just this wt plus one square was wt square plus one wt square is going to be wt minus one square plus one right and how many such ones will get added k of those right starting from w naught ok refer slide time one thousand, two hundred and thirty-six so what have we shown the numerator is greater than equal to this the denominator is less than this ok now if i put them together i actually get that cos beta is going to be greater than equal to the numerator over the denominator ok now what is this quantity proportional to k k square k cube square root of k k by two student square root of k square root of k right you have i mean roughly speaking you have a k here you have a square root of k here so i could roughly speaking say that it is proportional to square root of k so as k grows what will happen to cos beta it will grow and that is fine right it can keep growing student refer time one thousand, three hundred and thirty-one only until one right so cos beta is going to be proportional to k what is k the number of updates that you make now if i were to take that degenerate case which you guys were hinting at where that it will keep changing again and again what will happen to k it will keep going to infinity can that happen no because cos beta will blow up right and that is not allowed so k has to be finite so that cos beta stays within its limits right hence are we done how many if you think we are done how many if you are satisfy that we are done refer slide time one thousand, four hundred and twenty-nine so yeah so this says that we can only have a finite number of such k updates that we make and after that the algorithm will converge so we have a proof of convergence now coming back to our questions this is where we had started at one point what about non boolean inputs so perceptron allows that we took imdb rating and critics rating as an input do we always need to hand code the threshold no in our perceptron learning algorithm are all inputs equal no we now assign weights to input what about functions which are not linearly separable we still do not know so that is where we are headed now not possible with a single perceptron but we will see how to handle this"}
{"audio_filepath": "/content/Audio_trimmed_wav/From Cats to Convolutional Neural Networks.wav", "duration": 171.755, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture \u2013 one chapter four from cats to convolutional neural networks i will talk about the history of convolutional neural networks and i call this part of history as cats and it will become obvious why i call it so refer slide time twenty-one so around one thousand, nine hundred and fifty-nine hubel and wiesel did this famous experiment they are still i think you could see some videos of it on youtube where there is this cat and there was a screen in front of it and on the screen there were these lines being displayed at different locations and in different orientations so slanted horizontal vertical and so on and there are some electrodes fitted to the cat and they were measuring trying to measure that which parts of brain actually respond to different visual stimuli let us say if you show it stimulus at a certain location does the different part of the brain fire and so on so and one of the things of outcomes of the study was that that different neurons in brain fire to only different types of stimuli it is not that all neurons in brain always fire to any kind of visual stimuli that you give to them refer slide time one hundred and eighteen so this is essentially roughly the idea behind convolutional neural networks starting from something known as neocognitron which was proposed way back in one thousand, nine hundred and eighty you could think of it as a very primitive convolutional neural network i am sure that most of you have now read about or heard about convolutional neural networks but something very similar to it was proposed way back in one thousand, nine hundred and eighty refer slide time one hundred and thirty-six and what we know as the modern convolutional neural networks maybe i think yan li kun is someone who proposed them way back in one thousand, nine hundred and eighty-nine and he was interested in using them for the task of handwritten digit recognition and this was again in the context of postal delivery services so lot of pin codes get written or phone numbers get written on the postcards and there was a requirement to read them automatically so that they can be the letters or postcards can be separated into different categories according to the postcard according to the postal code and so on right so or the pin code so that is where this interest was there and one thousand, nine hundred and eighty-nine was when this convolutional neural networks were first proposed or used for this task refer slide time two hundred and nineteen and then over the years several improvements were done to that and in one thousand, nine hundred and ninety-eight this now how famous data set the mnist data set which is used for teaching deep neural networks courses or even for initial experiments with various neural network based networks this is one of the popular data sets which is used in this field and this was again released way back in one thousand, nine hundred and ninety-eight and even today even for my course i use it for various assignments and so on refer slide time two hundred and forty-nine so it is interesting that an algorithm which was inspired by an experiment on cats is today used to detect cats in videos of course among other various other things is just i am just jokingly saying this"}
{"audio_filepath": "/content/Audio_trimmed_wav/Backpropagation: Computing Gradients w.r.t. Parameters.wav", "duration": 724.672, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module \u2013 forty-seven lecture four back propagation computing gradients wrt parameters refer slide time sixteen before we move on to the next module a quick summary of what we have done so far so we introduced feed forward neural networks and we wanted to learn the parameters right from the last layer to the first layer and we figured out that what we can do is that we can just use the gradient descent algorithm as it is except that we have this small problem that we have so many parameters now and located at differ different points in the network right some at the initial layer some at the final year and you want to compute the derivatives or the partial derivatives with respect to all of these if you can do that put them all in this large matrix then we can just use gradient descent as it is so that is what we figured out and then we wanted to find out the gradients with respect to or the partial derivatives with respect to all these parameters so then we realize that this can be done using chain rule because there is a path from your output which is the loss function to any of these weights so we just need to follow that path and apply this smart this chain rule smartly and just sum up the derivatives across all the paths that lead to that weight so in that process we started from the output layer we just treated it a bit special because the output function is special and this is the last layer so we just first computed the gradient with respect to the output layers then we figured out how to compute the gradients with respect to any of the hidden layers and now if you are at a particular hidden layer now the weights that feed into this layer we could or we have not reached there so now the next thing that we need to do is that we have computed the gradients with respect to any of these hidden layers and now we want to find the gradients with respect to the parameters which is the weights and the biases so it is the do you all remember this or it is all long history or the story is back right fine so now we are at the last point which is computing gradients with respect to parameters refer slide time two hundred and four refer slide time two hundred and fourteen so again this is the overall picture we were in this chain rule and we have come all the way to the last point where we are ready to now compute these quantities so now start by recalling that a k is equal to b k plus w k h k minus one right this is our activation formula pre activation formula right so i am talking about these light blue guys ok which is clear in image and now i what have i done so far i have been able to come up with a formula to write the gradient of the loss function with respect to any of these light green guys right that is what where we ended last time right where we are able to compute the gradients with respect to the sorry light blue guys ok and now i want to compute the gradient with respect to any of these parameters or any of these parameters so any parameter it does not matter am at some i\u2019th activation layer pre activation layer and i just want to compute the gradients with respect to the weights which feed into this layer and that is what we are interested in so we are just taking any layer k and you want to find the gradient with respect to the weights there now can you tell me so can you tell me what is what is the thing that am going to do here or what is the recipe that we have been following i need to move what is the recipe that we have been following apart from yelling at people who come late we find the element wise partial derivatives first and then put them all together to get the gradient ok what is the element here what is what am i looking for right now i want to compute this fill this blank what goes here student w w any of these w is right and in particular say w k that is what i am looking for so what is the first thing that i am going to attack student wkij good w k i j and once i have this for one of these guys i just know a generic formula with respect to i j and k and i can just put it into a gradient vector ok is that fine ok so now can you ok now from here to here if i want to reach from here to here so this is what i am interested in right now how is the chain rule going to look on look like based on whatever you have already seen till where have you already reached you already know this quantity right now if i want this how am i going to write it student refer time four hundred and fifty-nine i will find up to the light blue guys which is this i already know how to compute it and then from the light blue guys i will go to the this is fine right so this is the quantity that i am looking for ok now what is one element of this guy dou a k by is it fine ok what is the dimension of this actually is it a scalar a vector a matrix matrix or a tensor what is the tensor what is it is it a matrix what are the dimensions what does this derivative mean or this gradient mean i change one element of w k how much does one element of a k change how many elements are there in ak n how many elements are there in w k n cross n so how many partial derivatives which i have n cross n cross n what is this student tensor a tensor right so this is going to be a tensor ok so when i say one element of this i mean this ok so this is one element of this gradient ok now can you tell me the formula for this what is this quantity hk minus student one refer time six hundred and twenty-seven hk minus one or hk minus one j or student refer time six hundred and thirty-one everyone gets this hk minus 1i how many of you get this refer slide time six hundred and thirty-eight so let us do it right so you have ak1 ak2 ak3 that is your ak vector ok you have bk1 bk2 bk3 plus wk1 one yeah i know again this is one of those silly things but if everyone does not raise their hands and compelled to do this so h k minus one one hk minus one two hk minus one three ok so let us take one of these guys right so a k one can you tell me the formula for that student refer time seven hundred and thirty plus first row ok one two this one three now can you tell me this quantity so what is i here one ok so i want this by w k i j right so i is one so i can take any of the j so let me take j equal to two so what is it going to be this will go off this is constant this is constant only this term remains and the derivative is hk minus one two which is j right so that is what the formula says so i have a formula for one of these guys ok and that is a generic formula so always remember if you cannot figure out what it is just write it down in scalar terms just add up all the terms and you will get the formula right so now this is what the chain rule is going to be refer slide time eight hundred and thirty-seven so this is what it is going to be this is one element of that tensor this is how that entire thing is going to look i have just flattened it out and put it here refer slide time nine hundred and five now let us take a simple example of wk belonging to r cross three cross three everyone is fine so far right or anyone who everyone is fine please raise your hands i mean fine i mean not in life but with the lecture fine so this is what it looks like right for a three cross three matrix now let us see we already found out that this guy is equal to hk minus one comma j right so this is what this matrix looks like nothing rocket science here right so each of these quantities is actually can be written in this form where i appropriately substitute i k and j and i know that this quantity can be further written as this quantity right that this is our clear right so i have written it as this now can you simplify this i do use a lot of this ok can you simplify it is it looks similar to something that you did on the assignment does this look like matrix which has some very regular patterns yeah i can see someone doing this and this everyone gets it refer slide time one thousand and twenty-eight so let us see so this the first column the second term in the product is all same throughout all the rows right what i mean is all these guys are similar same thing happens in the second row the third row right ah that is sorry the second column and the third column what about the rows these are all equal right so what does this look like actually the outer product of two vectors everyone gets this raise your hands ok good so i do not need to do an example so it is fine right this is an outer product of these two vectors one happens to the quantity to be the quantity that we already knew right and the other happens to be a quantity that we can figure out i mean we already know this what is we know how to compute the hidden representations right the hk\u2019s we can compute refer slide time one thousand, one hundred and twenty so fine so finally we come to the biases this is what one entry looks like this is exactly the sum which i had written out now i take the derivative with respect to b k i of the loss function so i could write it into as this chain rule where the first quantity is something i already know i have computed the gradient with respect to the pre activation layers what about the second quantity anonymous roar is what i was expecting student one one ok fine we can now write the gradient with respect to the bias what would it be what is this what is this it is just the gradient with respect to the pre activation layer right simple so now we are done with all the gradients that we were interested in"}
{"audio_filepath": "/content/Audio_trimmed_wav/Deep Learning(CS7015): Sigmoid Neuron.wav", "duration": 709.077, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture \u2013 three sigmoid neurons gradient descent feedforward neural networks representation power of feedforward neural networks we are in lecture three of cs7015 and today we are going to cover the following modules we are going to talk about sigmoid neurons gradient descent feedforward neural networks representation power of feedforward neural networks refer slide time thirty-one so let us start so here are some acknowledgments so for one of the modules i have borrowed ideas from the videos of ryan harris on \u201cvisualize back propagation\u201c they are available on youtube you can have a look if you want for module thirty-five i have borrowed ideas from this excellent book which is available online it is the url as mentioned in the footnote and i am sure i would have been influenced in borrowed ideas from other places and i apologize if i am not acknowledge them probably properly if you think there are some other sources from which i have taken ideas and let me know i will put them in the acknowledgments refer slide time one hundred and two so with that we will start with module thirty-one which is on sigmoid neurons so the story i had is that it is enough about boolean functions refer slide time one hundred and ten now we have done a lot of boolean functions but now we want to move on to arbitrary functions of the form y is equal to f of x where x could belong to rn and y could belong to r so what do i mean by this so let me just explain this with the help of an example so i will again go back to our oil mining example oil drilling example where we are given a particular location say in the ocean and we are interested in finding how much oil could i drill from this place and that is what i would base my decision alright whether i want to actually invest in this location or not and then what we are saying is that this could depend on several factors so we could have x1 x2 x3 up to xn right where this could be the salinity of the water at that location so this could be a real number this could be the density of the water it is average density this could be the pressure on the surface of the ocean bed and so on and so forth so each of these values independently belongs to the set of real numbers so each of this is a real number and we have n of these so together they belong to rn so i can read that i have n such real numbers and i could just put them in a vector and say that i have a input x which belongs to r raised to n so we have this x which we can say belongs to rn and in this particular case we want to predict y we want to take this as an input and predictor y and what is y in this case you want to predict the quantity of oil that we could mine so what does ry belong to again a set of real numbers and it could be some gallons or litres or kill of water so this again belongs to r so these are the kind of functions that we are interested in now we want a function which takes us from i am having this x which belongs to rn right it is a vector of dimension n and takes us to a value belonging to r so you clearly see that this is different from the case when we had n variables each of this was just boolean so these were only zero one inputs now we have real inputs and these are the kind of functions that we are interested in refer slide time three hundred and thirty-five now can we have a network which can represent such functions now what do i mean by represent such functions we already spoke about this when we were doing boolean functions so what do we mean by representing the function we mean that if i am given a lot of training data right so i am given these x1 x2 each of these belongs to rn and i am also given the corresponding labels now i want a network which should be able to give me the same predictions as is are there in my training data so it should be able to take any of these x\u2019s as input and it should give me the same y i corresponding to it and i am saying approximately which means i am with some error rate whether if it is within some to with as long as it is close to the actual value i am fine with it so that is what i mean by a network which can represent such functions is that working definition of representing clear right so that is a very similar to the definition that we were used for boolean functions we had said that we should be exactly be able to get the truth table the network should be able to represent the truth table exactly so that is very similar to the definition that i am using here refer slide time nine hundred and forty-five and then before we do this right before we come up with a network which can do this for arbitrary functions we have to graduate from perceptron\u2019s to something known as sigmoid neurons so please remember this overall context that we dealt with a lot of boolean functions we analyze them carefully and we saw that we could come up with these networks which could represent arbitrary boolean functions and they could represent them exactly as long as we have one hidden layer of course the catch was that that hidden layer could grow exponentially now we want to graduate from boolean to real functions that means you have a real input of n variables and one or more outputs and you should be able to represent this exactly so that is where the transition is where so that is the story that we are looking for refer slide time five hundred and thirty so let us start so recall that a perceptron will fire if the weighted sum of it is inputs is greater than the threshold just recall that fine refer slide time five hundred and thirty-eight so now i claim that the thresholding logic which is used by a perceptron is actually very harsh now what do i mean by that let us see so let us return to a problem of deciding whether we like or dislike a movie that is the same problem that we have been dealing with and now consider that we base our decisions only on one input which is the critics rating which lies between zero to one and this is what my model looks like it takes the input as the critics rating i have learned some weight for it and my threshold is five what does this mean it means that if for a given movie the rating is fifty-one will it predict like or dislike like so then i should go and watch the movie what about a movie for which the critics rating is forty-nine dislike so now you see what i mean by harsh so both these values are very close to each other but for one i say i like it for the other i say that i would not like it so it is not how we make decisions right you would have probably said something equal for both the movies you would have not given such a drastic decision refer slide time six hundred and fifty-two so why is this happening so you might say oh this is a characteristic of a problem that you have picked up maybe that is the critics rating which is between zero to one or something but i want to convince you that this is not a characteristic of the problem that i have picked up but this is something to do with the perceptron function itself so this is what the perceptron function looks like so this sum of all the inputs the weighted sum of all the inputs i am calling it by a quantity z and this is what i am going to plot on the this axis so this is my z axis now what does the perceptron say that when this value of z becomes greater than w naught or minus of w naught it will fire and when it is less than minus of w naught it will not fire that is what it says so this is a characteristic of the perceptron function itself it is going to have this refer slide time seven hundred and forty-three sharp decision boundary that whenever your sum crosses this threshold you will say one and whenever your sum does not cross this threshold you will say zero so in this toy example over the movie critics it just happened that this was five and so it was saying yes for fifty-one and it was saying no for forty-nine so this will happen for any problem that you pick up refer slide time eight hundred and six so to counter this we introduce something known as sigmoid neurons and this is just a smoother function or a smoother version of the step function you see that how many if you know what a sigmoid function what is the formula for a sigmoid function quite a few good and here is one such sigmoid function which is called the logistic function so remember that sigmoid is a family of functions these are functions which have this s shaped logistic function which i have shown here is one such function and the other function that we will see in this course is something known as the tanh function so let me just get into a bit more detail with this logistic function i just want you to understand it properly so this quantity here remember we were writing it as w transpose x which was summation i equal to zero to n wi xi remember this so now i am just going to consider this to be one over one plus e raise to minus w transpose x now i am going to ask you some questions and try answering those what happens when w transpose x tends to infinity what happens to the sigmoid function one and that is exactly what is happening here as this tends to infinity as this keeps growing so remember this axis is z which is the same as w transpose x right this is w transpose x so as it tends to infinity your sigmoid goes to one what happens if w transpose x is minus infinity zero and that is exactly what is happening here and what happens when w transpose x is equal to zero half so this is that value corresponding to half is that clear so that is how a sigmoid function behaves fine refer slide time one thousand and nine now we no longer see a sharp transition it is a very smooth function and the sigmoid function lies between the values produced by the sigmoid function rate what is the range that they lie between zero to one what is another quantity of interest that you know which lies between zero to one probability so that is one advantage of sigmoid functions so now you can interpret the value given by a sigmoid function as a probability so what does it mean in our movie example again so it just tells me in those two cases that with fifty one percent probability i like the movie or with forty-nine percent probability i like the movie so now this is not very drastic or very harsh right i am not saying yes or no i am not committing myself i am just giving you a number which is proportional to how much i like the movie so it can be interpreted as a probability refer slide time one thousand and fifty-nine now here\u2019s the overall picture it so this is the difference between the perceptron function and the sigmoid function so notice that here we had this if else condition right which was leading to that sharp boundary now here we do not have that defence condition we just have a function which is a smooth function refer slide time one thousand, one hundred and eighteen and here is another picture so this is not smooth not continuous and not differentiable everyone agrees with that it is not smooth here right it is not differentiable here whereas this is smooth continuous and differentiable and the contents that we covered today it will be very important to deal with functions which are smooth continuous and differentiable so for lot of this course calculus is going to be the hero of the course lot of the things that we do will be based on calculus and in calculus always if you have smooth and continuous and differentiable functions they are always good so that is why we want to deal with such functions"}
{"audio_filepath": "/content/Audio_trimmed_wav/The Curious Case of Sequences.wav", "duration": 355.2, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras lecture one chapter six the curious case of sequences so i was talking about successes in image speech pattern recognition even natural language processing and so on so one interesting thing here is about sequences so i will talk about sequences now refer slide time twenty-seven sequences are everywhere when you are dealing with data so you have time series which is like say the stock market trends or any other kind of a series time series then you have speech which is again a series of phonemes or you have music you have text which is a series of words you could even have videos which are the series of images right one frame each image each frame can be considered to be an image and so on so in speech data one peculiar characteristic of speech data is that every unit in the sequence interacts with other units so words on their own may not mean much but when you put them together into a sentence they all interact with each other and give meaning to the sentence right and the same can be said about music or speech or any kind of sequence data so all these elements of the sequence actually interact with each other so there was a need for models to capture this interaction and this is very important for natural language processing because in natural language processing you deal with sequence of words or all your texts or sentences or documents or all sequences of words so that is very important and the same in the case of speech also so if you take up any deep learning paper nowadays it is very likely that you will come across the term recurrent neural network or lstms which are long short term memory cells and so on refer slide time one hundred and forty-seven so this is also something which was proposed way back in one thousand, nine hundred and eighty-six refer slide time one hundred and forty-nine so a recurrent neural network is something which allows you to capture the interactions between the elements of your sequence i had said at a very layman level but of course you are going to see this in much more detail in the course and this was also not something new even though you hear about it a lot in the past three to four years the first recurrent neural network and what you see here is exactly a very similar to what we are going to cover in the course was proposed way back in jordan by jordan in one thousand, nine hundred and eighty-six refer slide time two hundred and twenty-three its variant was proposed by elmen in 1990so this is again not a very new idea this has existed for some time but now there are various factors because of which it has been possible to now start using them for a lot of practical applications as i said one you have a lot of compute time and the other you have a lot of data and the third is now the training has stabilized a lot because of these advances which i was talking about in terms of better optimization algorithms better regularization better weight initialization and so on so it has become very easy to train these networks for real world problems at a large scale so that is why they have become very popular and hear about them on a regular basis but it is again something which was done way back refer slide time three hundred and four so from one thousand, nine hundred and ninety-nine to one thousand, nine hundred and ninety-four actually people also looking at various problems will be training neural networks and recurrent neural networks and so that this problem which is known as exploding and the vanishing gradient problem which is again something that we will see in the course in reasonable detail we have this problem and it is very difficult to train recurrent neural networks for longer sequences so if you have a very long sequence or a time series you cannot really train a recurrent neural network to learn something from that refer slide time three hundred and thirty-four and to overcome these problems around one thousand, nine hundred and ninety-seven long short term memory cells were proposed and this is again something that we will cover in the course and this is now almost de facto standard used for training for a lot of nlp work lstm are used as one of the building blocks and another variants of lstms which are known as gated recurrent units and some other variants so this is also not something new even though they have become very popular nowadays like almost any article that you pick about to talk about any article on deep learning that pick about to talk about recurrent neural networks or lstms or gated recurrent units this is not something which is new refer slide time four hundred and twenty-three lstms had come way back in one thousand, nine hundred and ninety-seven but again due to various compute and other issues which i said at that time it is not so easy to use them but by two thousand and fourteen because of these parallel progresses which i mentioned in terms of optimization regularization and so on people are now able to use rnns lstms for large scale sequence to sequence problems and in particular a very important discovery at this time are very important model which was proposed at this time which is attention mechanism which is used in a lot of deep neural networks nowadays which enabled to deal with a lot of sequence prediction problems for example translation where you have given one sequence in one language and you want to generate the equivalent sequence in another language so this is known as a sequence to sequence translation problem so for that people proposed a sequence to sequence attention network and this was one of the key discoveries which then led to a lot of adaptation of or adoption of deep neural networks for nlp a lot of research in nlp happened which was then driven by deep neutral networks so a lot of existing algorithms which are non neural network based algorithms which are traditionally used for nlp was slowly replaced by these deep neural network based algorithms ok refer slide time five hundred and thirty-three and again this idea of attention itself is something that was explored earlier also somewhere around one thousand, nine hundred and ninety-one or so and it was something known as reinforcement learning which was used for learning this attention mechanism what attention basically tells you is that if you have a large sequence and if you want to do something with this sequence what are the important entities of this sequence or elements of this sequence that you need to focus on so this is again something that we will look at in detail in the course"}
{"audio_filepath": "/content/Audio_trimmed_wav/Backpropagation: Pseudo code.wav", "duration": 318.784, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module \u2013 forty-eight lecture four back propagation pseudo code so we move on to the next module and now we will write pseudo code to for back propagation refer slide time twenty-three so we have all the pieces of the puzzle we have the gradients with respect to the output layer that was the special layer because the output activation function is different they are the gradients with respect to all the hidden layers that means i have the gradients with respect to the activations as well as the pre activations so in the h\u2019s as well as the a\u2019s and i also have the gradients with respect to the weights and the biases and this is all index agnostic right that means i am just using k as the index everywhere i have a generic formula which applies at any layer for the weights as well as the activations and the pre activations right ok now we can put all this together into a full learning algorithm so let us see what the pseudo code looks like refer slide time one hundred and three so we have this t equal to zero well run this for some max iterations we initialize all the parameters to some quantity will randomly initialize them ok now for these max iterations can you tell me what is the first thing that i will do so there will be two functions here ok tell me what those two functions would be student forward forward propagation and then backward propagation right so you do a forward propagation and you compute all these activations pre activations output layer loss everything and then you do this backward propagation where you feed all these things which you have computed these are the quantities which you have computed you will pass this to your backward propagation algorithm it would not look so nasty as this it will not take so many parameters you could write it smartly and then you will just do the parameter update so what will the back propagation give you actually all the gradients all the partial derivatives right and then once you have the partial derivatives you know how to compute the update law so now let us look at these two functions more carefully the forward propagation and the backward propagation refer slide time two hundred and nine so forward propagation is simple for all the hidden layers that means from layer one to layer l minus one what will i do give me the code a k is equal to good then ok and what it what is h of zero you are starting the loop from one right so you will need h of zero that is x and then you will have a special treatment for the output layer and your final output will be whatever output function you use ok this makes sense you can write this in python you will have to write this in python refer slide time two hundred and forty-five now we have computed all the h\u2019s and the a\u2019s what have we computed all the a\u2019s all the h\u2019s and all and the y right now you want to do back propagation so back propagation the loop will be from i equal to one to n minus one good so the first thing i will compute is the gradient with respect to the output layer see even here the output layer was outside the loop the same thing would happen here also in the back propagation also first you will compute the gradient with respect to the output layer and this is the formula if you remember from last class right that is the formula which i have substitute here and note that f of x is known to you because you computed that in the forward pass and e of y one hot vector which with a correct label said to one and you know what the correct label is because we have given you the refer time three hundred and fourteen data right ok then what would the loop be l to one or l minus one let us see first you compute the gradients with respect to parameters it is l so because we are using k minus one then you compute the gradients with respect to the layer below computes gradients with respect to the pre activation right this is exactly how you will proceed this is clear to everyone the same three components that we have used you might be a bit confused about the ordering in which we have put them because we computed the gradients with respect to pre activation first and then the weights but once you go back you will realize because it is the way we have indexed it because this is already outside so this has already been computed so you can already compute the gradients with respect to the weights of the outermost layer is that fine so this is straightforward you can go back and check this ok now anything remaining or you have everything can you just take a minute and see if you can visualize the python code and we will just assume that you are done the assignment you can read you will have multiple these vectors and matrices and so on and you are just doing a lot of matrix operations using refer time four hundred and six or refer time four hundred and eight or whatever you prefer right now what is missing here input is missing ok input we have given right the ominous data set has been given is there something that yours i have still not shown you how to compute oh i did not update the parameters here is it no the parameter update will happen in the outer loop right so those forward prop back prop and then update the parameters right so the main algorithm was forward prop back prop update the parameters when we saw forward prob an obvious seeing backward prop so what is missing one thousand iterations something in the last line before end of course do you know how to compute this"}
{"audio_filepath": "/content/Audio_trimmed_wav/Learning Paramters of Feedforward Neural Networks (Intuition).wav", "duration": 376.747, "text": "deep learning prof sudarshan iyengar department of computer science and engineering indian institute of technology madras module forty-two lecture four learning parameters of feedforward neural networks intuition now we will move on to the next module where we want to learn the parameters of feed forward neural networks and we first start with some intuition and then mathematical details refer slide time twenty-six so we have introduced feed forward neural networks and we are now interested in finding an algorithm which can allow us to learn the weights of this network refer slide time thirty-three so recall our gradient descent algorithm this is how it looked ok i had initialized those two parameters w naught b naught and then i was iteratively doing this in a loop at every step i was moving in a direction opposite to the gradient at that step now can i write this a bit more compactly we can write using vectors refer slide time fifty-nine so are you ok if i write it this way so these two was actually nothing but vector at every point so i can just write it this way so theta is the vector containing w and b ok or theta is the vector of all the parameters my network had it just so happened that network had only two parameters so see where am going with this how many of you see where am going with this good so where delta theta t right just to remind you it was this the partial collection of all the partial derivatives with respect to all the parameters in this toy example all was equal to two right we just had two parameters now you see where am going with this ok so now in this feed forward neural network instead of theta equal to w comma b what do we have theta is equal to so many parameters ok so what would grad of theta t now be partial derivatives with respect to student refer time one hundred and fifty-eight all the weights but there is a problem here right this is the matrix how do you take the partial derivative with respect to the matrix who asked you to use the matrix how you take the partial derivatives with respect to matrix so what i am interested in this right the question i know there is some loss function which is a function of theta one of the elements of theta has this matrix w one which belongs to r n cross n right and now i want the derivative with respect to w so see what i am trying to do this is scalar and we take the derivative of that with respect to a matrix what is all that the derivative with respect to student refer time two hundred and thirty-seven every element of the matrix ok refer slide time two hundred and forty-one so we can still use the same algorithm except that del this grad of hat of so now i could just say that theta two hat i mean initialized all parameters and theta naught right compute the gradient with respect to all of them and then do this update right i could just instead of putting them in matrices i could just think of them as a large vector just had initially i had just had w comma b now this vector is even more large in fact i will show you actually how it is refer slide time three hundred and eight so this is the grad with respect to theta looks very nasty now this is how nasty looks right so you have this weight matrix w one you have the derivatives with respect to first element of w one all the way up to the last element last element so with respect to all the n cross n elements of w one what is the next entry going to be w two hundred and eleven to student refer time three hundred and thirty-two w2nn next after wl11 ok and then after this ok student refer time three hundred and forty-one what is remaining biases right so you have b11 to b1n this slight error here but intentionally this actual is k because k is not equal to n right the last layer has only k parameters whereas so that it looks ok is this clear so is this are all the partial derivative that we need right you do not need to worry about taking a partial derivative with respect to our matrix it just boils down to taking the partial derivative with respect to all elements of the matrix so earlier you just had two parameters now you have these n cross n plus n cross n upto l right so l into n cross n plus l into n that many number of parameters is what you have you get the calculation right or rather you have l minus one layers each of which has n cross n parameters right and l minus one layers which also have the biases so these are the w\u2019s these are the b\u2019s then the output layer one layer which has n cross k parameters and k cross one bias so these are all the number of parameters that you have and this is exactly what this size of this matrix is right it has all these parameters and you need to compute the partial derivative with respect to each of these parameters refer slide time four hundred and fifty-nine so this is what grad theta is composed of it is composed of the partial derivatives with respect to all the parameters of your network ok so now if someone gives you each of these quantities same oracle give you each of these quantities then can you apply gradient descent right you can use the exactly the same algorithm that you are using earlier just the sizes of earlier vectors changes how many of you are convinced that now you can use that gradient descent there is not a trick question how many of you convinced how many of you not convinced assuming that someone has given you these quantities right i know that it is hard to compute we will see how to compute that but let us assume someone has given you this then you can use gradient descent that is what the case i made in the previous slide right that you could initialize with all the parameters compute the gradients with respect to all the parameters and just do this update fine so now we need to answer two questions first is this is the key question refer slide time five hundred and fifty-five because we are taking derivative of what loss functions so we need to know what the loss functions that is the crucial question right and then we are taking derivatives with respect to all these elements so whatever i was told you that assume that oracle gives you now you have to do the hard work and actually find it out right so if you can answer these two questions then we are done we have an algorithm for learning the parameters of feed forward neural networks we all agree that if you have these two elements then we have done so here i will end this module"}
